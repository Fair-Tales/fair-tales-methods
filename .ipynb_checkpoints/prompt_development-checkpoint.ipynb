{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task decomposition and prompt development.\n",
    "\n",
    "We provide here a framework for developing sequential prompts for a complex NLP task using GPT4o.\n",
    "\n",
    "The complex tasks is decompsed into as sequence of simpler tasks that each build on the previous one.\n",
    "\n",
    "For each task in the sequence we produce a number of examples to show GPT4o, and a number of further examples to use for automated testing of the response. This borrows ideas from unit testing of software, since iterative changes to the prompt may break functionality that was previously working.\n",
    "\n",
    "This framework can be adapted to use with other LLMs and NLP tasks.\n",
    "\n",
    "#### We decompose into the following tasks:\n",
    "- Task 1: identify sections of direct speech, and the name of the speaker and recipient\n",
    "- Task 2: locate pre-defined sentences in these detected sections of speech (for comparison with human coding)\n",
    "- Task 3: pull out the spoken words only from each section (removing e.g. 'he said' etc)\n",
    "- Task 4: locate and replace the names of the speakers and recipients using a pre-defined character map  \n",
    "\n",
    "#### Notes:\n",
    "- Determinism is not guaranteed. But well structured prompts should produce near deterministic outputs, along with temperature=0, fixed seed. It is also worth storing the system finerprint for future reference, as changes to this may be the cause of differing results in the future.  \n",
    "- The lack of determinism can make tests quite brittle. It is worth repeating tests several times to confirm their behvaiour. And then running the full manual validation on a single static result set.\n",
    "- Where possible, the sequential tasks should b tackled as a new completion API, using formatted output from the previous task as the inupt. This is preferrable to chaining of prompts and outputs to produce a chat style conversation, but this increases the risk of conflict or confusion between prompts/instructions sets. And also increases the length of the context window.\n",
    "- Need to ensure consistency between instructions, schemas and examples. Otherwise results may be inconsistent e.g. 'reproduce all punctuation as it appears' conflicted with 'remove  speech marks' example.\n",
    "- Should typos be accounted for (e.g. task_3 name matching?)\n",
    "- Cost: \\\\$1.22 left after developing prompts. Added \\\\$10 to run for 50 books (so ~0.25 full dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating this using the Chat GPT API:\n",
    "\n",
    "## TODO:\n",
    " - move deifnition of input json to system prompt?\n",
    " - add character/alias mapping to prompt for each book: use primary name only\n",
    " - When in pipeline to spellcheck/ correct typos? (e.g. Hany in the Dinosaurs (book 21).\n",
    " - what to do about inconsitent sentence detection? e.g \"Now Dasher!\" being at the end of sentence 7 was causing GPT confusion...\n",
    " - add an instruction about how to refer to 'general audience' or 'narrator' or 'I'\n",
    " - ask for output of reaosning/thought process?\n",
    " - ask for a confidence score?\n",
    " - do we need to specify (in system prompt), not to use MD or any other formatting in the json output?\n",
    " \n",
    "## Note: ideas to explore if we need performance boost...\n",
    "\n",
    "- system message to edit assistant role\n",
    "- vary temperature or top_p parameter\n",
    "- fine_tuning a model with bespoke training data (how much data is necessary?)\n",
    "- improved instructions or prompt engineering (see e.g. paper on iterative prompting)\n",
    "- compare results with gpt-3.5-turbo? - does not seem to work weel for our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "from openai import OpenAI\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./key.txt', 'r') as infile:\n",
    "    api_key = infile.read().splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_to_exclude = []\n",
    "labels = pd.read_excel('./Book-List-Final-NONA.xlsx', sheet_name='Sheet1')\n",
    "labels = labels.rename(columns={'Author ': 'Author'})\n",
    "labels = labels.loc[~labels.Title.isin(books_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../text_pdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "def grab_text(title, labels):\n",
    "    \n",
    "    start = labels.loc[labels.Title==title]['Starting Page']\n",
    "    if len(start)==0:\n",
    "        print(title, \"no start\")\n",
    "        start = 0\n",
    "    else:\n",
    "        start = start.values[0]\n",
    "    end = labels.loc[labels.Title==title]['Ending Page']\n",
    "    if len(end)==0:\n",
    "        print(title, \"no end\")\n",
    "        end = 0\n",
    "    else:\n",
    "        end = end.values[0]\n",
    "    \n",
    "    title = title + '.pdf'\n",
    "    all_text = ''\n",
    "    with pdfplumber.open(title) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            if i+1 >= start and i < end:\n",
    "                single_page_text = page.extract_text()\n",
    "\n",
    "                if single_page_text is not None:\n",
    "                    all_text = all_text + '\\n' + single_page_text\n",
    "                \n",
    "    return all_text\n",
    "\n",
    "df['Title'] = [file.split('.')[0] for file in os.listdir() if file.split('.')[1]=='pdf']\n",
    "df['Text'] = [grab_text(title, labels) for title in df.Title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>\\n'Twas the night before Christmas\\nwhen all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>\\nThe unicorn has a silver horn, Her\\neyes are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Gruffalo</td>\n",
       "      <td>\\nA mouse took a stroll through the deep dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Monstrous Tale of Celery Crumble</td>\n",
       "      <td>\\nHave you met Celery Crumble?\\nThat’s her rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace at Last</td>\n",
       "      <td>\\nThe hour was late.\\nMr Bear was tired, Mrs B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0            The Night Before Christmas   \n",
       "1             Sugarlump and the Unicorn   \n",
       "2                          The Gruffalo   \n",
       "3  The Monstrous Tale of Celery Crumble   \n",
       "4                         Peace at Last   \n",
       "\n",
       "                                                Text  \n",
       "0  \\n'Twas the night before Christmas\\nwhen all t...  \n",
       "1  \\nThe unicorn has a silver horn, Her\\neyes are...  \n",
       "2  \\nA mouse took a stroll through the deep dark ...  \n",
       "3  \\nHave you met Celery Crumble?\\nThat’s her rig...  \n",
       "4  \\nThe hour was late.\\nMr Bear was tired, Mrs B...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../code_new_version')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.Text != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences\n",
    "Note: using strip() here to remove trailing or leading spaces for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.DataFrame()\n",
    "\n",
    "book_col = []\n",
    "sentences_col = []\n",
    "length_col = []\n",
    "index_col = []\n",
    "\n",
    "for title, text in zip(df.Title, df.Text):\n",
    "    text = text.replace('\\n', ' ') # This is only safe provided the line break is not being used to separate sentences w/o puntctuation...\n",
    "    text = text.replace('\\t', ' ') # This allows us to save as tsv (and simplifies the whitespace)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentence_list = list(doc.sents)\n",
    "    \n",
    "    for si, sen in enumerate(sentence_list):\n",
    "        book_col.append(title)\n",
    "        \n",
    "        doc = sen #nlp(sen.text.strip())\n",
    "        sentences_col.append(doc)\n",
    "        length_col.append(len(doc.text.translate(str.maketrans('', '', string.punctuation)).split(' ')))\n",
    "        index_col.append(si)\n",
    "\n",
    "    \n",
    "sentences['book'] = book_col\n",
    "sentences['sentence_length'] = length_col\n",
    "sentences['sentence'] = sentences_col\n",
    "sentences['sentence_index'] = index_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "    'task_1': {\n",
    "        'example_input_1': {\n",
    "            'full_text': '\\nBob saw an animal just like a horse. “That’s a\\ndonkey,” said Alice.\\n“Horses have got longer legs.” \\n The donkey realy was quite short and said it definitely wasn\\'t a horse. \\n“Cool! I\\'ve never seen a donkey before.” shouted Bob.'\n",
    "        },\n",
    "        'example_output_1': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Bob\",\n",
    "                        \"speech_text\": 'That’s a\\ndonkey,” said Alice.\\n“Horses have got longer legs.”',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"Alice\",\n",
    "                        \"speech_text\": '\\n“Cool! I\\'ve never seen a donkey before.” shouted Bob.',\n",
    "                        \"speech_section_id\": 1\n",
    "                    }   \n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        'example_input_2': {\n",
    "            'full_text': '\"What a strange day!\" Alice said to herself. \\n\"What do you think of that everyone? She is talking to herself!\" asked Bob.'\n",
    "        },\n",
    "        'example_output_2': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"self\",\n",
    "                        \"speech_text\": '\"What a strange day!\" Alice said to herself.',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"reader\",\n",
    "                        \"speech_text\": '\\n\"What do you think of that? She is talking to herself!\"',\n",
    "                        \"speech_section_id\": 1\n",
    "                    }   \n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    'task_2':  {\n",
    "        'example_input_1': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Bob\",\n",
    "                        \"speech_text\": 'That’s a\\ndonkey,” said Alice.\\n“Horses have got longer legs.”',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"Alice\",\n",
    "                        \"speech_text\": '\\n“Cool! I\\'ve never seen a donkey before.” shouted Bob.',\n",
    "                        \"speech_section_id\": 1\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Bob\",\n",
    "                        \"speech_text\": '\\n“You can\\'t be serious Bob!”\\nShe said he must have seen a donkey before.',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                    \n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        'example_output_1': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Bob\",\n",
    "                        \"spoken_words_only\": 'That’s a donkey. Horses have got longer legs.',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"Alice\",\n",
    "                        \"speech_text\": 'Cool! I\\'ve never seen a donkey before.',\n",
    "                        \"speech_section_id\": 1\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Bob\",\n",
    "                        \"speech_text\": 'You can\\'t be serious Bob!',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    'task_3':  {\n",
    "        'example_input_1': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alace\",\n",
    "                        \"recipient\": \"Bobby\",\n",
    "                        \"spoken_words_only\": 'That’s a donkey. Horses have got longer legs.',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"The Queen\",\n",
    "                        \"speech_text\": 'Cool! I\\'ve never seen a donkey before.',\n",
    "                        \"speech_section_id\": 1\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Robert\",\n",
    "                        \"speech_text\": 'You can\\'t be serious Bob!',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"everyone\",\n",
    "                        \"speech_text\": 'What do you think, everyone?',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        'example_characters_1': ['Alice', 'Bob', 'Charlie'],\n",
    "        'example_aliases_1': pd.DataFrame({\n",
    "            'alias': ['The Queen', 'Bobby'],\n",
    "            'character': ['Alice', 'Bob']\n",
    "        }).to_csv(),\n",
    "        'example_output_1': json.dumps(\n",
    "            {\n",
    "                'speech_sections': [\n",
    "                    {\n",
    "                        \"speaker\": \"Alace\",\n",
    "                        \"recipient\": \"Bobby\",\n",
    "                        \"speaker_matched\": \"Alice\",\n",
    "                        \"recipient_matched\": \"Bob\",\n",
    "#                         \"spoken_words_only\": 'That’s a donkey. Horses have got longer legs.',\n",
    "                        \"speech_section_id\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"The Queen\",\n",
    "                        \"speaker_matched\": \"Bob\",\n",
    "                        \"recipient_matched\": \"Alice\",\n",
    "#                         \"speech_text\": 'Cool! I\\'ve never seen a donkey before.',\n",
    "                        \"speech_section_id\": 1\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Alice\",\n",
    "                        \"recipient\": \"Robert\",\n",
    "                        \"speaker_matched\": \"Alice\",\n",
    "                        \"recipient_matched\": \"Unknown\",\n",
    "#                         \"speech_text\": 'You can\\'t be serious Bob!',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                    {\n",
    "                        \"speaker\": \"Bob\",\n",
    "                        \"recipient\": \"everyone\",\n",
    "                        \"speaker_matched\": \"Bob\",\n",
    "                        \"recipient_matched\": \"The Reader\",\n",
    "#                         \"speech_text\": 'What do you think, everyone?',\n",
    "                        \"speech_section_id\": 2\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    'test_ids': [0, 1, 2],\n",
    "    'strings': {\n",
    "        0: '\\n\"Watch out Rosie!\" cried Mum. \\n\"There\\'s a monster behind you.\" \\n\"I am going to eat you!\" shouted the monster.',\n",
    "        1: '\\nIt was a long drive to the safari park but it was worth it.\\nApatosaurus saw an animal just like Triceratops. “That’s a\\nrhinoceros,” said Hany.\\n“Triceratops has got more horns.”\\nMum liked the giraffes best and Nan-\\nliked the zebras.\\nThe monkeys were funny but the\\nman said not to feed them.\\nSam asked him if they had pandas but the man said\\nno, they were endangered animals.\\nHarry wanted to know what endangered meant.\\nSam said he was too little to understand.\\nNan helped. She bought Harry a book about endangered animals.\\nShe thought it was sad about the Sumatran tigers. People kept\\nhunting them so there were only a few left in the whole world.\\n\\nHarry really wanted to help but he had no money. “I\\nwant to save some animals,” he said.\\n“What can I do, Mum?”\\nSam said, “Tuh! What a waste of time!”\\nShe said he was miles too small to make any difference.',\n",
    "        2: df.iloc[0].Text\n",
    "    },\n",
    "    'task_1_responses': {\n",
    "        0: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Mum',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'speech_text': '\\n\"Watch out Rosie!\" cried Mum. \\n\"There\\'s a monster behind you.\"',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'The monster',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'speech_text': '\\n\"I am going to eat you!\" shouted the monster.',\n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "        },\n",
    "        1: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Hany',\n",
    "                    'recipient': 'Apatosaurus',\n",
    "                    'speech_text': '“That’s a\\nrhinoceros,” said Hany.\\n“Triceratops has got more horns.”',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Harry',\n",
    "                    'recipient': 'Mum',\n",
    "                    'speech_text': '“I\\nwant to save some animals,” he said.\\n“What can I do, Mum?”',      \n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Sam',\n",
    "                    'recipient': 'Harry',\n",
    "                    'speech_text': '“Tuh! What a waste of time!”\\nShe said he was miles too small to make any difference.',\n",
    "                    'speech_section_id': 2\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        2: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'Reindeer',\n",
    "                    'speech_text': 'Now, Dasher! now, Dancer!\\nnow, Prancer and Vixen!\\nOn Comet! on Cupid!\\non Donner and Blitzen!\\nTo the top of the porch, to\\nthe top of the wall,\\nNow, dash away! Dash\\naway! Dash away all!',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'everyone',\n",
    "                    'speech_text': 'Happy\\nChristmas to all, and to all a good\\nnight!',\n",
    "                    'speech_section_id': 1\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'task_2_responses': {\n",
    "        0: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Mum',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'spoken_words_only': 'Watch out Rosie! There\\'s a monster behind you.',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'The monster',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'spoken_words_only': 'I am going to eat you!',\n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "        },\n",
    "        1: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Hany',\n",
    "                    'recipient': 'Apatosaurus',\n",
    "                    'spoken_words_only': 'That’s a rhinoceros. Triceratops has got more horns.',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Harry',\n",
    "                    'recipient': 'Mum',\n",
    "                    'spoken_words_only': 'I want to save some animals. What can I do, Mum?',      \n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Sam',\n",
    "                    'recipient': 'Harry',\n",
    "                    'spoken_words_only': 'Tuh! What a waste of time!',\n",
    "                    'speech_section_id': 2\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        2: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'Reindeer',\n",
    "                    'spoken_words_only': 'Now, Dasher! now, Dancer! now, Prancer and Vixen! On Comet! on Cupid! on Donner and Blitzen! To the top of the porch, to the top of the wall, Now, dash away! Dash away! Dash away all!',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'everyone',\n",
    "                    'spoken_words_only': 'Happy Christmas to all, and to all a good night!',\n",
    "                    'speech_section_id': 1\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'task_3_characters': {\n",
    "        0: ['Rosie', 'Mum'],\n",
    "        1: ['Harry', 'Apatosaurus', 'Mum'],\n",
    "        2: ['Saint Nick', 'Reindeer']\n",
    "    },\n",
    "    'task_3_aliases': {\n",
    "        0: pd.DataFrame({\n",
    "            'alias': ['Monster'],\n",
    "            'character': ['Mum']\n",
    "        }).to_csv(),\n",
    "        1: pd.DataFrame({\n",
    "            'alias': ['Sam'],\n",
    "            'character': ['Mum']\n",
    "        }).to_csv(),\n",
    "        2: pd.DataFrame({\n",
    "            'alias': ['St. Nicholas'],\n",
    "            'character': ['Saint Nick']\n",
    "        }).to_csv(),\n",
    "    },\n",
    "    'task_3_responses': {\n",
    "        0: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Mum',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'speaker_matched': 'Mum',\n",
    "                    'recipient_matched': 'Rosie',\n",
    "#                     'spoken_words_only': 'Watch out Rosie! There\\'s a monster behind you.',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'The monster',\n",
    "                    'recipient': 'Rosie',\n",
    "                    'speaker_matched': 'Mum',\n",
    "                    'recipient_matched': 'Rosie',\n",
    "#                     'spoken_words_only': 'I am going to eat you!',\n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "        },\n",
    "        1: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'Hany',\n",
    "                    'recipient': 'Apatosaurus',\n",
    "                    'speaker_matched': 'Unknown',\n",
    "                    'recipient_matched': 'Apatosaurus',\n",
    "#                     'spoken_words_only': 'That’s a rhinoceros. Triceratops has got more horns.',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Harry',\n",
    "                    'recipient': 'Mum',\n",
    "                    'speaker_matched': 'Harry',\n",
    "                    'recipient_matched': 'Mum',\n",
    "#                     'spoken_words_only': 'I want to save some animals. What can I do, Mum?',      \n",
    "                    'speech_section_id': 1\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'Sam',\n",
    "                    'recipient': 'Harry',\n",
    "                    'speaker_matched': 'Mum',\n",
    "                    'recipient_matched': 'Harry',\n",
    "#                     'spoken_words_only': 'Tuh! What a waste of time!',\n",
    "                    'speech_section_id': 2\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        2: {\n",
    "            'speech_sections': [\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'Reindeer',\n",
    "                    'speaker_matched': 'Saint Nick',\n",
    "                    'recipient_matched': 'Reindeer',\n",
    "#                     'spoken_words_only': 'Now, Dasher! now, Dancer! now, Prancer and Vixen! On Comet! on Cupid! on Donner and Blitzen! To the top of the porch, to the top of the wall, Now, dash away! Dash away! Dash away all!',\n",
    "                    'speech_section_id': 0\n",
    "                },\n",
    "                {\n",
    "                    'speaker': 'St. Nicholas',\n",
    "                    'recipient': 'everyone',\n",
    "                    'speaker_matched': 'Saint Nick',\n",
    "                    'recipient_matched': 'The Reader',\n",
    "#                     'spoken_words_only': 'Happy Christmas to all, and to all a good night!',\n",
    "                    'speech_section_id': 1\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_response_schema = {\n",
    "    \"speech_sections\": {\n",
    "        \"speaker\": \"string\",\n",
    "        \"recipient\": \"string\",\n",
    "        \"speech_text\": \"string\",\n",
    "        \"speech_section_id\": \"integer\"\n",
    "    }\n",
    "}\n",
    "    \n",
    "task_1_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_1_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_input_schema = {\n",
    "    \"full_text\": \"string\"\n",
    "}\n",
    "    \n",
    "task_1_input_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_1_input_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_speech_marks(text):\n",
    "    new_text = text.replace('“', '\"').replace('”', '\"').replace('’', '\\'')\n",
    "    return new_text\n",
    "\n",
    "def discount_speech_marks(text, marks=['“', '\"', '”', '’', '\\'']):\n",
    "    \n",
    "    new_text = text\n",
    "    if text[0] in marks:\n",
    "        new_text = text[1:]\n",
    "    if new_text[-1] in marks:\n",
    "        new_text = new_text[:-1]\n",
    "    return new_text\n",
    "\n",
    "def remove_the(text):\n",
    "    new_text = text\n",
    "    if text[0:3].lower() == 'the':\n",
    "        new_text = text[3:].strip()\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def compare_strings(\n",
    "    string_1, string_2, \n",
    "    _case_sensitive=True, \n",
    "    _strip_whitespace=True, \n",
    "    _replace_speech_marks=True,\n",
    "    _discount_leading_trailing_marks=True,\n",
    "    _remove_leading_the=False\n",
    "):\n",
    "    \n",
    "    if _case_sensitive:\n",
    "        s_1 = string_1\n",
    "        s_2 = string_2\n",
    "    else:\n",
    "        s_1 = string_1.lower()\n",
    "        s_2 = string_2.lower()\n",
    "    \n",
    "    if _strip_whitespace:\n",
    "        s_1 = s_1.strip()\n",
    "        s_2 = s_2.strip()\n",
    "        \n",
    "    if _replace_speech_marks:\n",
    "        s_1 = replace_speech_marks(s_1)\n",
    "        s_2 = replace_speech_marks(s_2)\n",
    "        \n",
    "    if _discount_leading_trailing_marks:\n",
    "        s_1 = discount_speech_marks(s_1)\n",
    "        s_2 = discount_speech_marks(s_2)\n",
    "        \n",
    "    if _remove_leading_the:\n",
    "        s_1 = remove_the(s_1)\n",
    "        s_2 = remove_the(s_2)\n",
    "        \n",
    "    return s_1 == s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_1_responses'][test_id]['speech_sections']\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speech_text': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "        pass_flag = True\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_1_prompt_string(data, example_data):\n",
    "    \n",
    "    example_input_1 = example_data['task_1']['example_input_1']\n",
    "    example_output_1 = example_data['task_1']['example_output_1']\n",
    "#     example_input_2 = example_data['task_1']['example_input_2']\n",
    "#     example_output_2 = example_data['task_1']['example_output_2']\n",
    "    \n",
    "    return f\"\"\"\n",
    "        I will provide you below with the following data in JSON format: {task_1_input_schema_str}\n",
    "        \n",
    "        The full_text is text of a children's book as a single string. \n",
    "\n",
    "        Using the full_text, please identify any sections of direct speech, and for each one tell me who is the speaker and who is the recipient.\n",
    "        Remember that a section of direct speech can be broken up by information about who is speaking and that this break could even span \n",
    "        multiple lines in some cases. In these cases, please treat this as a single section of speech.\n",
    "        \n",
    "        For example, the input: {example_input_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Use '\\n' as the newline character and reproduce these as they occur.\n",
    "        Reproduce all punctuation as it is written.    \n",
    "            \n",
    "        Provide the results in JSON format with the following fields: speaker, recipient, speech_text, speech_section_id\n",
    "        (where speech_section_id counts the number of sections of speech in this book)\n",
    "\n",
    "        Data: {data}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_1_system_prompt(input_schema, output_schema):\n",
    "    return f\"\"\"\n",
    "            You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "            You will recieve data in JSON format with the following schema: {input_schema}\n",
    "            Output your response in JSON format using the following schema: {output_schema}.\n",
    "            Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(full_text, client, seed=42):\n",
    "    \n",
    "    prompt_string = get_task_1_prompt_string(\n",
    "            {'full_text': full_text}, \n",
    "            example_data\n",
    "        )\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_task_1_system_prompt(task_1_input_schema_str, task_1_response_schema_str)},\n",
    "            {\"role\": \"user\", \"content\": r\"{}\".format(prompt_string)}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return completion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "        \n",
    "        completion = run_task_1(test_data['strings'][test_id], client=client)\n",
    "        \n",
    "        if run_task_1_test_i(test_id, test_data, completion, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 5\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 6\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 7\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 8\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 9\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 10\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 11\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 12\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 13\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 14\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 15\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 16\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 17\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 18\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 19\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 20\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(20):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_1_tests(test_data)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: recognising pre-defined sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: pulling out spoken words only.\n",
    "\n",
    "#### TODO:\n",
    "- refactor run_test_i method\n",
    "- move schemas and test and example data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_response_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "task_2_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_2_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_task_2_prompt_string(example_data):\n",
    "    \n",
    "#     example_input_1 = example_data['task_2']['example_input_1']\n",
    "#     example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "#     return f\"\"\"\n",
    "#         For the speech sections that you just found, please pull out the words that are direct speech\n",
    "#         and add them as a field in the JSON output called spoken_words_only.\n",
    "        \n",
    "#         You will need to remove all non-speech words such as 'she said' \n",
    "#         and anything else that is not direct speech. \n",
    "        \n",
    "#         Do not include indirect speech.\n",
    "        \n",
    "#         For example, these speech sections: {example_input_1}\n",
    "#         Should produce the following output: {example_output_1}\n",
    "        \n",
    "#         Reproduce all punctuation as it is written.    \n",
    "#         Provide your response in JSON.\n",
    "#     \"\"\"\n",
    "# def get_task_2_prompt_string(example_data):\n",
    "    \n",
    "#     example_input_1 = example_data['task_2']['example_input_1']\n",
    "#     example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "#     return f\"\"\"\n",
    "#         For the speech sections that you just found, please look at the speech_text fields in the JSON.\n",
    "        \n",
    "#         First, replace all newline characters with a single space.\n",
    "#         Then, remove all words that are not direct speech. Keep only the words that are actually spoken\n",
    "#         and add them as a field in the JSON output called 'spoken_words_only'.\n",
    "        \n",
    "#         You will need to remove all non-speech words such as 'she said' \n",
    "#         and anything else that is not direct speech. \n",
    "        \n",
    "#         Do not include indirect speech.\n",
    "        \n",
    "#         For example, these speech sections: {example_input_1}\n",
    "#         Should produce the following output: {example_output_1}\n",
    "        \n",
    "#         Reproduce all punctuation as it is written.    \n",
    "#         Provide your response in JSON.\n",
    "#     \"\"\"\n",
    "def get_task_2_prompt_string(example_data, task_1_response):\n",
    "    \n",
    "    example_input_1 = example_data['task_2']['example_input_1']\n",
    "    example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "    return f\"\"\"\n",
    "        Here are the speech sections that you just found: {task_1_response}. \n",
    "        \n",
    "        Look at the speech_text fields.\n",
    "        Extract only the words that are direct speech, omitting any words that are not actually spoken.\n",
    "        Add these spoken words as a field in the JSON output called 'spoken_words_only'.\n",
    "        \n",
    "        For example, these speech sections: {example_input_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Remove all speech marks and add full stops where needed, otherwise produce all punctuation as it is written. Replace each newline character '\\n' with a sinlge space.   \n",
    "        Provide your response in JSON.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_2_system_prompt(_task_2_input_schema, _task_2_response_schema):\n",
    "#     return f\"Please use the following schema for your JSON response: {_task_2_response_schema}. Remove all newline characters in your output with a single space.\"\n",
    "    return f\"\"\"\n",
    "        You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "        You will recieve data in JSON format with the following schema: {_task_2_input_schema}\n",
    "        Use the following schema for your JSON response: {_task_2_response_schema}.\n",
    "        Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(full_text, client, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_1_completion is None:\n",
    "        task_1_completion = run_task_1(full_text, client)\n",
    "        \n",
    "    task_1_prompt_string = get_task_1_prompt_string(\n",
    "        {'full_text': full_text}, \n",
    "        example_data\n",
    "    )\n",
    "    \n",
    "    task_2_prompt_string = get_task_2_prompt_string(\n",
    "        example_data,\n",
    "        task_1_response=json.loads(task_1_completion.choices[0].message.content)\n",
    "    )\n",
    "    \n",
    "    task_2_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "#            {\n",
    "#                \"role\": \"system\", \n",
    "#                \"content\": get_task_1_system_prompt(task_1_input_schema_str, task_1_response_schema_str)\n",
    "#            },\n",
    "#            {\n",
    "#                \"role\": \n",
    "#                \"user\", \"content\": r\"{}\".format(task_1_prompt_string)\n",
    "#            },\n",
    "#            {\n",
    "#                \"role\": \"assistant\", \n",
    "#                \"content\": task_1_completion.choices[0].message.content\n",
    "#            },\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_2_system_prompt(task_1_response_schema_str, task_2_response_schema_str)\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_2_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=156, prompt_tokens=666, total_tokens=822)"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"That’s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_2_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'spoken_words_only': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, completion_2 = run_task_2(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client\n",
    "        )\n",
    "           \n",
    "        if run_task_2_test_i(test_id, test_data, completion_2, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_2_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: mappnig character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_response_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"speaker_matched\": \"string\",\n",
    "    \"recipient_matched\": \"string\",\n",
    "#     \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "task_3_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_3_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_prompt_string(example_data, task_2_response, characters, aliases):\n",
    "    \n",
    "    example_input_1 = example_data['task_3']['example_input_1']\n",
    "    example_characters_1 = example_data['task_3']['example_characters_1']\n",
    "    example_aliases_1 = example_data['task_3']['example_aliases_1']\n",
    "    example_output_1 = example_data['task_3']['example_output_1']\n",
    "    \n",
    "    if not isinstance(characters, list):\n",
    "        character_list = list(characters.name)\n",
    "    else:\n",
    "        character_list = characters\n",
    "    if not isinstance(aliases, str):\n",
    "        alias_csv = aliases[['alias', 'character']].to_csv()\n",
    "    else:\n",
    "        alias_csv = aliases\n",
    "    \n",
    "    return f\"\"\"\n",
    "        Here are the speech sections that you just found: {task_2_response}. \n",
    "        \n",
    "        Look at the speakers and recipients. I want you to match these to pre-defined character names,\n",
    "        and to store the matched name as new fileds called speaker_matched and recipient_matched in the JSON ouput.\n",
    "        \n",
    "        Here is a list of character names: {characters}\n",
    "        If you find the speaker or recipient in this list (or a close enough match, including typos), please\n",
    "        use the found name as the match value.\n",
    "        If there is no match in the list, look for the name in the 'alias' column of the following\n",
    "        csv lookup table: {alias_csv}\n",
    "        If you find the name in the 'alias' column, take the corresponding value from the 'character' column\n",
    "        as the match.\n",
    "        If you cannot find a name in either the characters or aliases, record the match value as 'Unknown'.\n",
    "        If the recipient appears to be the reader or general audience, record the match value as 'The Reader'.\n",
    "        If the speaker is talking to themself, record the match value as 'Self'.\n",
    "        \n",
    "        For example, these speech sections: {example_input_1}\n",
    "        with this character list: {example_characters_1}\n",
    "        and this alias lookup table: {example_aliases_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Provide your response in JSON.\n",
    "        Do not change the value of the speaker, recipient fields. Do not include the spoken_words_only field.   \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_system_prompt(_task_3_input_schema, _task_3_response_schema):\n",
    "#     return f\"Please use the following schema for your JSON response: {_task_2_response_schema}. Remove all newline characters in your output with a single space.\"\n",
    "    return f\"\"\"\n",
    "        You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "        You will recieve data in JSON format with the following schema: {_task_3_input_schema}\n",
    "        Use the following schema for your JSON response: {_task_3_response_schema}.\n",
    "        Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(full_text, client, characters, aliases, task_2_completion=None, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_2_completion is None:\n",
    "        task_1_completion, task_2_completion = run_task_2(full_text, client)\n",
    "        \n",
    "    \n",
    "    task_3_prompt_string = get_task_3_prompt_string(\n",
    "        example_data,\n",
    "        task_2_response=json.loads(task_2_completion.choices[0].message.content),\n",
    "        characters=characters,\n",
    "        aliases=aliases\n",
    "    )\n",
    "    \n",
    "    task_3_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_3_system_prompt(task_2_response_schema_str, task_3_response_schema_str)\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_3_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion, task_3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client,\n",
    "    characters=test_data['task_3_characters'][test_id],\n",
    "    aliases=test_data['task_3_aliases'][test_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=215, prompt_tokens=928, total_tokens=1143)"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"speaker_matched\": \"Unknown\",\n",
      "      \"recipient_matched\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"That’s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"speaker_matched\": \"Harry\",\n",
      "      \"recipient_matched\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"speaker_matched\": \"Mum\",\n",
      "      \"recipient_matched\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_3_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speaker_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "        'recipient_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "#         'spoken_words_only': {\n",
    "#             'case_sensitive': True,\n",
    "#             'remove_leading_the': False\n",
    "#         },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, _, completion_3 = run_task_3(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client,\n",
    "            characters=test_data['task_3_characters'][test_id],\n",
    "            aliases=test_data['task_3_aliases'][test_id]\n",
    "        )\n",
    "           \n",
    "        if run_task_3_test_i(test_id, test_data, completion_3, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_3_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for corpus\n",
    "\n",
    "Now that our prompts are passing all tests, we run the method for all books in the corpus and save the results to disk....\n",
    "\n",
    "# TODO:\n",
    "- add a 'self' match example to data (still using himself)\n",
    "- check Noi and 'his dad' - shouldn't it be Dad? (The Storm Whale In Winter)\n",
    "- add Narrator handling/example (e.g. There's A Monster In Your Book)\n",
    "- add a flag for if it is a character match or something else ('Everyone' Narrator' etc!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n",
      "Book:  Once Upon A Unicorn Horn\n",
      "Book:  Mind Your Manners\n",
      "Book:  The Princess and the Wizard\n",
      "Book:  Kipper's Toybox\n",
      "Book:  Oi Frog!\n",
      "Book:  Elmer and the Lost Teddy\n",
      "Book:  The Hungry Caterpillar\n",
      "Book:  A Squash and a Squeeze\n",
      "Book:  Keith The Cat With The Magic Hat\n",
      "Book:  Santa is Coming to Devon\n",
      "Book:  The Enormous Crocodile\n",
      "Book:  Harry and the Dinosaurs Go Wild\n",
      "Book:  Open Very Carefully, A Book With Bite!\n",
      "Book:  The Most Wonderful Gift In The World\n",
      "Book:  Elmer and Grandpa Eldo\n",
      "Book:  Tabby McTat\n",
      "Book:  Harry and the Dinosaurs at the Museum\n",
      "Book:  The Hedgehog's Balloon\n",
      "Book:  Jasper's Jungle Journey\n",
      "Book:  The Owl Who Was Afraid Of The Dark\n",
      "Book:  The Cross Rabbit\n",
      "Book:  Shark In The Dark\n",
      "Book:  A Thing Called Snow\n",
      "Book:  Yoga Babies\n",
      "Book:  The Way Home For Wolf\n",
      "Book:  Elmer and Wilbur\n",
      "Book:  One Starry Night\n",
      "Book:  I Need A Wee\n",
      "Book:  Harry and the Dinosaurs say Raahh!\n",
      "Book:  An Alphabet Of Stories\n",
      "Book:  The Owl's Lesson\n",
      "Book:  The Very Lazy Ladybird\n",
      "Book:  The Dinosaur Department Store\n",
      "Book:  The Fox's Hiccups\n",
      "Book:  You Choose\n",
      "Book:  Whatever Next!\n",
      "Book:  Cave Baby\n",
      "Book:  The Rescue Party\n",
      "Book:  Elmer and the Stranger\n",
      "Book:  Dinosaurs Love Underpants\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': 0,\n",
    "    'c1_completion_tokens': [],\n",
    "    'c1_prompt_tokens': [],\n",
    "    'c1_total_tokens': [],\n",
    "    'c1_system_fingerprint': [],\n",
    "    'c2_completion_tokens': [],\n",
    "    'c2_prompt_tokens': [],\n",
    "    'c2_total_tokens': [],\n",
    "    'c2_system_fingerprint': [],\n",
    "    'c3_completion_tokens': [],\n",
    "    'c3_prompt_tokens': [],\n",
    "    'c3_total_tokens': [],\n",
    "    'c3_system_fingerprint': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "c1_results_dict = {}\n",
    "c2_results_dict = {}\n",
    "c3_results_dict = {}\n",
    "\n",
    "# for book_id in range(len(df)):\n",
    "for book_id in range(50):\n",
    "    title = df.iloc[book_id].Title\n",
    "    print(\"Book: \", title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    completion_1, completion_2, completion_3 = run_task_3(\n",
    "        full_text=df.iloc[book_id].Text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title]\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion_3.choices[0].message.content)\n",
    "    \n",
    "    book_df['c1_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c1_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c1_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c1_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c2_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c2_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c2_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c2_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c3_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c3_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c3_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c3_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    \n",
    "    book_df['title'].append(title)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'] += len(json_response['speech_sections'])\n",
    "    \n",
    "    c3_results_dict[title] = json_response\n",
    "    \n",
    "    c1_results_dict[title] = json.loads(completion_1.choices[0].message.content)\n",
    "    c2_results_dict[title] = json.loads(completion_2.choices[0].message.content)\n",
    "    \n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Night Before Christmas\n",
      "Sugarlump and the Unicorn\n",
      "The Gruffalo\n",
      "The Monstrous Tale of Celery Crumble\n",
      "Peace at Last\n",
      "Sing A Song Of Bottoms\n",
      "Barry The Fish With Fingers\n",
      "The Troll\n",
      "The Storm Whale In Winter\n",
      "There's A Monster In Your Book\n",
      "Once Upon A Unicorn Horn\n",
      "Mind Your Manners\n",
      "The Princess and the Wizard\n",
      "Kipper's Toybox\n",
      "Oi Frog!\n",
      "Elmer and the Lost Teddy\n",
      "The Hungry Caterpillar\n",
      "A Squash and a Squeeze\n",
      "Keith The Cat With The Magic Hat\n",
      "Santa is Coming to Devon\n",
      "The Enormous Crocodile\n",
      "Harry and the Dinosaurs Go Wild\n",
      "Open Very Carefully, A Book With Bite!\n",
      "The Most Wonderful Gift In The World\n",
      "Elmer and Grandpa Eldo\n",
      "Tabby McTat\n",
      "Harry and the Dinosaurs at the Museum\n",
      "The Hedgehog's Balloon\n",
      "Jasper's Jungle Journey\n",
      "The Owl Who Was Afraid Of The Dark\n",
      "The Cross Rabbit\n",
      "Shark In The Dark\n",
      "A Thing Called Snow\n",
      "Yoga Babies\n",
      "The Way Home For Wolf\n",
      "Elmer and Wilbur\n",
      "One Starry Night\n",
      "I Need A Wee\n",
      "Harry and the Dinosaurs say Raahh!\n",
      "An Alphabet Of Stories\n",
      "The Owl's Lesson\n",
      "The Very Lazy Ladybird\n",
      "The Dinosaur Department Store\n",
      "The Fox's Hiccups\n",
      "You Choose\n",
      "Whatever Next!\n",
      "Cave Baby\n",
      "The Rescue Party\n",
      "Elmer and the Stranger\n",
      "Dinosaurs Love Underpants\n"
     ]
    }
   ],
   "source": [
    "# Convert results dicts to dataframe of all speech sections and save to disk:\n",
    "\n",
    "all_speech_sections = {\n",
    "    'book': [],\n",
    "    'speech_section_id': [], # speech section id within book\n",
    "    'speaker': [],\n",
    "    'recipient': [],\n",
    "    'speaker_matched': [],\n",
    "    'recipient_matched': [],\n",
    "    'speech_text': [],\n",
    "    'spoken_words_only': [],\n",
    "    'spoken_word_count': []\n",
    "}\n",
    "\n",
    "for book in c3_results_dict.keys():\n",
    "    print(book)\n",
    "    for si, section in enumerate(c3_results_dict[book]['speech_sections']):\n",
    "        all_speech_sections['book'].append(book)\n",
    "        for key in all_speech_sections.keys():\n",
    "            if key not in ['book', 'spoken_word_count', 'speech_text', 'spoken_words_only']:\n",
    "                all_speech_sections[key].append(section[key])\n",
    "        \n",
    "        all_speech_sections['speech_text'].append(c1_results_dict[book]['speech_sections'][si]['speech_text'])\n",
    "        all_speech_sections['spoken_words_only'].append(c2_results_dict[book]['speech_sections'][si]['spoken_words_only'])\n",
    "        all_speech_sections['spoken_word_count'].append(len(c2_results_dict[book]['speech_sections'][si]['spoken_words_only']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections = pd.DataFrame(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Happy\\nChristmas to all, and to all a good\\nni...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! came a voice, and there stood a beast Wi...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Elmer and the Stranger</td>\n",
       "      <td>37</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Lion and Tiger</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Lion and Tiger</td>\n",
       "      <td>Yes. And now we’re all... aah...</td>\n",
       "      <td>Yes. And now we’re all... aah...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Elmer and the Stranger</td>\n",
       "      <td>38</td>\n",
       "      <td>Elmer, Lion, and Tiger</td>\n",
       "      <td>each other</td>\n",
       "      <td>Elmer, Lion, and Tiger</td>\n",
       "      <td>each other</td>\n",
       "      <td>Friends!</td>\n",
       "      <td>Friends!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>0</td>\n",
       "      <td>T-rex</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Tyrannosaurus rex</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>“I don’t\\nwant to eat you up, I want your\\nund...</td>\n",
       "      <td>I don’t want to eat you up, I want your underp...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>1</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>each other</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Self</td>\n",
       "      <td>“We’ve too few knickers to go around!” The\\nca...</td>\n",
       "      <td>We’ve too few knickers to go around! The cavem...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>2</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>each other</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Self</td>\n",
       "      <td>“Hooray! Our biggest enemy,\\nIs now at last no...</td>\n",
       "      <td>Hooray! Our biggest enemy, Is now at last no m...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           book  speech_section_id                 speaker  \\\n",
       "0    The Night Before Christmas                  0            St. Nicholas   \n",
       "1    The Night Before Christmas                  1            St. Nicholas   \n",
       "2     Sugarlump and the Unicorn                  0               Sugarlump   \n",
       "3     Sugarlump and the Unicorn                  1               Sugarlump   \n",
       "4     Sugarlump and the Unicorn                  2                 unicorn   \n",
       "..                          ...                ...                     ...   \n",
       "806      Elmer and the Stranger                 37                   Elmer   \n",
       "807      Elmer and the Stranger                 38  Elmer, Lion, and Tiger   \n",
       "808   Dinosaurs Love Underpants                  0                   T-rex   \n",
       "809   Dinosaurs Love Underpants                  1                 cavemen   \n",
       "810   Dinosaurs Love Underpants                  2                 cavemen   \n",
       "\n",
       "          recipient         speaker_matched recipient_matched  \\\n",
       "0          Reindeer            St. Nicholas           Unknown   \n",
       "1          Everyone            St. Nicholas        The Reader   \n",
       "2           himself               Sugarlump              Self   \n",
       "3           himself               Sugarlump              Self   \n",
       "4         Sugarlump                 unicorn         Sugarlump   \n",
       "..              ...                     ...               ...   \n",
       "806  Lion and Tiger                   Elmer    Lion and Tiger   \n",
       "807      each other  Elmer, Lion, and Tiger        each other   \n",
       "808         cavemen       Tyrannosaurus rex           cavemen   \n",
       "809      each other                 cavemen              Self   \n",
       "810      each other                 cavemen              Self   \n",
       "\n",
       "                                           speech_text  \\\n",
       "0    Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...   \n",
       "1    Happy\\nChristmas to all, and to all a good\\nni...   \n",
       "2    \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3    \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4    \"Done!\" came a voice, and there stood a beast\\...   \n",
       "..                                                 ...   \n",
       "806                   Yes. And now we’re all... aah...   \n",
       "807                                           Friends!   \n",
       "808  “I don’t\\nwant to eat you up, I want your\\nund...   \n",
       "809  “We’ve too few knickers to go around!” The\\nca...   \n",
       "810  “Hooray! Our biggest enemy,\\nIs now at last no...   \n",
       "\n",
       "                                     spoken_words_only  spoken_word_count  \n",
       "0    Now, Dasher! now, Dancer! now, Prancer and Vix...                183  \n",
       "1     Happy Christmas to all, and to all a good night!                 48  \n",
       "2    Here in the children's bedroom Is where I want...                106  \n",
       "3    Oh to be out in the big wide world! I wish I c...                 65  \n",
       "4    Done! came a voice, and there stood a beast Wi...                128  \n",
       "..                                                 ...                ...  \n",
       "806                   Yes. And now we’re all... aah...                 32  \n",
       "807                                           Friends!                  8  \n",
       "808  I don’t want to eat you up, I want your underp...                 51  \n",
       "809  We’ve too few knickers to go around! The cavem...                123  \n",
       "810  Hooray! Our biggest enemy, Is now at last no m...                 50  \n",
       "\n",
       "[811 rows x 9 columns]"
      ]
     },
     "execution_count": 1008,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = all_speech_sections.merge(characters, how='left', left_on=['speaker_matched', 'book'], right_on=['name', 'book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23057953144266338"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "187/811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "['The Night Before Christmas' 'Sugarlump and the Unicorn' 'The Gruffalo'\n",
      " 'The Monstrous Tale of Celery Crumble' 'Peace at Last'\n",
      " 'Sing A Song Of Bottoms' 'The Troll' 'The Storm Whale In Winter'\n",
      " \"There's A Monster In Your Book\" 'Once Upon A Unicorn Horn'\n",
      " 'Mind Your Manners' 'The Princess and the Wizard' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Open Very Carefully, A Book With Bite!'\n",
      " 'The Most Wonderful Gift In The World' 'Tabby McTat'\n",
      " 'Harry and the Dinosaurs at the Museum' \"The Hedgehog's Balloon\"\n",
      " 'The Owl Who Was Afraid Of The Dark' 'The Cross Rabbit'\n",
      " 'Shark In The Dark' 'A Thing Called Snow' 'The Way Home For Wolf'\n",
      " 'I Need A Wee' 'Harry and the Dinosaurs say Raahh!'\n",
      " 'An Alphabet Of Stories' \"The Owl's Lesson\"\n",
      " 'The Dinosaur Department Store' \"The Fox's Hiccups\" 'Cave Baby'\n",
      " 'The Rescue Party' 'Elmer and the Stranger' 'Dinosaurs Love Underpants']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_recipient.isna()].book.unique()))\n",
    "print(speakers[speakers.name_recipient.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "['Sing A Song Of Bottoms' 'The Troll' \"There's A Monster In Your Book\"\n",
      " 'Once Upon A Unicorn Horn' 'Mind Your Manners' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Open Very Carefully, A Book With Bite!'\n",
      " 'The Most Wonderful Gift In The World' 'Tabby McTat'\n",
      " 'Harry and the Dinosaurs at the Museum' 'The Cross Rabbit'\n",
      " 'A Thing Called Snow' 'I Need A Wee' 'Harry and the Dinosaurs say Raahh!'\n",
      " 'An Alphabet Of Stories' \"The Owl's Lesson\"\n",
      " 'The Dinosaur Department Store' 'Cave Baby' 'The Rescue Party'\n",
      " 'Elmer and the Stranger']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_speaker.isna()].book.unique()))\n",
    "print(speakers[speakers.name_speaker.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = speakers.merge(characters, how='left', left_on=['recipient_matched', 'book'], right_on=['name', 'book'], suffixes=['_speaker', '_recipient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Happy\\nChristmas to all, and to all a good\\nni...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>65</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! came a voice, and there stood a beast Wi...</td>\n",
       "      <td>128</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Elmer and the Stranger</td>\n",
       "      <td>37</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Lion and Tiger</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Lion and Tiger</td>\n",
       "      <td>Yes. And now we’re all... aah...</td>\n",
       "      <td>Yes. And now we’re all... aah...</td>\n",
       "      <td>32</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Elmer and the Stranger</td>\n",
       "      <td>38</td>\n",
       "      <td>Elmer, Lion, and Tiger</td>\n",
       "      <td>each other</td>\n",
       "      <td>Elmer, Lion, and Tiger</td>\n",
       "      <td>each other</td>\n",
       "      <td>Friends!</td>\n",
       "      <td>Friends!</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>0</td>\n",
       "      <td>T-rex</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Tyrannosaurus rex</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>“I don’t\\nwant to eat you up, I want your\\nund...</td>\n",
       "      <td>I don’t want to eat you up, I want your underp...</td>\n",
       "      <td>51</td>\n",
       "      <td>Tyrannosaurus rex</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>1</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>each other</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Self</td>\n",
       "      <td>“We’ve too few knickers to go around!” The\\nca...</td>\n",
       "      <td>We’ve too few knickers to go around! The cavem...</td>\n",
       "      <td>123</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Dinosaurs Love Underpants</td>\n",
       "      <td>2</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>each other</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>Self</td>\n",
       "      <td>“Hooray! Our biggest enemy,\\nIs now at last no...</td>\n",
       "      <td>Hooray! Our biggest enemy, Is now at last no m...</td>\n",
       "      <td>50</td>\n",
       "      <td>cavemen</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           book  speech_section_id                 speaker  \\\n",
       "0    The Night Before Christmas                  0            St. Nicholas   \n",
       "1    The Night Before Christmas                  1            St. Nicholas   \n",
       "2     Sugarlump and the Unicorn                  0               Sugarlump   \n",
       "3     Sugarlump and the Unicorn                  1               Sugarlump   \n",
       "4     Sugarlump and the Unicorn                  2                 unicorn   \n",
       "..                          ...                ...                     ...   \n",
       "806      Elmer and the Stranger                 37                   Elmer   \n",
       "807      Elmer and the Stranger                 38  Elmer, Lion, and Tiger   \n",
       "808   Dinosaurs Love Underpants                  0                   T-rex   \n",
       "809   Dinosaurs Love Underpants                  1                 cavemen   \n",
       "810   Dinosaurs Love Underpants                  2                 cavemen   \n",
       "\n",
       "          recipient         speaker_matched recipient_matched  \\\n",
       "0          Reindeer            St. Nicholas           Unknown   \n",
       "1          Everyone            St. Nicholas        The Reader   \n",
       "2           himself               Sugarlump              Self   \n",
       "3           himself               Sugarlump              Self   \n",
       "4         Sugarlump                 unicorn         Sugarlump   \n",
       "..              ...                     ...               ...   \n",
       "806  Lion and Tiger                   Elmer    Lion and Tiger   \n",
       "807      each other  Elmer, Lion, and Tiger        each other   \n",
       "808         cavemen       Tyrannosaurus rex           cavemen   \n",
       "809      each other                 cavemen              Self   \n",
       "810      each other                 cavemen              Self   \n",
       "\n",
       "                                           speech_text  \\\n",
       "0    Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...   \n",
       "1    Happy\\nChristmas to all, and to all a good\\nni...   \n",
       "2    \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3    \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4    \"Done!\" came a voice, and there stood a beast\\...   \n",
       "..                                                 ...   \n",
       "806                   Yes. And now we’re all... aah...   \n",
       "807                                           Friends!   \n",
       "808  “I don’t\\nwant to eat you up, I want your\\nund...   \n",
       "809  “We’ve too few knickers to go around!” The\\nca...   \n",
       "810  “Hooray! Our biggest enemy,\\nIs now at last no...   \n",
       "\n",
       "                                     spoken_words_only  spoken_word_count  \\\n",
       "0    Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1     Happy Christmas to all, and to all a good night!                 48   \n",
       "2    Here in the children's bedroom Is where I want...                106   \n",
       "3    Oh to be out in the big wide world! I wish I c...                 65   \n",
       "4    Done! came a voice, and there stood a beast Wi...                128   \n",
       "..                                                 ...                ...   \n",
       "806                   Yes. And now we’re all... aah...                 32   \n",
       "807                                           Friends!                  8   \n",
       "808  I don’t want to eat you up, I want your underp...                 51   \n",
       "809  We’ve too few knickers to go around! The cavem...                123   \n",
       "810  Hooray! Our biggest enemy, Is now at last no m...                 50   \n",
       "\n",
       "          name_speaker gender_speaker human_speaker  alias_count_speaker  \\\n",
       "0         St. Nicholas              M             H                  1.0   \n",
       "1         St. Nicholas              M             H                  1.0   \n",
       "2            Sugarlump              M            NH                  0.0   \n",
       "3            Sugarlump              M            NH                  0.0   \n",
       "4              unicorn              F            NH                  0.0   \n",
       "..                 ...            ...           ...                  ...   \n",
       "806              Elmer              M            NH                  0.0   \n",
       "807                NaN            NaN           NaN                  NaN   \n",
       "808  Tyrannosaurus rex              M            NH                  1.0   \n",
       "809            cavemen             M              H                  0.0   \n",
       "810            cavemen             M              H                  0.0   \n",
       "\n",
       "    name_recipient gender_recipient human_recipient  alias_count_recipient  \n",
       "0              NaN              NaN             NaN                    NaN  \n",
       "1              NaN              NaN             NaN                    NaN  \n",
       "2              NaN              NaN             NaN                    NaN  \n",
       "3              NaN              NaN             NaN                    NaN  \n",
       "4        Sugarlump                M              NH                    0.0  \n",
       "..             ...              ...             ...                    ...  \n",
       "806            NaN              NaN             NaN                    NaN  \n",
       "807            NaN              NaN             NaN                    NaN  \n",
       "808        cavemen               M                H                    0.0  \n",
       "809            NaN              NaN             NaN                    NaN  \n",
       "810            NaN              NaN             NaN                    NaN  \n",
       "\n",
       "[811 rows x 17 columns]"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_character_count = sum(characters.gender == 'F')\n",
    "male_character_count = sum(characters.gender == 'M')\n",
    "ngs_character_count = sum(characters.gender == 'NGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_word_count = speakers[speakers.gender_speaker == 'M'].spoken_word_count.sum()\n",
    "female_spoken_word_count = speakers[speakers.gender_speaker == 'F'].spoken_word_count.sum()\n",
    "ngs_spoken_word_count = speakers[speakers.gender_speaker == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.18846153846154"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.43558282208589"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.39605734767025"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_spoken_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269230769230769"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_received_word_count = speakers[speakers.gender_recipient == 'M'].spoken_word_count.sum()\n",
    "female_received_word_count = speakers[speakers.gender_recipient == 'F'].spoken_word_count.sum()\n",
    "ngs_received_word_count = speakers[speakers.gender_recipient == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.03846153846154"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_received_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.423312883435583"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_received_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.24731182795699"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_received_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speech_sections = len(speakers[speakers.gender_speaker == 'M'])\n",
    "female_speech_sections = len(speakers[speakers.gender_speaker == 'F'])\n",
    "ngs_speech_sections = len(speakers[speakers.gender_speaker == 'NGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211538461538461"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588957055214724"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22939068100358423"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mum</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mum</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mummy</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Granny</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinderella</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Bear</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nan</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldilocks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow White</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Bird</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheep</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Griselda</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book  gender  human  alias_count\n",
       "name                                        \n",
       "Mum           18      18     18           18\n",
       "mum           10      10     10           10\n",
       "Mummy          8       8      8            8\n",
       "Sam            7       7      7            7\n",
       "Granny         5       5      5            5\n",
       "mother         5       5      5            5\n",
       "Cinderella     5       5      5            5\n",
       "Mary           5       5      5            5\n",
       "girl           5       5      5            5\n",
       "cow            5       5      5            5\n",
       "I              4       4      4            4\n",
       "Mrs Bear       4       4      4            4\n",
       "Nan            4       4      4            4\n",
       "Goldilocks     4       4      4            4\n",
       "hen            4       4      4            4\n",
       "Snow White     3       3      3            3\n",
       "Miss Bird      3       3      3            3\n",
       "granny         3       3      3            3\n",
       "sheep          3       3      3            3\n",
       "Griselda       3       3      3            3"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.gender == 'F'].groupby('name').agg('count').sort_values('book', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cells beyond this point were removed - they were just exploratory. Check legacy branch for content if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
