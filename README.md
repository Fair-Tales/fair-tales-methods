# fair-tales-methods
Development and usage of analytic methods for Fair Tales project.

This methodology showcases the use of GPT-4o for complex NLP via robust iterative prompt development (with in-context learning), unit testing and manual validation.

We would like to draw your attention to the following key files:
* The script that was used to produce the results (language analysis) included in the book chapter can be found [here](https://github.com/Fair-Tales/fair-tales-methods/blob/main/vocabulary_analysis.ipynb)
* The summary statistics for the character database were produced by [this](https://github.com/Fair-Tales/fair-tales-methods/blob/main/summary_stats_final.ipynb) script.
* The prompt strings, data schemas and unit test cases are located in the [openai_api](https://github.com/Fair-Tales/fair-tales-methods/tree/main/openai_api) drectory.
* The scripts that were used to collect manual validation input for the sentence detection and general GPT-4o results are [here](https://github.com/Fair-Tales/fair-tales-methods/blob/main/speech_detection_validation_gpt4o.ipynb!) and [here](https://github.com/Fair-Tales/fair-tales-methods/blob/main/manual_validation_gpt4o.ipynb!) respectively.
* The script for running the full set of tasks with GPT-4o across the entrie corpus is provided [here](https://github.com/Fair-Tales/fair-tales-methods/blob/main/run_gpt4o_tasks_final.ipynb!). 

A few comments on our methodology:
- Each subtask is unit tested (Daka & Fraser, 2014) separately during prompt development to ensure consistency in performance.
- During prompt development we tested the pipeline on subsets of the dataset and observed any outputs that were incorrect. These were usually edge cases or cases that were linguistically more complex. Manually constructed examples were then added to the example set to be included in the prompt for the relevant task. For example, GPT-4o initially struggled to correctly attribute sections of speech that were broken by a non-speech clause, such as: ```“I wasn’t aware,” she complained, “that this was the same speech section.”``` Inclusion of a single in-context example of this type of speech clause resulted in correct speaker attribution and full extraction the spoken words for all subsequent examples tested.
- Unlike a conventional machine learning methodology, where a sample of held out data is used to estimate the generalisation performance of a model to unseen data, we used the full corpus during the prompt development process and the validation data was sampled from the full corpus. This approach aimed to achieve the best possible performance across the corpus, to ensure confidence in the downstream linguistic analysis. Therefore, we acknowledge that our pipeline is likely overfitted and we cannot say how well it would perform if applied directly to another dataset
- We would expect around 4.4% (570 sentences) of all speech in the corpus to be undetected. Validation revealed that indirect speech was uncommon, appearing in 1.2% of sentences, and direct speech constitutes a large part of these books, appearing in 42% of sentences. 
- An important consideration is context length, which is the total length of a single ‘conversation’ that the model can have. For example, GPT-4o has a context length of 128k tokens and a limit of 4,096 tokens for a single response. Most of our books were short enough to be processed fully in a single context window, but several did require splitting into multiple batches. This would be become an important consideration when working with longer texts as would prompt conciseness and cost, as LLMs are often pay-per-token. We did not optimise for conciseness. Running our pipeline on the whole corpus cost around $12, and we spent around 3 times this amount during development. As data volume increases, free and open-source LLMs would become more attractive. 
