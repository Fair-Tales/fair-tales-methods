{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare text data by parsing the book pdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_to_exclude = []\n",
    "labels = pd.read_excel('./Book-List-Final-NONA.xlsx', sheet_name='Sheet1')\n",
    "labels = labels.rename(columns={'Author ': 'Author'})\n",
    "labels = labels.loc[~labels.Title.isin(books_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../text_pdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "def grab_text(title, labels):\n",
    "    \n",
    "    start = labels.loc[labels.Title==title]['Starting Page']\n",
    "    if len(start)==0:\n",
    "        print(title, \"no start\")\n",
    "        start = 0\n",
    "    else:\n",
    "        start = start.values[0]\n",
    "    end = labels.loc[labels.Title==title]['Ending Page']\n",
    "    if len(end)==0:\n",
    "        print(title, \"no end\")\n",
    "        end = 0\n",
    "    else:\n",
    "        end = end.values[0]\n",
    "    \n",
    "    title = title + '.pdf'\n",
    "    all_text = ''\n",
    "    with pdfplumber.open(title) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            if i+1 >= start and i < end:\n",
    "                single_page_text = page.extract_text()\n",
    "\n",
    "                if single_page_text is not None:\n",
    "                    all_text = all_text + '\\n' + single_page_text\n",
    "                \n",
    "    return all_text\n",
    "\n",
    "df['Title'] = [file.split('.')[0] for file in os.listdir() if file.split('.')[1]=='pdf']\n",
    "df['Text'] = [grab_text(title, labels) for title in df.Title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>\\n'Twas the night before Christmas\\nwhen all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>\\nThe unicorn has a silver horn, Her\\neyes are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Gruffalo</td>\n",
       "      <td>\\nA mouse took a stroll through the deep dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Monstrous Tale of Celery Crumble</td>\n",
       "      <td>\\nHave you met Celery Crumble?\\nThat’s her rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace at Last</td>\n",
       "      <td>\\nThe hour was late.\\nMr Bear was tired, Mrs B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0            The Night Before Christmas   \n",
       "1             Sugarlump and the Unicorn   \n",
       "2                          The Gruffalo   \n",
       "3  The Monstrous Tale of Celery Crumble   \n",
       "4                         Peace at Last   \n",
       "\n",
       "                                                Text  \n",
       "0  \\n'Twas the night before Christmas\\nwhen all t...  \n",
       "1  \\nThe unicorn has a silver horn, Her\\neyes are...  \n",
       "2  \\nA mouse took a stroll through the deep dark ...  \n",
       "3  \\nHave you met Celery Crumble?\\nThat’s her rig...  \n",
       "4  \\nThe hour was late.\\nMr Bear was tired, Mrs B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../code_new_version')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.Text != ''].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tempdf.pickle', 'wb') as outfile:\n",
    "    pickle.dump(df, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences\n",
    "Note: using strip() here to remove trailing or leading spaces for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.DataFrame()\n",
    "\n",
    "book_col = []\n",
    "sentences_col = []\n",
    "length_col = []\n",
    "index_col = []\n",
    "\n",
    "for title, text in zip(df.Title, df.Text):\n",
    "    text = text.replace('\\n', ' ') # This is only safe provided the line break is not being used to separate sentences w/o puntctuation...\n",
    "    text = text.replace('\\t', ' ') # This allows us to save as tsv (and simplifies the whitespace)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentence_list = list(doc.sents)\n",
    "    \n",
    "    for si, sen in enumerate(sentence_list):\n",
    "        book_col.append(title)\n",
    "        \n",
    "        _doc = sen #nlp(sen.text.strip())\n",
    "        sentences_col.append(_doc)\n",
    "        length_col.append(len(_doc.text.translate(str.maketrans('', '', string.punctuation)).split(' ')))\n",
    "        index_col.append(si)\n",
    "\n",
    "    \n",
    "sentences['book'] = book_col\n",
    "sentences['sentence_length'] = length_col\n",
    "sentences['sentence'] = sentences_col\n",
    "sentences['sentence_index'] = index_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/temp.pickle', 'wb') as outfile:\n",
    "    pickle.dump(doc, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.to_csv('./data/all_sentences_oldenv.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.iloc[0].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12493    (Now, the, fat, red, hen, with, her, thin, bro...\n",
       "1350     (\", I, have, secret, plans, and, clever, trick...\n",
       "3656     (She, took, him, to, the, park, to, play, on, ...\n",
       "11731                                        (“, There, .)\n",
       "4560     (Inside, the, tower, a, windy, ,, windy, stair...\n",
       "                               ...                        \n",
       "3784     (Dogger, had, just, been, bought, by, a, littl...\n",
       "3076     (He, found, a, space, helmet, on, the, drainin...\n",
       "7799                         (Even, Biscuits, the, dog, !)\n",
       "12890                 (“, You, ’re, not, the, Mouse, ., ”)\n",
       "2611     (A, baby, ,, lying, in, a, manger, ;, a, baby,...\n",
       "Name: sentence, Length: 2125, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding_sample.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyio==3.7.1\n",
      "backcall==0.2.0\n",
      "blis==0.7.11\n",
      "cached-property==1.5.2\n",
      "catalogue==2.0.10\n",
      "certifi==2024.2.2\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "cloudpathlib==0.16.0\n",
      "confection==0.1.4\n",
      "cryptography==42.0.7\n",
      "cycler==0.11.0\n",
      "cymem==2.0.8\n",
      "debugpy==1.7.0\n",
      "decorator==5.1.1\n",
      "distro==1.9.0\n",
      "en-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc\n",
      "entrypoints==0.4\n",
      "et-xmlfile==1.1.0\n",
      "exceptiongroup==1.2.1\n",
      "fonttools==4.38.0\n",
      "h11==0.14.0\n",
      "httpcore==0.17.3\n",
      "httpx==0.24.1\n",
      "idna==3.7\n",
      "importlib-metadata==6.7.0\n",
      "ipykernel==6.16.2\n",
      "ipython==7.34.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "jupyter_client==7.4.9\n",
      "jupyter_core==4.12.0\n",
      "kiwisolver==1.4.5\n",
      "langcodes==3.3.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib==3.5.3\n",
      "matplotlib-inline==0.1.6\n",
      "murmurhash==1.0.10\n",
      "nest-asyncio==1.6.0\n",
      "numpy==1.21.6\n",
      "openai==1.35.10\n",
      "openpyxl==3.1.2\n",
      "packaging==24.0\n",
      "pandas==1.3.5\n",
      "parso==0.8.4\n",
      "pdfminer.six==20221105\n",
      "pdfplumber==0.9.0\n",
      "pexpect==4.9.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.5.0\n",
      "preshed==3.0.9\n",
      "prompt-toolkit==3.0.43\n",
      "psutil==5.9.8\n",
      "ptyprocess==0.7.0\n",
      "pycparser==2.21\n",
      "pydantic==1.10.15\n",
      "Pygments==2.17.2\n",
      "pyparsing==3.1.2\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.1\n",
      "pyzmq==26.0.3\n",
      "requests==2.31.0\n",
      "six==1.16.0\n",
      "smart-open==6.4.0\n",
      "sniffio==1.3.1\n",
      "spacy==3.7.4\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "srsly==2.4.8\n",
      "thinc==8.2.3\n",
      "tornado==6.2\n",
      "tqdm==4.66.4\n",
      "traitlets==5.9.0\n",
      "typer==0.9.4\n",
      "typing_extensions==4.7.1\n",
      "urllib3==2.0.7\n",
      "Wand==0.6.13\n",
      "wasabi==1.1.2\n",
      "wcwidth==0.2.13\n",
      "weasel==0.3.4\n",
      "zipp==3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
