{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TODO: add 'and' handling to task 3 prompt and examples. Then postprocess by detecting 'ands'. Also handle comma separation with 3 or more characters. Handle split titles eg. Mr and Mrs Large, Tim and Betty Box etc\n",
    "## TODO: add instruction to be case insensitive in task 3 e.g. mole -> Mole. Add example of case-insentive matching (with aliases also?)\n",
    "\n",
    "## Add 'themsevles' example to prompt\n",
    "\n",
    "## TODO: add fixed split legnth for different books (How grinch..3794)\n",
    "## TODO: SAVE book_df and sentence_df\n",
    "\n",
    "### Task decomposition and prompt development.\n",
    "\n",
    "We provide here a framework for developing sequential prompts for a complex NLP task using GPT4o.\n",
    "\n",
    "The complex tasks is decompsed into as sequence of simpler tasks that each build on the previous one.\n",
    "\n",
    "For each task in the sequence we produce a number of examples to show GPT4o, and a number of further examples to use for automated testing of the response. This borrows ideas from unit testing of software, since iterative changes to the prompt may break functionality that was previously working.\n",
    "\n",
    "This framework can be adapted to use with other LLMs and NLP tasks.\n",
    "\n",
    "#### We decompose into the following tasks:\n",
    "- Task 1: identify sections of direct speech, and the name of the speaker and recipient\n",
    "- Task 1b: locate pre-defined sentences in these detected sections of speech (for comparison with human coding)\n",
    "- Task 2: pull out the spoken words only from each section (removing e.g. 'he said' etc)\n",
    "- Task 3: locate and replace the names of the speakers and recipients using a pre-defined character map  \n",
    "\n",
    "#### Notes:\n",
    "- Determinism is not guaranteed. But well structured prompts should produce near deterministic outputs, along with temperature=0, fixed seed. It is also worth storing the system finerprint for future reference, as changes to this may be the cause of differing results in the future.  \n",
    "- The lack of determinism can make tests quite brittle. It is worth repeating tests several times to confirm their behvaiour. And then running the full manual validation on a single static result set.\n",
    "- Where possible, the sequential tasks should b tackled as a new completion API, using formatted output from the previous task as the inupt. This is preferrable to chaining of prompts and outputs to produce a chat style conversation, but this increases the risk of conflict or confusion between prompts/instructions sets. And also increases the length of the context window.\n",
    "- Need to ensure consistency between instructions, schemas and examples. Otherwise results may be inconsistent e.g. 'reproduce all punctuation all it appears' conflicted with 'remove  speech marks' example.\n",
    "- Should typos be accounted for (e.g. task_3 name matching?)\n",
    "- Cost: \\\\$1.22 left after developing prompts. Added \\\\$10 to run for 50 books (so ~0.25 full dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work:\n",
    "- handle unnamed characters that are still gendered and speaf (e.g. a girl who was older -> older girl: Enormous Croc)\n",
    "- Improve current mapping: speaking to 'each other' -> The Reader \n",
    "- Refactor run_task and run_test methods and move them to separate files\n",
    "- Use SpaCy doc/spans to hanlde speech sections, which knowledge base of characters and aliases, and tags for who is speaking etc.\n",
    "- Then can use the spans to handle splitting books with some overlap to avoid splitting speech/conversations resulting in 'unknown' speaker/recipient. \n",
    "- Add further analysis of speech sections: what is being said - commands, questions, statements, sentiment, who is being spoken about etc.\n",
    "- Better handling of cases where the speech section get split in later tasks (or ideally prevent this from happening).\n",
    "- Add handling for difficult ways of referring to characters by their role or identity rather than a name or alias e.g. 'his siblings' or 'the postman'\n",
    "- Add logic or mapping for same character across multiple books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating this using the Chat GPT API:\n",
    "\n",
    "## TODO:\n",
    " \n",
    " - When in pipeline to spellcheck/ correct typos? (e.g. Hany in the Dinosaurs (book 21).\n",
    " - what to do about inconsitent sentence detection? e.g \"Now Dasher!\" being at the end of sentence 7 was causing GPT confusion...\n",
    " - add an instruction about how to refer to 'general audience' or 'narrator' or 'I'\n",
    " - provide example of input and what the output should look like (within the prompt)\n",
    " - should temp be close to 0 (but not exactly 0)?\n",
    " - ask for output of reaosning/thought process?\n",
    " - ask for a confidence score?\n",
    " - do we need to specify (in system prompt), not to use MD or any other formatting in the json output?\n",
    " \n",
    "## Note: ideas to explore if we need performance boost...\n",
    "\n",
    "- system message to edit assistant role\n",
    "- vary temperature or top_p parameter\n",
    "- fine_tuning a model with bespoke training data (how much is necessary?)\n",
    "- improved instructions or prompt engineering (see e.g. paper on iterative prompting)\n",
    "- compare results with gpt-3.5-turbo? - does not seem to work well for our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./key.txt', 'r') as infile:\n",
    "    api_key = infile.read().splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tempdf.pickle', 'rb') as outfile:\n",
    "    df = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our prompts, example data (for in-context learning), and test data for unit testing each task: \n",
    "from openai_api.examples import example_data\n",
    "from openai_api.tests import build_test_data\n",
    "\n",
    "test_data = build_test_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.utilities import spacy_extract_sentences\n",
    "sentences = spacy_extract_sentences(df, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)\n",
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    \n",
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build OpenAI API code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.schemas import build_task_1_input_schema, build_task_1_response_schema\n",
    "from openai_api.utilities import *\n",
    "\n",
    "task_1_response_schema_str = build_task_1_response_schema()\n",
    "task_1_input_schema_str = build_task_1_input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.tests import run_task_1_test_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.prompts import (\n",
    "    get_task_1_prompt_string, get_task_1_system_prompt,\n",
    "    get_task_2_prompt_string, get_task_2_system_prompt,\n",
    "    get_task_3_prompt_string, get_task_3_system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(full_text, client, seed=42):\n",
    "    \n",
    "    prompt_string = get_task_1_prompt_string(\n",
    "            data={'full_text': full_text}, \n",
    "        )\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_task_1_system_prompt()},\n",
    "            {\"role\": \"user\", \"content\": r\"{}\".format(prompt_string)}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return completion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "        \n",
    "        completion = run_task_1(test_data['strings'][test_id], client=client)\n",
    "        \n",
    "        if run_task_1_test_i(test_id, test_data, completion, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 5\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 6\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 7\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 8\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 9\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 10\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 11\n",
      "Running test: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10772/533159088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running repeat {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msuccess_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/668737001.py\u001b[0m in \u001b[0;36mrun_task_1_tests\u001b[0;34m(test_data, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running test: {test_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'strings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_task_1_test_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/926607395.py\u001b[0m in \u001b[0;36mrun_task_1\u001b[0;34m(full_text, client, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresponse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"json_object\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatCompletionChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         )\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     def patch(\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m             \u001b[0mremaining_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             )\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         )\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m                 )\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m                 trace.return_value = (\n\u001b[1;32m    101\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 data = self._network_stream.read(\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    929\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(20):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_1_tests(test_data)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b: recognising pre-defined sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for comparison with student speech flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: pulling out spoken words only.\n",
    "\n",
    "#### TODO:\n",
    "- refactor run_test_i method\n",
    "- move schemas and test and example data to files\n",
    "- rename as tak 2 or rename functions and strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(full_text, client, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_1_completion is None:\n",
    "        task_1_completion = run_task_1(full_text, client)\n",
    "        \n",
    "    task_1_prompt_string = get_task_1_prompt_string(\n",
    "        data={'full_text': full_text}\n",
    "    )\n",
    "    \n",
    "    task_2_prompt_string = get_task_2_prompt_string(\n",
    "        task_1_response=json.loads(task_1_completion.choices[0].message.content)\n",
    "    )\n",
    "    \n",
    "    task_2_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_2_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_2_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=156, prompt_tokens=684, total_tokens=840)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"Thatâ€™s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_2_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'spoken_words_only': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, completion_2 = run_task_2(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client\n",
    "        )\n",
    "           \n",
    "        if run_task_2_test_i(test_id, test_data, completion_2, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_2_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: mappnig character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(\n",
    "    full_text, client, characters, aliases, \n",
    "    task_2_completion=None, \n",
    "    task_1_completion=None, \n",
    "    _meta_character_list=meta_character_list,\n",
    "    seed=42\n",
    "):\n",
    "    \n",
    "    if task_2_completion is None:\n",
    "        task_1_completion, task_2_completion = run_task_2(full_text, client)\n",
    "        \n",
    "    \n",
    "    task_3_prompt_string = get_task_3_prompt_string(\n",
    "        task_2_response=json.loads(task_2_completion.choices[0].message.content),\n",
    "        characters=characters,\n",
    "        aliases=aliases,\n",
    "        meta_characters=_meta_character_list\n",
    "    )\n",
    "    \n",
    "    task_3_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_3_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_3_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion, task_3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client,\n",
    "    characters=test_data['task_3_characters'][test_id],\n",
    "    aliases=test_data['task_3_aliases'][test_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=155, prompt_tokens=937, total_tokens=1092)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"speech_sections\": [\n",
      "        {\n",
      "            \"speaker\": \"Hany\",\n",
      "            \"recipient\": \"Apatosaurus\",\n",
      "            \"speaker_matched\": \"Unknown\",\n",
      "            \"recipient_matched\": \"Apatosaurus\",\n",
      "            \"speech_section_id\": 0\n",
      "        },\n",
      "        {\n",
      "            \"speaker\": \"Harry\",\n",
      "            \"recipient\": \"Mum\",\n",
      "            \"speaker_matched\": \"Harry\",\n",
      "            \"recipient_matched\": \"Mum\",\n",
      "            \"speech_section_id\": 1\n",
      "        },\n",
      "        {\n",
      "            \"speaker\": \"Sam\",\n",
      "            \"recipient\": \"Harry\",\n",
      "            \"speaker_matched\": \"Mum\",\n",
      "            \"recipient_matched\": \"Harry\",\n",
      "            \"speech_section_id\": 2\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_3_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speaker_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "        'recipient_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "#         'spoken_words_only': {\n",
    "#             'case_sensitive': True,\n",
    "#             'remove_leading_the': False\n",
    "#         },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, _, completion_3 = run_task_3(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client,\n",
    "            characters=test_data['task_3_characters'][test_id],\n",
    "            aliases=test_data['task_3_aliases'][test_id]\n",
    "        )\n",
    "           \n",
    "        if run_task_3_test_i(test_id, test_data, completion_3, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_3_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for corpus\n",
    "\n",
    "Now that our prompts are passing all tests, we run the method for all books in the corpus and save the results to disk....\n",
    "\n",
    "# TODO:\n",
    "- add a 'self' match example to data (still usig himself)\n",
    "- check Noi and 'his dad' - shouldn't it be Dad? (The Storm Whale In Winter)\n",
    "- add Narrator handling/example (e.g. There's A Monster In Your Book)\n",
    "- add a flag for if it is a character match or something else ('Everyone' Narrator' etc!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: that this only handles two chunks currently. And is not an optimal way of splitting since sections of speech may be separated, for example.\n",
    "# max_chunk_size = 9677\n",
    "multi_chunk_books = {\n",
    "    'The Enormous Crocodile': 9677,\n",
    "    'How The Grinch Stole Christmas': 3794, \n",
    "    'Farmer Duck': 1160\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['book_length'] = np.array([len(t) for t in df.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not story books and are also the longest so would possibly need splitting.\n",
    "remove_non_stories = [\n",
    "    'All Year Round', 'All About Feelings', 'Ten in the Bed and Other Counting Rhymes', 'Why Am I An Insect'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='book_length', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(\n",
    "    title, chunk_name, chunk_text, client, book_df, \n",
    "    c1_results_dict, c2_results_dict, c3_results_dict\n",
    "):\n",
    "    \n",
    "    print(\"Book: \", title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    completion_1, completion_2, completion_3 = run_task_3(\n",
    "        full_text=chunk_text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title],\n",
    "        _meta_character_list=meta_character_list\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion_3.choices[0].message.content)\n",
    "    \n",
    "    book_df['c1_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c1_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c1_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c1_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c2_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c2_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c2_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c2_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c3_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c3_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c3_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c3_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    \n",
    "    book_df['title'].append(chunk_name)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'].append(len(json_response['speech_sections']))\n",
    "    \n",
    "    c3_results_dict[chunk_name] = json_response\n",
    "    \n",
    "    c1_results_dict[chunk_name] = json.loads(completion_1.choices[0].message.content)\n",
    "    c2_results_dict[chunk_name] = json.loads(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/2198107619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mc1_results_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc1_results_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mc2_results_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc2_results_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mc3_results_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc3_results_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24432/3843021462.py\u001b[0m in \u001b[0;36mprocess_chunk\u001b[0;34m(title, chunk_name, chunk_text, client, book_df, c1_results_dict, c2_results_dict, c3_results_dict)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcharacters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0maliases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0m_meta_character_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_character_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24432/107826145.py\u001b[0m in \u001b[0;36mrun_task_3\u001b[0;34m(full_text, client, characters, aliases, task_2_completion, task_1_completion, _meta_character_list, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtask_1_completion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24432/1246665002.py\u001b[0m in \u001b[0;36mrun_task_2\u001b[0;34m(full_text, client, task_1_completion, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_1_completion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtask_1_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     task_1_prompt_string = get_task_1_prompt_string(\n",
      "\u001b[0;32m/tmp/ipykernel_24432/926607395.py\u001b[0m in \u001b[0;36mrun_task_1\u001b[0;34m(full_text, client, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresponse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"json_object\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatCompletionChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         )\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     def patch(\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m             \u001b[0mremaining_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             )\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         )\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m                 )\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m                 trace.return_value = (\n\u001b[1;32m    101\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 data = self._network_stream.read(\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    929\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': [],\n",
    "    'c1_completion_tokens': [],\n",
    "    'c1_prompt_tokens': [],\n",
    "    'c1_total_tokens': [],\n",
    "    'c1_system_fingerprint': [],\n",
    "    'c2_completion_tokens': [],\n",
    "    'c2_prompt_tokens': [],\n",
    "    'c2_total_tokens': [],\n",
    "    'c2_system_fingerprint': [],\n",
    "    'c3_completion_tokens': [],\n",
    "    'c3_prompt_tokens': [],\n",
    "    'c3_total_tokens': [],\n",
    "    'c3_system_fingerprint': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "c1_results_dict = {}\n",
    "c2_results_dict = {}\n",
    "c3_results_dict = {}\n",
    "\n",
    "for book_id in df.index:\n",
    "    \n",
    "    title = df.iloc[book_id].Title\n",
    "    \n",
    "    if title not in remove_non_stories:\n",
    "        book_text = df.iloc[book_id].Text\n",
    "#         if len(book_text) > max_chunk_size:\n",
    "    \n",
    "        if title in multi_chunk_books.keys():\n",
    "            max_chunk_size = multi_chunk_books[title]\n",
    "            last_newline = book_text[0:max_chunk_size].rfind('\\n')\n",
    "            chunks = {\n",
    "                ''.join(['_chunk_a_', title]): book_text[0:max_chunk_size],\n",
    "                ''.join(['_chunk_b_', title]): book_text[max_chunk_size:]\n",
    "            }\n",
    "            for chunk in chunks.keys():\n",
    "                process_chunk(\n",
    "                    title=title, \n",
    "                    chunk_name=chunk, \n",
    "                    chunk_text=chunks[chunk], \n",
    "                    client=client, \n",
    "                    book_df=book_df, \n",
    "                    c1_results_dict=c1_results_dict, \n",
    "                    c2_results_dict=c2_results_dict, \n",
    "                    c3_results_dict=c3_results_dict\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            process_chunk(\n",
    "                title=title, \n",
    "                chunk_name=title, \n",
    "                chunk_text=book_text, \n",
    "                client=client, \n",
    "                book_df=book_df, \n",
    "                c1_results_dict=c1_results_dict, \n",
    "                c2_results_dict=c2_results_dict, \n",
    "                c3_results_dict=c3_results_dict\n",
    "            )\n",
    "\n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "boof_df_complete = book_df.copy()\n",
    "boof_df_complete.to_json('data/gpt4_output_summary_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/gpt4_output_summary_corpus.json', 'r') as outfile:\n",
    "#     temp_bdf = pd.read_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_df = pd.concat([temp_bdf, book_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.Title =='Farmer Duck'].iloc[0].Text.find('just before dawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3794"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.Title =='How The Grinch Stole Christmas'].iloc[0].Text.find('Then he slunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supertato\n",
      "Who Will Sing My Puff-a-bye\n",
      "Can't You Sleep Little Bear\n",
      "The Duchess and Guy\n",
      "Grandad's Island\n",
      "Harry and the Robots\n",
      "You Can't Take An Elephant On The Bus\n",
      "Where's My Cuddle\n",
      "Jesus' Christmas Party\n",
      "Princess Mirror-Belle And The Dragon Pox\n",
      "We're Going on a Bear Hunt\n",
      "The Ugly Duckling\n",
      "Room on the Broom\n",
      "Harry and the Bucketful of Dinosaurs\n",
      "Grandma Bird\n",
      "We're Going On A Lion Hunt\n",
      "The Wheels on the Bus\n",
      "The Cave\n",
      "Where's My Teddy\n",
      "The Singing Mermaid\n",
      "What The Ladybird Heard Next\n",
      "The Pirates Next Door\n",
      "Captain Duck\n",
      "The Little Bully\n",
      "All In One Piece\n",
      "The Gruffalo's Child\n",
      "Elephant Learns to Share\n",
      "One Snowy Night\n",
      "Each Peach Pear Plum\n",
      "The Squirrels Who Squabbled\n",
      "Knock Knock Pirate\n",
      "Who Will Save Us\n",
      "Jack Breaks The Beanstalk\n",
      "The Snowiest Christmas Ever\n",
      "Jack and the Beanstalk\n",
      "Super Sid The Silly Sausage Dog\n",
      "The Christmas Extravaganza Hotel\n",
      "Cinder the Bubble-Blowing Dragon\n",
      "The Animal Boogie\n",
      "The Truth According to Arthur\n",
      "Monkey Puzzle\n",
      "Little Monkey\n"
     ]
    }
   ],
   "source": [
    "# Convert results dicts to dataframe of all speech sections and save to disk:\n",
    "\n",
    "all_speech_sections = {\n",
    "    'book': [],\n",
    "    'speech_section_id': [], # speech section id within book\n",
    "    'speaker': [],\n",
    "    'recipient': [],\n",
    "    'speaker_matched': [],\n",
    "    'recipient_matched': [],\n",
    "    'speech_text': [],\n",
    "    'spoken_words_only': [],\n",
    "    'spoken_word_count': []\n",
    "}\n",
    "\n",
    "for book in c3_results_dict.keys():\n",
    "    print(book)\n",
    "    for si, section in enumerate(c3_results_dict[book]['speech_sections']):\n",
    "        all_speech_sections['book'].append(book)\n",
    "        for key in all_speech_sections.keys():\n",
    "            if key not in ['book', 'spoken_word_count', 'speech_text', 'spoken_words_only']:\n",
    "                all_speech_sections[key].append(section[key])\n",
    "        \n",
    "        # Handling edge cases where a speach section is split:\n",
    "        si_corrected = si\n",
    "        if si >= len(c1_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c1_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['speech_text'].append(c1_results_dict[book]['speech_sections'][si_corrected]['speech_text'])\n",
    "        \n",
    "        if si >= len(c2_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c2_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['spoken_words_only'].append(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only'])\n",
    "        all_speech_sections['spoken_word_count'].append(len(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections = pd.DataFrame(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections.to_json('data/gpt4_all_speech_sections_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/gpt4_all_speech_sections_corpus.json', 'r') as outfile:\n",
    "#     temp_ass = pd.read_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_speech_sections = pd.concat([temp_ass, all_speech_sections])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We replace any chunked book titles with the original, adding columns to retain chunk information in case needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections['chunk_titles'] = all_speech_sections['book']\n",
    "all_speech_sections['book'] = [\n",
    "    title\n",
    "    if '_chunk_' not in title\n",
    "    else title.split('_')[3]\n",
    "    for title in all_speech_sections.book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We add the metacharacter data to the character table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_data = pd.DataFrame({\n",
    "    'book': ['all' for c in meta_character_list],\n",
    "    'name': [c for c in meta_character_list],\n",
    "    'gender': ['NGS' for c in meta_character_list],\n",
    "    'human': ['NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "    'alias_count': [0 for c in meta_character_list]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.concat([\n",
    "    characters, meta_character_data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'self' with character name for ease of analysis (and flag self)\n",
    "all_speech_sections['self_talk_flag'] = [\n",
    "    True if r == 'Self'\n",
    "    else False \n",
    "    for r in all_speech_sections.recipient_matched\n",
    "]\n",
    "all_speech_sections['recipient_matched'] = [\n",
    "    s if r == 'Self'\n",
    "    else r \n",
    "    for s,r in zip(all_speech_sections.speaker_matched, all_speech_sections.recipient_matched)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = all_speech_sections.merge(characters, how='left', left_on=['speaker_matched', 'book'], right_on=['name', 'book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = speakers.merge(characters, how='left', left_on=['recipient_matched', 'book'], right_on=['name', 'book'], suffixes=['_speaker', '_recipient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "# for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "for c in [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]:\n",
    "  \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>\"Now, Dasher! now, Dancer!\\nnow, Prancer and V...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>\"Happy\\nChristmas to all, and to all a good\\nn...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>56</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! I can grant horses' wishes.</td>\n",
       "      <td>33</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>False</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         book  speech_section_id       speaker  recipient  \\\n",
       "0  The Night Before Christmas                  0  St. Nicholas   Reindeer   \n",
       "1  The Night Before Christmas                  1  St. Nicholas   Everyone   \n",
       "2   Sugarlump and the Unicorn                  0     Sugarlump    himself   \n",
       "3   Sugarlump and the Unicorn                  1     Sugarlump    himself   \n",
       "4   Sugarlump and the Unicorn                  2       unicorn  Sugarlump   \n",
       "\n",
       "  speaker_matched recipient_matched  \\\n",
       "0    St. Nicholas          Reindeer   \n",
       "1    St. Nicholas          Everyone   \n",
       "2       Sugarlump         Sugarlump   \n",
       "3       Sugarlump         Sugarlump   \n",
       "4         unicorn         Sugarlump   \n",
       "\n",
       "                                         speech_text  \\\n",
       "0  \"Now, Dasher! now, Dancer!\\nnow, Prancer and V...   \n",
       "1  \"Happy\\nChristmas to all, and to all a good\\nn...   \n",
       "2  \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3  \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4  \"Done!\" came a voice, and there stood a beast\\...   \n",
       "\n",
       "                                   spoken_words_only  spoken_word_count  \\\n",
       "0  Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1   Happy Christmas to all, and to all a good night!                 48   \n",
       "2  Here in the children's bedroom Is where I want...                106   \n",
       "3  Oh to be out in the big wide world! I wish I c...                 56   \n",
       "4                  Done! I can grant horses' wishes.                 33   \n",
       "\n",
       "                 chunk_titles  self_talk_flag  name_speaker gender_speaker  \\\n",
       "0  The Night Before Christmas           False  St. Nicholas              M   \n",
       "1  The Night Before Christmas           False  St. Nicholas              M   \n",
       "2   Sugarlump and the Unicorn            True     Sugarlump              M   \n",
       "3   Sugarlump and the Unicorn            True     Sugarlump              M   \n",
       "4   Sugarlump and the Unicorn           False       unicorn              F   \n",
       "\n",
       "  human_speaker  alias_count_speaker name_recipient gender_recipient  \\\n",
       "0             H                  1.0       Reindeer              NGS   \n",
       "1             H                  1.0       Everyone              NGS   \n",
       "2            NH                  0.0      Sugarlump                M   \n",
       "3            NH                  0.0      Sugarlump                M   \n",
       "4            NH                  0.0      Sugarlump                M   \n",
       "\n",
       "  human_recipient  alias_count_recipient  \n",
       "0              NH                    0.0  \n",
       "1               H                    0.0  \n",
       "2              NH                    0.0  \n",
       "3              NH                    0.0  \n",
       "4              NH                    0.0  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06143344709897611"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1242320819112628"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "['The Troll' 'The Princess and the Wizard' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild' 'Tabby McTat'\n",
      " 'Harry and the Dinosaurs at the Museum' 'The Cross Rabbit'\n",
      " 'A Thing Called Snow' 'The Way Home For Wolf' 'Elmer and Wilbur'\n",
      " 'I Need A Wee' \"The Owl's Lesson\" 'Cave Baby' 'The Rescue Party'\n",
      " 'Elmer and the Stranger' 'Zog' 'Lost in Snow' 'Monkey Needs to Listen'\n",
      " 'Dogger' 'Is It Betime Wibbly Pig' 'Wide-awake Hedgehog'\n",
      " 'Tyrannosaurus Drip' 'Sharing A Shell' 'The Enormous Turnip'\n",
      " 'Sir Charlie Stinky Socks and the Really Big Adventure' \"Ruby's Worry\"\n",
      " 'I Am Amelia Earhart' 'She Rex' 'Mole Hill' 'Oi Dog!'\n",
      " 'The Gingerbread Man' \"The Lighthouse Keeper's Lunch\"\n",
      " \"Dogs Don't Do Ballet\" 'Hippo Owns Up' 'Giraffe is Left Out'\n",
      " \"The Tree That's Meant To Be\" 'The Dinosaur That Pooped Christmas'\n",
      " 'The Book With No Pictures' 'The First Christmas' 'Owl Babies'\n",
      " \"The Jolly Postman or Other People's Letters\" 'What The Ladybird Heard'\n",
      " \"Charlie Cook's Favourite Book\" \"Ravi's Roar\" 'The Runaway Pea'\n",
      " 'Goldilocks and the Three Bears' 'Zog and the Flying Doctors'\n",
      " 'The Three Little Pigs' 'The Christmas Story' 'Knock Knock Alien'\n",
      " 'Boogie Bear' 'Santa to the Rescue' 'The Bad-Tempered Ladybird'\n",
      " 'Harry and the Dinosaurs go to School' 'Snow White, Star Striker'\n",
      " 'Elmer and the Wind' \"Eleanor Won't Share\" 'Elmer and Rose' 'All For One'\n",
      " 'Barry the Fish With Fingers and the Hairy Scary Monster'\n",
      " 'The Tiger Who Came To Tea' 'Stick Man' 'When Granny Saved Christmas'\n",
      " 'Who Will Sing My Puff-a-bye' \"You Can't Take An Elephant On The Bus\"\n",
      " \"Jesus' Christmas Party\" 'The Ugly Duckling' 'Room on the Broom'\n",
      " 'Harry and the Bucketful of Dinosaurs' 'The Wheels on the Bus'\n",
      " \"Where's My Teddy\" 'What The Ladybird Heard Next' 'Captain Duck'\n",
      " 'All In One Piece' \"The Gruffalo's Child\" 'Knock Knock Pirate'\n",
      " 'Who Will Save Us' 'The Snowiest Christmas Ever' 'Jack and the Beanstalk'\n",
      " 'Little Monkey']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_recipient.isna()].book.unique()))\n",
    "print(speakers[speakers.name_recipient.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "['Sing A Song Of Bottoms' 'The Troll' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Harry and the Dinosaurs at the Museum' 'The Cross Rabbit'\n",
      " 'A Thing Called Snow' 'Yoga Babies' 'Elmer and Wilbur' 'I Need A Wee'\n",
      " \"The Owl's Lesson\" 'Cave Baby' 'The Rescue Party'\n",
      " 'Elmer and the Stranger' 'Zog' 'Lost in Snow' 'Dogger'\n",
      " 'Is It Betime Wibbly Pig' 'Wide-awake Hedgehog' 'Tyrannosaurus Drip'\n",
      " 'Sharing A Shell' 'The Rhyming Rabbit' 'I Am Amelia Earhart' 'She Rex'\n",
      " 'Mole Hill' 'Oi Dog!' \"The Lighthouse Keeper's Lunch\" 'Hippo Owns Up'\n",
      " 'Giraffe is Left Out' \"The Tree That's Meant To Be\"\n",
      " 'The Dinosaur That Pooped Christmas' \"Lion's in a Flap\" 'Owl Babies'\n",
      " \"The Jolly Postman or Other People's Letters\" 'What The Ladybird Heard'\n",
      " \"Ravi's Roar\" 'The Runaway Pea' 'Zog and the Flying Doctors'\n",
      " 'The Three Little Pigs' 'Lenny Makes A Wish' 'Knock Knock Alien'\n",
      " 'Boogie Bear' 'The Bad-Tempered Ladybird' 'Snow White, Star Striker'\n",
      " 'Father Christmas Needs A Wee' 'The Polar Express' 'Mini Beasties'\n",
      " 'Elmer and Rose' 'The Smartest Giant in Town'\n",
      " 'Barry the Fish With Fingers and the Hairy Scary Monster' 'Stick Man'\n",
      " 'When Granny Saved Christmas' \"Cinderella's Ballet Shoes\" 'Bottoms Up!'\n",
      " \"You Can't Take An Elephant On The Bus\" \"Jesus' Christmas Party\"\n",
      " 'The Ugly Duckling' 'Room on the Broom' 'The Wheels on the Bus'\n",
      " \"Where's My Teddy\" 'What The Ladybird Heard Next' 'All In One Piece'\n",
      " \"The Gruffalo's Child\" 'One Snowy Night' 'Knock Knock Pirate'\n",
      " 'Who Will Save Us' 'The Snowiest Christmas Ever'\n",
      " 'Super Sid The Silly Sausage Dog' 'Cinder the Bubble-Blowing Dragon'\n",
      " 'Little Monkey']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_speaker.isna()].book.unique()))\n",
    "print(speakers[speakers.name_speaker.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_speaker_books = iter(speakers[speakers.name_speaker.isna()].book.unique())\n",
    "# null_speaker_books = iter(speakers[speakers.name_recipient.isna()].book.unique())\n",
    "null_speaker_books = iter(\n",
    "    set(speakers[speakers.name_recipient.isna()].book.unique()) - set(speakers[speakers.name_speaker.isna()].book.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monkey Needs to Listen', 'Harry and the Bucketful of Dinosaurs', 'The Way Home For Wolf', 'Who Will Sing My Puff-a-bye', 'The First Christmas', 'Elmer and the Wind', 'Santa to the Rescue', 'The Christmas Story', 'Harry and the Dinosaurs go to School', 'Goldilocks and the Three Bears', 'The Enormous Turnip', 'Sir Charlie Stinky Socks and the Really Big Adventure', \"Eleanor Won't Share\", 'The Tiger Who Came To Tea', 'The Princess and the Wizard', 'Tabby McTat', 'All For One', 'Captain Duck', 'Jack and the Beanstalk', \"Dogs Don't Do Ballet\", \"Charlie Cook's Favourite Book\", \"Ruby's Worry\", 'The Book With No Pictures', 'The Gingerbread Man']\n"
     ]
    }
   ],
   "source": [
    "print(list(null_speaker_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24432/1597105911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurrent_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_speaker_books\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_book\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_book = next(null_speaker_books)\n",
    "print(current_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>0</td>\n",
       "      <td>The judge</td>\n",
       "      <td>Audience</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>â€œSomeoneâ€™s sitting on a\\nwinnerâ€¦â€\\nCongratulat...</td>\n",
       "      <td>Someoneâ€™s sitting on a winnerâ€¦ Congratulations...</td>\n",
       "      <td>72</td>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      book  speech_section_id    speaker recipient  \\\n",
       "83  Sing A Song Of Bottoms                  0  The judge  Audience   \n",
       "\n",
       "   speaker_matched recipient_matched  \\\n",
       "83         Unknown        The Reader   \n",
       "\n",
       "                                          speech_text  \\\n",
       "83  â€œSomeoneâ€™s sitting on a\\nwinnerâ€¦â€\\nCongratulat...   \n",
       "\n",
       "                                    spoken_words_only  spoken_word_count  \\\n",
       "83  Someoneâ€™s sitting on a winnerâ€¦ Congratulations...                 72   \n",
       "\n",
       "              chunk_titles  self_talk_flag name_speaker gender_speaker  \\\n",
       "83  Sing A Song Of Bottoms           False          NaN            NaN   \n",
       "\n",
       "   human_speaker  alias_count_speaker name_recipient gender_recipient  \\\n",
       "83           NaN                  NaN     The Reader              NGS   \n",
       "\n",
       "   human_recipient  alias_count_recipient  \n",
       "83               H                    0.0  "
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# speakers[(speakers.book == current_book) * (speakers.name_recipient.isna())]\n",
    "speakers[(speakers.book == 'Sing A Song Of Bottoms') * (speakers.name_speaker.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>dogs</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>bears</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>monkeys</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>mice</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>whales</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>rabbits</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>camels</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>kangeroos</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>elephants</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>peacocks</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>skunks</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>squid</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>rhinos</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>tortoises</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>pigs</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>pythons</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>clowns</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>princess</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>snowman</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>pirates</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>trolls</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>bats</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>martians</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>babies</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        book       name gender human  alias_count\n",
       "1053  Sing A Song Of Bottoms       dogs    NGS    NH            0\n",
       "1054  Sing A Song Of Bottoms      bears    NGS    NH            0\n",
       "1055  Sing A Song Of Bottoms    monkeys    NGS    NH            0\n",
       "1056  Sing A Song Of Bottoms       mice    NGS    NH            0\n",
       "1057  Sing A Song Of Bottoms     whales    NGS    NH            0\n",
       "1058  Sing A Song Of Bottoms    rabbits    NGS    NH            0\n",
       "1059  Sing A Song Of Bottoms     camels    NGS    NH            0\n",
       "1060  Sing A Song Of Bottoms  kangeroos    NGS    NH            0\n",
       "1061  Sing A Song Of Bottoms  elephants    NGS    NH            0\n",
       "1062  Sing A Song Of Bottoms   peacocks    NGS    NH            0\n",
       "1063  Sing A Song Of Bottoms     skunks    NGS    NH            0\n",
       "1064  Sing A Song Of Bottoms      squid    NGS    NH            0\n",
       "1065  Sing A Song Of Bottoms     rhinos    NGS    NH            0\n",
       "1066  Sing A Song Of Bottoms  tortoises    NGS    NH            0\n",
       "1067  Sing A Song Of Bottoms       pigs    NGS    NH            0\n",
       "1068  Sing A Song Of Bottoms    pythons    NGS    NH            0\n",
       "1069  Sing A Song Of Bottoms     clowns    NGS    NH            0\n",
       "1070  Sing A Song Of Bottoms   princess      F     H            0\n",
       "1071  Sing A Song Of Bottoms    snowman      M     H            0\n",
       "1072  Sing A Song Of Bottoms    pirates    NGS     H            0\n",
       "1073  Sing A Song Of Bottoms     trolls    NGS    NH            0\n",
       "1074  Sing A Song Of Bottoms       bats    NGS    NH            0\n",
       "1075  Sing A Song Of Bottoms   martians    NGS    NH            0\n",
       "1076  Sing A Song Of Bottoms     babies    NGS     H            0"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# characters[characters.book == current_book]\n",
    "characters[characters.book == 'Sing A Song Of Bottoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_characters = [\n",
    "    ('Ben Buckle and Percy Patch', 'The Troll'), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alias, character, character_id, book]\n",
       "Index: []"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aliases[aliases.character_id==196]\n",
    "aliases[aliases.character==current_book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gruff the Grump</td>\n",
       "      <td>Mr Bear</td>\n",
       "      <td>5</td>\n",
       "      <td>Gruff the Grump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We</td>\n",
       "      <td>I</td>\n",
       "      <td>16</td>\n",
       "      <td>The Polar Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little dove</td>\n",
       "      <td>her baby</td>\n",
       "      <td>24</td>\n",
       "      <td>The Christmas Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McTat</td>\n",
       "      <td>Tabby McTat</td>\n",
       "      <td>51</td>\n",
       "      <td>Tabby McTat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we're</td>\n",
       "      <td>we</td>\n",
       "      <td>67</td>\n",
       "      <td>We're Going On A Lion Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>everyone</td>\n",
       "      <td>other children</td>\n",
       "      <td>1383</td>\n",
       "      <td>Eleanor Won't Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother duck</td>\n",
       "      <td>1434</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>the swans</td>\n",
       "      <td>white birds</td>\n",
       "      <td>1436</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Granny</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>1449</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>Troll</td>\n",
       "      <td>50</td>\n",
       "      <td>The Troll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  alias       character  character_id  \\\n",
       "index                                                   \n",
       "0       Gruff the Grump         Mr Bear             5   \n",
       "1                    We               I            16   \n",
       "2           little dove        her baby            24   \n",
       "3                McTat      Tabby McTat            51   \n",
       "4                 we're              we            67   \n",
       "...                 ...             ...           ...   \n",
       "164            everyone  other children          1383   \n",
       "165              mother     mother duck          1434   \n",
       "166           the swans     white birds          1436   \n",
       "167              Granny     grandmother          1449   \n",
       "168           The Troll           Troll            50   \n",
       "\n",
       "                             book  \n",
       "index                              \n",
       "0                 Gruff the Grump  \n",
       "1               The Polar Express  \n",
       "2             The Christmas Story  \n",
       "3                     Tabby McTat  \n",
       "4      We're Going On A Lion Hunt  \n",
       "...                           ...  \n",
       "164           Eleanor Won't Share  \n",
       "165             The Ugly Duckling  \n",
       "166             The Ugly Duckling  \n",
       "167        Little Red Riding Hood  \n",
       "168                     The Troll  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>Bottoms Up!</td>\n",
       "      <td>0</td>\n",
       "      <td>Babies and Toddlers</td>\n",
       "      <td>Mummies and Daddies</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>Mummies and Daddies,\\nwhy are we unhappy?\\nWeâ€™...</td>\n",
       "      <td>Mummies and Daddies, why are we unhappy? Weâ€™re...</td>\n",
       "      <td>1380</td>\n",
       "      <td>Bottoms Up!</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             book  speech_section_id              speaker  \\\n",
       "2231  Bottoms Up!                  0  Babies and Toddlers   \n",
       "\n",
       "                recipient speaker_matched recipient_matched  \\\n",
       "2231  Mummies and Daddies         Unknown       Mum and Dad   \n",
       "\n",
       "                                            speech_text  \\\n",
       "2231  Mummies and Daddies,\\nwhy are we unhappy?\\nWeâ€™...   \n",
       "\n",
       "                                      spoken_words_only  spoken_word_count  \\\n",
       "2231  Mummies and Daddies, why are we unhappy? Weâ€™re...               1380   \n",
       "\n",
       "     chunk_titles  self_talk_flag name_speaker gender_speaker human_speaker  \\\n",
       "2231  Bottoms Up!           False          NaN            NaN           NaN   \n",
       "\n",
       "      alias_count_speaker name_recipient gender_recipient human_recipient  \\\n",
       "2231                  NaN    Mum and Dad              NGS               H   \n",
       "\n",
       "      alias_count_recipient  \n",
       "2231                    0.0  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.recipient == 'Mummies and Daddies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_character_count = sum(characters.gender == 'F')\n",
    "male_character_count = sum(characters.gender == 'M')\n",
    "ngs_character_count = sum(characters.gender == 'NGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_word_count = speakers[speakers.gender_speaker == 'M'].spoken_word_count.sum()\n",
    "female_spoken_word_count = speakers[speakers.gender_speaker == 'F'].spoken_word_count.sum()\n",
    "ngs_spoken_word_count = speakers[speakers.gender_speaker == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.18846153846154"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.43558282208589"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.39605734767025"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_spoken_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269230769230769"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_received_word_count = speakers[speakers.gender_recipient == 'M'].spoken_word_count.sum()\n",
    "female_received_word_count = speakers[speakers.gender_recipient == 'F'].spoken_word_count.sum()\n",
    "ngs_received_word_count = speakers[speakers.gender_recipient == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.03846153846154"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_received_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.423312883435583"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_received_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.24731182795699"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_received_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speech_sections = len(speakers[speakers.gender_speaker == 'M'])\n",
    "female_speech_sections = len(speakers[speakers.gender_speaker == 'F'])\n",
    "ngs_speech_sections = len(speakers[speakers.gender_speaker == 'NGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211538461538461"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588957055214724"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22939068100358423"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mum</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mum</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mummy</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Granny</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinderella</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Bear</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nan</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldilocks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow White</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Bird</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheep</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Griselda</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book  gender  human  alias_count\n",
       "name                                        \n",
       "Mum           18      18     18           18\n",
       "mum           10      10     10           10\n",
       "Mummy          8       8      8            8\n",
       "Sam            7       7      7            7\n",
       "Granny         5       5      5            5\n",
       "mother         5       5      5            5\n",
       "Cinderella     5       5      5            5\n",
       "Mary           5       5      5            5\n",
       "girl           5       5      5            5\n",
       "cow            5       5      5            5\n",
       "I              4       4      4            4\n",
       "Mrs Bear       4       4      4            4\n",
       "Nan            4       4      4            4\n",
       "Goldilocks     4       4      4            4\n",
       "hen            4       4      4            4\n",
       "Snow White     3       3      3            3\n",
       "Miss Bird      3       3      3            3\n",
       "granny         3       3      3            3\n",
       "sheep          3       3      3            3\n",
       "Griselda       3       3      3            3"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.gender == 'F'].groupby('name').agg('count').sort_values('book', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Proceeds as follows:\n",
    "\n",
    "#### Notes:\n",
    "- For speaker matching, inspect 'unknowns' and 'The Reader' and 'Self' separately: how many instances? Binary clasification metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for several books to test outputs, save format etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': 0,\n",
    "    'completion_tokens': [],\n",
    "    'prompt_tokens': [],\n",
    "    'total_tokens': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "results_dict = {\n",
    "    \n",
    "}\n",
    "\n",
    "for book_id in range(10):\n",
    "    \n",
    "    print(\"Book: \", df.iloc[book_id].Title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    data = {\n",
    "        'full_text': df.iloc[book_id].Text,\n",
    "        'sentences': dict(\n",
    "            zip(\n",
    "                sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "                [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    prompt = get_prompt_string(data)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation.\"},\n",
    "        {\"role\": \"user\", \"content\": r\"{}\".format(prompt)}\n",
    "      ],\n",
    "     temperature=0.0,\n",
    "     response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion.choices[0].message.content)\n",
    "    \n",
    "    book_df['completion_tokens'].append(completion.usage.completion_tokens)\n",
    "    book_df['prompt_tokens'].append(completion.usage.prompt_tokens)\n",
    "    book_df['total_tokens'].append(completion.usage.total_tokens)\n",
    "    book_df['title'].append(df.iloc[book_id].Title)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'] += len(json_response['speech_sections'])\n",
    "    \n",
    "    results_dict[df.iloc[book_id].Title] = json_response\n",
    "    \n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech_section_count</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>runtime_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>154</td>\n",
       "      <td>234</td>\n",
       "      <td>1949</td>\n",
       "      <td>2183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>154</td>\n",
       "      <td>1114</td>\n",
       "      <td>2295</td>\n",
       "      <td>3409</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Gruffalo</td>\n",
       "      <td>154</td>\n",
       "      <td>2821</td>\n",
       "      <td>3055</td>\n",
       "      <td>5876</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Monstrous Tale of Celery Crumble</td>\n",
       "      <td>154</td>\n",
       "      <td>802</td>\n",
       "      <td>2631</td>\n",
       "      <td>3433</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace at Last</td>\n",
       "      <td>154</td>\n",
       "      <td>754</td>\n",
       "      <td>1855</td>\n",
       "      <td>2609</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>154</td>\n",
       "      <td>71</td>\n",
       "      <td>1427</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barry The Fish With Fingers</td>\n",
       "      <td>154</td>\n",
       "      <td>595</td>\n",
       "      <td>1530</td>\n",
       "      <td>2125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>154</td>\n",
       "      <td>2891</td>\n",
       "      <td>4854</td>\n",
       "      <td>7745</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Storm Whale In Winter</td>\n",
       "      <td>154</td>\n",
       "      <td>274</td>\n",
       "      <td>1544</td>\n",
       "      <td>1818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There's A Monster In Your Book</td>\n",
       "      <td>154</td>\n",
       "      <td>254</td>\n",
       "      <td>1351</td>\n",
       "      <td>1605</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  speech_section_count  \\\n",
       "0            The Night Before Christmas                   154   \n",
       "1             Sugarlump and the Unicorn                   154   \n",
       "2                          The Gruffalo                   154   \n",
       "3  The Monstrous Tale of Celery Crumble                   154   \n",
       "4                         Peace at Last                   154   \n",
       "5                Sing A Song Of Bottoms                   154   \n",
       "6           Barry The Fish With Fingers                   154   \n",
       "7                             The Troll                   154   \n",
       "8             The Storm Whale In Winter                   154   \n",
       "9        There's A Monster In Your Book                   154   \n",
       "\n",
       "   completion_tokens  prompt_tokens  total_tokens  runtime_seconds  \n",
       "0                234           1949          2183                3  \n",
       "1               1114           2295          3409               17  \n",
       "2               2821           3055          5876               37  \n",
       "3                802           2631          3433               13  \n",
       "4                754           1855          2609               11  \n",
       "5                 71           1427          1498                1  \n",
       "6                595           1530          2125                9  \n",
       "7               2891           4854          7745               52  \n",
       "8                274           1544          1818                4  \n",
       "9                254           1351          1605                4  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['The Night Before Christmas', 'Sugarlump and the Unicorn', 'The Gruffalo', 'The Monstrous Tale of Celery Crumble', 'Peace at Last', 'Sing A Song Of Bottoms', 'Barry The Fish With Fingers', 'The Troll', 'The Storm Whale In Winter', \"There's A Monster In Your Book\"])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be out in the big wide world!\\nI wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.\\n\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.\\nClippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be free of this heavy load.\\nI wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.\\nGallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to slow down and have some fun!\\nI wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.\\nDancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh for a child to ride me!\\nI want to go home,\" he said',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.\\nMerrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}],\n",
       " 'sentences_with_speech': [{'sentence_id': 5,\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 6,\n",
       "   'speech_text': 'Happily rocking to and fro.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 7,\n",
       "   'speech_text': 'This is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 9,\n",
       "   'speech_text': '\"Oh to be out in the big wide world!',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 10,\n",
       "   'speech_text': 'I wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 11,\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 12,\n",
       "   'speech_text': '\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 18,\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 19,\n",
       "   'speech_text': 'Clippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 22,\n",
       "   'speech_text': '\"Oh to be free of this heavy load.',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 23,\n",
       "   'speech_text': 'I wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 25,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'sentence_id': 31,\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 32,\n",
       "   'speech_text': 'Gallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 35,\n",
       "   'speech_text': '\"Oh to slow down and have some fun!',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 36,\n",
       "   'speech_text': 'I wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 37,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'sentence_id': 41,\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 42,\n",
       "   'speech_text': 'Dancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 44,\n",
       "   'speech_text': '\"Oh for a child to ride me!',\n",
       "   'speech_section_id': 11},\n",
       "  {'sentence_id': 45,\n",
       "   'speech_text': 'I want to go home,\" he said \"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'sentence_id': 49,\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'sentence_id': 50,\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'sentence_id': 55,\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.',\n",
       "   'speech_section_id': 15},\n",
       "  {'sentence_id': 56,\n",
       "   'speech_text': 'Merrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}]}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['Sugarlump and the Unicorn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk \n",
    "with open('./results/gpt4o_results_dict.pk', 'wb') as outfile:\n",
    "    pk.dump(results_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_csv('./results/gpt4o_book_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now extend the conversation to pull out only the spoken words only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "new_json_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in new_json_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For the speech sections that you just found, which I reproduce below, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "\n",
    "        Data: {previous_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_prompt_string(previous_response):\n",
    "    \n",
    "    return f\"\"\"\n",
    "        For the speech sections that you just found, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry and the Dinosaurs Go Wild'"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id = 21\n",
    "df.iloc[book_id].Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'full_text': df.iloc[book_id].Text,\n",
    "    'sentences': dict(\n",
    "        zip(\n",
    "            sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "            [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=992, prompt_tokens=2418, total_tokens=3410)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))},\n",
    "    {\"role\": \"assistant\", \"content\": completion.choices[0].message.content},\n",
    "    {\"role\": \"system\", \"content\": f\"Please use the following schema for your JSON response: {new_json_schema}\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_second_prompt_string(json.loads(completion.choices[0].message.content)))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=944, prompt_tokens=3557, total_tokens=4501)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'speech_text': 'â€œThatâ€™s a\\nrhinoceros,â€ said Hany.',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'speech_text': 'â€œI\\nwant to save some animals,â€ he said.\\nâ€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'speech_text': 'â€œWait till Iâ€™ve finished my blue whale,â€ said Harry.\\nâ€œBlue whales are bigger than trains, bigger than\\ndinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'speech_text': 'â€œArmy tanks donâ€™t need saving!â€ said Triceratops.\\nâ€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhy not talk to Mr Bopsom?\\nHe might put up a poster in his shop window!\\nThen people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œThatâ€™s a shame,â€ said Mr Bopsom.\\nâ€œBecause saving animals is\\nimportant!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œIâ€™ve had an idea!â€ he said. â€œCan you do me lots more\\npictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œMarvellous!â€\\nâ€œWhat a brilliant idea!â€\\nâ€œSo original!â€\\nâ€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhat a\\nwonderful thing youâ€™ve done!â€ she said.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Apatosaurus.\\nâ€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Pterodactyl.\\nâ€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œQuite right, my dinosaurs! Because even\\nif you are as tiny as a tick on the tail of a green turtle, you can\\nstill do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a rhinoceros,â€',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'spoken_words_only': 'â€œI want to save some animals,â€ â€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'spoken_words_only': 'â€œWait till Iâ€™ve finished my blue whale,â€ â€œBlue whales are bigger than trains, bigger than dinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'spoken_words_only': 'â€œArmy tanks donâ€™t need saving!â€ â€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhy not talk to Mr Bopsom? He might put up a poster in his shop window! Then people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a shame,â€ â€œBecause saving animals is important!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œIâ€™ve had an idea!â€ â€œCan you do me lots more pictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œMarvellous!â€ â€œWhat a brilliant idea!â€ â€œSo original!â€ â€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhat a wonderful thing youâ€™ve done!â€',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œQuite right, my dinosaurs! Because even if you are as tiny as a tick on the tail of a green turtle, you can still do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(second_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now trialling format for manual validation:\n",
    "\n",
    "We have already used the student manual coding for validate speech detection, so now we can just focus on detected speech...\n",
    "\n",
    "1. Select book at random, select passage of detected speech at random. \n",
    "2. Show user the passage and some of the text either side of the passage\n",
    "3. Ask is it speech? Is speaker correct? Is recipient correct? [Give option to view more text]\n",
    "4. Save result.\n",
    "\n",
    "#### Note: handle case when sentence is not found in text e.g. The Troll sentence 7 is split across two setences (7 and 8) due to bad pdfplumber output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = randint(0, 1)\n",
    "# book_selection = 4  # Peace at Last\n",
    "book_selection = 1  # Sugarlump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sugarlump and the Unicorn'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_book = list(results_dict.keys())[book_selection]\n",
    "selected_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_sections = json.loads(completion.choices[0].message.content)['speech_sections']\n",
    "speech_sections = results_dict[selected_book]['speech_sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(v_vec):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_section(df, res, speech_section_result, padding=200):\n",
    "\n",
    "    speech_section = speech_section_result['speech_text']\n",
    "    book_text = df[df.Title == selected_book].iloc[0].Text\n",
    "    this_text = book_text[0:res] + '**' + book_text[res:res+len(speech_section)] + '**' + book_text[res+len(speech_section):]\n",
    "    this_text = this_text[max(res-padding-2, 0):min(res+len(speech_section)+padding+2, len(this_text))]\n",
    "    display(Markdown(this_text.replace('\\n', '<br>')))\n",
    "\n",
    "    display(Markdown('**' + 'Result:' + '**'))\n",
    "    display(speech_section_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_selection = randint(0, len(speech_sections))\n",
    "section_selection = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = df[df.Title == selected_book].iloc[0].Text.find(speech_sections[section_selection]['speech_text']) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ht and blue. And when<br>she hears a horse's wish, She can<br>make that wish come tine.<br>Sugarlump was a rocking horse.<br>He belonged to a girl and boy.<br>To and fro, to and fro,<br>They rode on their favourite toy.<br>**\"Here in the children's bedroom<br>Is where I want to be.<br>Happily rocking to and fro.<br>This is the life for me!\"**<br><br>But when the children were out at school Sugarlump hung his head.<br>\"Oh to be out in the big wide world!<br>I wish I could trot,\" he said.<br><br>\"Done!\" came a voice, and there stood a beast<br>With a twisty s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'speaker': 'Sugarlump',\n",
       " 'recipient': 'himself',\n",
       " 'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       " 'speech_section_id': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_section(df, res, speech_sections[section_selection])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please indicate with '1' which are correct: [speech, speaker, recipient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vector = [1, 1, 1]\n",
    "validate(validation_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
