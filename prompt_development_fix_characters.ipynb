{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task decomposition and prompt development.\n",
    "\n",
    "We provide here a framework for developing sequential prompts for a complex NLP task using GPT4o.\n",
    "\n",
    "The complex tasks is decompsed into as sequence of simpler tasks that each build on the previous one.\n",
    "\n",
    "For each task in the sequence we produce a number of examples to show GPT4o, and a number of further examples to use for automated testing of the response. This borrows ideas from unit testing of software, since iterative changes to the prompt may break functionality that was previously working.\n",
    "\n",
    "This framework can be adapted to use with other LLMs and NLP tasks.\n",
    "\n",
    "#### We decompose into the following tasks:\n",
    "- Task 1: identify sections of direct speech, and the name of the speaker and recipient\n",
    "- Task 2: locate pre-defined sentences in these detected sections of speech (for comparison with human coding)\n",
    "- Task 3: pull out the spoken words only from each section (removing e.g. 'he said' etc)\n",
    "- Task 4: locate and replace the names of the speakers and recipients using a pre-defined character map  \n",
    "\n",
    "#### Notes:\n",
    "- Determinism is not guaranteed. But well structured prompts should produce near deterministic outputs, along with temperature=0, fixed seed. It is also worth storing the system finerprint for future reference, as changes to this may be the cause of differing results in the future.  \n",
    "- The lack of determinism can make tests quite brittle. It is worth repeating tests several times to confirm their behvaiour. And then running the full manual validation on a single static result set.\n",
    "- Where possible, the sequential tasks should b tackled as a new completion API, using formatted output from the previous task as the inupt. This is preferrable to chaining of prompts and outputs to produce a chat style conversation, but this increases the risk of conflict or confusion between prompts/instructions sets. And also increases the length of the context window.\n",
    "- Need to ensure consistency between instructions, schemas and examples. Otherwise results may be inconsistent e.g. 'reproduce all punctuation all it appears' conflicted with 'remove  speech marks' example.\n",
    "- Should typos be accounted for (e.g. task_3 name matching?)\n",
    "- Cost: \\\\$1.22 left after developing prompts. Added \\\\$10 to run for 50 books (so ~0.25 full dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating this using the Chat GPT API:\n",
    "\n",
    "## TODO:\n",
    " - move deifnition of input json to system prompt?\n",
    " - add character/alias mapping to prompt for each book: use primary name only\n",
    " - When in pipeline to spellcheck/ correct typos? (e.g. Hany in the Dinosaurs (book 21).\n",
    " - what to do about inconsitent sentence detection? e.g \"Now Dasher!\" being at the end of sentence 7 was causing GPT confusion...\n",
    " - add an instruction about how to refer to 'general audience' or 'narrator' or 'I'\n",
    " - provide example of input and what the output should look like (within the prompt)\n",
    " - should temp be close to 0 (but not exactly 0)?\n",
    " - ask for output of reaosning/thought process?\n",
    " - ask for a confidence score?\n",
    " - do we need to specify (in system prompt), not to use MD or any other formatting in the json output?\n",
    " \n",
    "## Note: ideas to explore if we need performance boost...\n",
    "\n",
    "- system message to edit assistant role\n",
    "- vary temperature or top_p parameter\n",
    "- fine_tuning a model with bespoke training data (how much is necessary?)\n",
    "- improved instructions or prompt engineering (see e.g. paper on iterative prompting)\n",
    "- compare results with gpt-3.5-turbo? - does not seem to work weel for our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./key.txt', 'r') as infile:\n",
    "    api_key = infile.read().splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tempdf.pickle', 'rb') as outfile:\n",
    "    df = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our prompts, example data (for in-context learning), and test data for unit testing each task: \n",
    "from prompts.examples import build_example_data\n",
    "from prompts.tests import build_test_data\n",
    "\n",
    "example_data = build_example_data()\n",
    "test_data = build_test_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.utilities import spacy_extract_sentences\n",
    "sentences = spacy_extract_sentences(df, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)\n",
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    \n",
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.schemas import build_task_1_input_schema, build_task_1_response_schema\n",
    "from prompts.utilities import *\n",
    "\n",
    "task_1_response_schema_str = build_task_1_response_schema()\n",
    "task_1_input_schema_str = build_task_1_input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_1_response_schema = {\n",
    "#     \"speech_sections\": {\n",
    "#         \"speaker\": \"string\",\n",
    "#         \"recipient\": \"string\",\n",
    "#         \"speech_text\": \"string\",\n",
    "#         \"speech_section_id\": \"integer\"\n",
    "#     }\n",
    "# }\n",
    "    \n",
    "# task_1_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_1_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_1_input_schema = {\n",
    "#     \"full_text\": \"string\"\n",
    "# }\n",
    "    \n",
    "# task_1_input_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_1_input_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_1_responses'][test_id]['speech_sections']\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speech_text': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "        pass_flag = True\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_1_prompt_string(data, example_data):\n",
    "    \n",
    "    example_input_1 = example_data['task_1']['example_input_1']\n",
    "    example_output_1 = example_data['task_1']['example_output_1']\n",
    "#     example_input_2 = example_data['task_1']['example_input_2']\n",
    "#     example_output_2 = example_data['task_1']['example_output_2']\n",
    "    \n",
    "    return f\"\"\"\n",
    "        I will provide you below with the following data in JSON format: {task_1_input_schema_str}\n",
    "        \n",
    "        The full_text is text of a children's book as a single string. \n",
    "\n",
    "        Using the full_text, please identify any sections of direct speech, and for each one tell me who is the speaker and who is the recipient.\n",
    "        Remember that a section of direct speech can be broken up by information about who is speaking and that this break could even span \n",
    "        multiple lines in some cases. In these cases, please treat this as a single section of speech.\n",
    "        \n",
    "        For example, the input: {example_input_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Use '\\n' as the newline character and reproduce these as they occur.\n",
    "        Reproduce all punctuation as it is written.    \n",
    "            \n",
    "        Provide the results in JSON format with the following fields: speaker, recipient, speech_text, speech_section_id\n",
    "        (where speech_section_id counts the number of sections of speech in this book)\n",
    "\n",
    "        Data: {data}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_1_system_prompt(input_schema, output_schema):\n",
    "    return f\"\"\"\n",
    "            You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "            You will recieve data in JSON format with the following schema: {input_schema}\n",
    "            Output your response in JSON format using the following schema: {output_schema}.\n",
    "            Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(full_text, client, seed=42):\n",
    "    \n",
    "    prompt_string = get_task_1_prompt_string(\n",
    "            {'full_text': full_text}, \n",
    "            example_data\n",
    "        )\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_task_1_system_prompt(task_1_input_schema_str, task_1_response_schema_str)},\n",
    "            {\"role\": \"user\", \"content\": r\"{}\".format(prompt_string)}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return completion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "        \n",
    "        completion = run_task_1(test_data['strings'][test_id], client=client)\n",
    "        \n",
    "        if run_task_1_test_i(test_id, test_data, completion, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 5\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 6\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 7\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 8\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 9\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 10\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 11\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 12\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 13\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 14\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 15\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 16\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 17\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 18\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 19\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 20\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(20):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_1_tests(test_data)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: recognising pre-defined sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for comparison with student speech flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: pulling out spoken words only.\n",
    "\n",
    "#### TODO:\n",
    "- refactor run_test_i method\n",
    "- move schemas and test and example data to files\n",
    "- rename as tak 2 or rename functions and strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_response_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "task_2_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_2_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_task_2_prompt_string(example_data):\n",
    "    \n",
    "#     example_input_1 = example_data['task_2']['example_input_1']\n",
    "#     example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "#     return f\"\"\"\n",
    "#         For the speech sections that you just found, please pull out the words that are direct speech\n",
    "#         and add them as a field in the JSON output called spoken_words_only.\n",
    "        \n",
    "#         You will need to remove all non-speech words such as 'she said' \n",
    "#         and anything else that is not direct speech. \n",
    "        \n",
    "#         Do not include indirect speech.\n",
    "        \n",
    "#         For example, these speech sections: {example_input_1}\n",
    "#         Should produce the following output: {example_output_1}\n",
    "        \n",
    "#         Reproduce all punctuation as it is written.    \n",
    "#         Provide your response in JSON.\n",
    "#     \"\"\"\n",
    "# def get_task_2_prompt_string(example_data):\n",
    "    \n",
    "#     example_input_1 = example_data['task_2']['example_input_1']\n",
    "#     example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "#     return f\"\"\"\n",
    "#         For the speech sections that you just found, please look at the speech_text fields in the JSON.\n",
    "        \n",
    "#         First, replace all newline characters with a single space.\n",
    "#         Then, remove all words that are not direct speech. Keep only the words that are actually spoken\n",
    "#         and add them as a field in the JSON output called 'spoken_words_only'.\n",
    "        \n",
    "#         You will need to remove all non-speech words such as 'she said' \n",
    "#         and anything else that is not direct speech. \n",
    "        \n",
    "#         Do not include indirect speech.\n",
    "        \n",
    "#         For example, these speech sections: {example_input_1}\n",
    "#         Should produce the following output: {example_output_1}\n",
    "        \n",
    "#         Reproduce all punctuation as it is written.    \n",
    "#         Provide your response in JSON.\n",
    "#     \"\"\"\n",
    "def get_task_2_prompt_string(example_data, task_1_response):\n",
    "    \n",
    "    example_input_1 = example_data['task_2']['example_input_1']\n",
    "    example_output_1 = example_data['task_2']['example_output_1']\n",
    "    \n",
    "    return f\"\"\"\n",
    "        Here are the speech sections that you just found: {task_1_response}. \n",
    "        \n",
    "        Look at the speech_text fields.\n",
    "        Extract only the words that are direct speech, omitting any words that are not actually spoken.\n",
    "        Add these spoken words as a field in the JSON output called 'spoken_words_only'.\n",
    "        Ensure that there is a one-to-one mapping between speech sections in the input and output. \n",
    "        \n",
    "        For example, these speech sections: {example_input_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Remove all speech marks and add full stops where needed, otherwise produce all punctuation as it is written. Replace each newline character '\\n' with a sinlge space.   \n",
    "        Provide your response in JSON.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_2_system_prompt(_task_2_input_schema, _task_2_response_schema):\n",
    "#     return f\"Please use the following schema for your JSON response: {_task_2_response_schema}. Remove all newline characters in your output with a single space.\"\n",
    "    return f\"\"\"\n",
    "        You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "        You will recieve data in JSON format with the following schema: {_task_2_input_schema}\n",
    "        Use the following schema for your JSON response: {_task_2_response_schema}.\n",
    "        Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(full_text, client, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_1_completion is None:\n",
    "        task_1_completion = run_task_1(full_text, client)\n",
    "        \n",
    "    task_1_prompt_string = get_task_1_prompt_string(\n",
    "        {'full_text': full_text}, \n",
    "        example_data\n",
    "    )\n",
    "    \n",
    "    task_2_prompt_string = get_task_2_prompt_string(\n",
    "        example_data,\n",
    "        task_1_response=json.loads(task_1_completion.choices[0].message.content)\n",
    "    )\n",
    "    \n",
    "    task_2_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "#            {\n",
    "#                \"role\": \"system\", \n",
    "#                \"content\": get_task_1_system_prompt(task_1_input_schema_str, task_1_response_schema_str)\n",
    "#            },\n",
    "#            {\n",
    "#                \"role\": \n",
    "#                \"user\", \"content\": r\"{}\".format(task_1_prompt_string)\n",
    "#            },\n",
    "#            {\n",
    "#                \"role\": \"assistant\", \n",
    "#                \"content\": task_1_completion.choices[0].message.content\n",
    "#            },\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_2_system_prompt(task_1_response_schema_str, task_2_response_schema_str)\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_2_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=156, prompt_tokens=680, total_tokens=836)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"Thatâ€™s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_2_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'spoken_words_only': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, completion_2 = run_task_2(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client\n",
    "        )\n",
    "           \n",
    "        if run_task_2_test_i(test_id, test_data, completion_2, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_2_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: mappnig character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator'\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_response_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"speaker_matched\": \"string\",\n",
    "    \"recipient_matched\": \"string\",\n",
    "#     \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "task_3_response_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in task_3_response_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_prompt_string(example_data, task_2_response, characters, aliases, meta_characters=meta_character_list):\n",
    "    \n",
    "    example_input_1 = example_data['task_3']['example_input_1']\n",
    "    example_characters_1 = example_data['task_3']['example_characters_1']\n",
    "    example_aliases_1 = example_data['task_3']['example_aliases_1']\n",
    "    example_output_1 = example_data['task_3']['example_output_1']\n",
    "    \n",
    "    if not isinstance(characters, list):\n",
    "        character_list = list(characters.name)\n",
    "    else:\n",
    "        character_list = characters\n",
    "    if not isinstance(aliases, str):\n",
    "        alias_csv = aliases[['alias', 'character']].to_csv()\n",
    "    else:\n",
    "        alias_csv = aliases\n",
    "    \n",
    "    character_list.append(meta_characters)\n",
    "    return f\"\"\"\n",
    "        Here are the speech sections that you just found: {task_2_response}. \n",
    "        \n",
    "        Look at the speakers and recipients. I want you to match these to pre-defined character names,\n",
    "        and to store the matched name as new fileds called speaker_matched and recipient_matched in the JSON ouput.\n",
    "        \n",
    "        Here is a list of character names: {character_list}\n",
    "        If you find the speaker or recipient in this list (or a close enough match, including typos), please\n",
    "        use the found name as the match value.\n",
    "        If there is no match in the list, look for the name in the 'alias' column of the following\n",
    "        csv lookup table: {alias_csv}\n",
    "        If you find the name in the 'alias' column, take the corresponding value from the 'character' column\n",
    "        as the match.\n",
    "        If you cannot find a name in either the characters or aliases, record the match value as 'Unknown'.\n",
    "        If the recipient appears to be the reader or general audience, record the match value as 'The Reader'.\n",
    "        If the speaker is talking to themself, record the match value as 'Self'.\n",
    "        \n",
    "        For example, these speech sections: {example_input_1}\n",
    "        with this character list: {example_characters_1}\n",
    "        and this alias lookup table: {example_aliases_1}\n",
    "        Should produce the following output: {example_output_1}\n",
    "        \n",
    "        Provide your response in JSON.\n",
    "        Do not change the value of the speaker, recipient fields. Do not include the spoken_words_only field.   \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_3_system_prompt(_task_3_input_schema, _task_3_response_schema):\n",
    "#     return f\"Please use the following schema for your JSON response: {_task_2_response_schema}. Remove all newline characters in your output with a single space.\"\n",
    "    return f\"\"\"\n",
    "        You are a data analysis assistant, capable of accurate and precise natural language processing. \n",
    "        You will recieve data in JSON format with the following schema: {_task_3_input_schema}\n",
    "        Use the following schema for your JSON response: {_task_3_response_schema}.\n",
    "        Please start all indexing of lists and arrays at 0 rather than 1.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(full_text, client, characters, aliases, task_2_completion=None, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_2_completion is None:\n",
    "        task_1_completion, task_2_completion = run_task_2(full_text, client)\n",
    "        \n",
    "    \n",
    "    task_3_prompt_string = get_task_3_prompt_string(\n",
    "        example_data,\n",
    "        task_2_response=json.loads(task_2_completion.choices[0].message.content),\n",
    "        characters=characters,\n",
    "        aliases=aliases\n",
    "    )\n",
    "    \n",
    "    task_3_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_3_system_prompt(task_2_response_schema_str, task_3_response_schema_str)\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_3_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion, task_3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client,\n",
    "    characters=test_data['task_3_characters'][test_id],\n",
    "    aliases=test_data['task_3_aliases'][test_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=155, prompt_tokens=934, total_tokens=1089)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"speech_sections\": [\n",
      "        {\n",
      "            \"speaker\": \"Hany\",\n",
      "            \"recipient\": \"Apatosaurus\",\n",
      "            \"speaker_matched\": \"Unknown\",\n",
      "            \"recipient_matched\": \"Apatosaurus\",\n",
      "            \"speech_section_id\": 0\n",
      "        },\n",
      "        {\n",
      "            \"speaker\": \"Harry\",\n",
      "            \"recipient\": \"Mum\",\n",
      "            \"speaker_matched\": \"Harry\",\n",
      "            \"recipient_matched\": \"Mum\",\n",
      "            \"speech_section_id\": 1\n",
      "        },\n",
      "        {\n",
      "            \"speaker\": \"Sam\",\n",
      "            \"recipient\": \"Harry\",\n",
      "            \"speaker_matched\": \"Mum\",\n",
      "            \"recipient_matched\": \"Harry\",\n",
      "            \"speech_section_id\": 2\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_3_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speaker_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "        'recipient_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "#         'spoken_words_only': {\n",
    "#             'case_sensitive': True,\n",
    "#             'remove_leading_the': False\n",
    "#         },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, _, completion_3 = run_task_3(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client,\n",
    "            characters=test_data['task_3_characters'][test_id],\n",
    "            aliases=test_data['task_3_aliases'][test_id]\n",
    "        )\n",
    "           \n",
    "        if run_task_3_test_i(test_id, test_data, completion_3, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_3_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for corpus\n",
    "\n",
    "Now that our prompts are passing all tests, we run the method for all books in the corpus and save the results to disk....\n",
    "\n",
    "# TODO:\n",
    "- add a 'self' match example to data (still usig himself)\n",
    "- check Noi and 'his dad' - shouldn't it be Dad? (The Storm Whale In Winter)\n",
    "- add Narrator handling/example (e.g. There's A Monster In Your Book)\n",
    "- add a flag for if it is a character match or something else ('Everyone' Narrator' etc!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n",
      "Book:  Once Upon A Unicorn Horn\n",
      "Book:  Mind Your Manners\n",
      "Book:  The Princess and the Wizard\n",
      "Book:  Kipper's Toybox\n",
      "Book:  Oi Frog!\n",
      "Book:  Elmer and the Lost Teddy\n",
      "Book:  The Hungry Caterpillar\n",
      "Book:  A Squash and a Squeeze\n",
      "Book:  Keith The Cat With The Magic Hat\n",
      "Book:  Santa is Coming to Devon\n",
      "Book:  The Enormous Crocodile\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 400 column 18 (char 14598)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25744/3772821360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcharacters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0maliases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25744/2225652110.py\u001b[0m in \u001b[0;36mrun_task_3\u001b[0;34m(full_text, client, characters, aliases, task_2_completion, task_1_completion, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtask_1_completion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25744/3693093833.py\u001b[0m in \u001b[0;36mrun_task_2\u001b[0;34m(full_text, client, task_1_completion, seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m     task_2_prompt_string = get_task_2_prompt_string(\n\u001b[1;32m     12\u001b[0m         \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtask_1_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_completion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 400 column 18 (char 14598)"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': 0,\n",
    "    'c1_completion_tokens': [],\n",
    "    'c1_prompt_tokens': [],\n",
    "    'c1_total_tokens': [],\n",
    "    'c1_system_fingerprint': [],\n",
    "    'c2_completion_tokens': [],\n",
    "    'c2_prompt_tokens': [],\n",
    "    'c2_total_tokens': [],\n",
    "    'c2_system_fingerprint': [],\n",
    "    'c3_completion_tokens': [],\n",
    "    'c3_prompt_tokens': [],\n",
    "    'c3_total_tokens': [],\n",
    "    'c3_system_fingerprint': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "c1_results_dict = {}\n",
    "c2_results_dict = {}\n",
    "c3_results_dict = {}\n",
    "\n",
    "# for book_id in range(len(df)):\n",
    "for book_id in range(50):\n",
    "    title = df.iloc[book_id].Title\n",
    "    print(\"Book: \", title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    completion_1, completion_2, completion_3 = run_task_3(\n",
    "        full_text=df.iloc[book_id].Text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title]\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion_3.choices[0].message.content)\n",
    "    \n",
    "    book_df['c1_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c1_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c1_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c1_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c2_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c2_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c2_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c2_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c3_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c3_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c3_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c3_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    \n",
    "    book_df['title'].append(title)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'] += len(json_response['speech_sections'])\n",
    "    \n",
    "    c3_results_dict[title] = json_response\n",
    "    \n",
    "    c1_results_dict[title] = json.loads(completion_1.choices[0].message.content)\n",
    "    c2_results_dict[title] = json.loads(completion_2.choices[0].message.content)\n",
    "    \n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Enormous Crocodile\n",
      "\n",
      "In the biggest brownest muddiest river in Africa, two crocodiles lay\n",
      "with their heads just above the water . One of the crocodiles was\n",
      "enormous. The other was not so big.\n",
      "â€œDo you know what I wo uld like for my lunch today?â€ the\n",
      "Enormous Crocodile asked.\n",
      "\"No,â€ the Notsobig One said. â€œWhat?â€\n",
      "The Enormous Crocodile grinned, showing hundreds of sharp white\n",
      "teeth. â€œ For my lunch today,â€ he said, â€œI would like a nice juicy little\n",
      "child.â€\n",
      "â€œI never eat children,â€ the Notsobig One said. \"Only fish.â€\n",
      "â€œHo, ho, ho!â€ cried the Enormous Crocodile. \"Iâ€™ll bet if you saw a\n",
      "fat juicy little child paddling in the water ov er there at this very\n",
      "moment, youâ€™d gulp him up in one gollop!â€\n",
      "â€œNo, I wouldnâ€™t,â€ the Notsobig One said. â€œChildren are to o tough\n",
      "and chewy. They are tough and chewy and nasty and bitter.â€\n",
      "â€ Tough and chewy!â€ cried the Enormous Crocodile. â€œNasty and\n",
      "bitter! What awful tommy-rot you talk! They are juicy and yummy!â€\n",
      "â€œThey taste so bitter,â€ the Notsobig One said, â€œyou have to cover\n",
      "them with sugar before you can eat them.â€\n",
      "\"Children are bigg er than fish,â€ said the Enormous Crocodile. \"You\n",
      "get bigger helpings.â€\n",
      "\"You are greedy,â€ the Notsobig One said. \"Youâ€™re the greediest\n",
      "croc in the whole river.â€\n",
      "\"Iâ€™m the bravest croc in the whole river,â€ said the Enormous\n",
      "Crocodile. \"Iâ€™m the only one who dares to leave the water and g o\n",
      "through the jungle to the town to look for little children to eat.â€\n",
      "\"Youâ€™ve only done that once,â€ snorted the Notsobig One. \"A nd\n",
      "what happened then? They all saw you coming and ran away.â€\n",
      "\"Ah, but today wh en I go, they wonâ€™t see me at all,â€ said the\n",
      "Enormous Crocodile.\n",
      "\"Of course theyâ€™ll see you,â€ the Notsobig One said. \"Youâ€™re so\n",
      "enormous and ugly, theyâ€™ll see you from miles away.â€\n",
      "The Enormous Crocodile grinned again, and his terrible sharp\n",
      "teeth sparkled like knives in the sun. \"Nobody will see me,â€ he sa id,\n",
      "\"because this time Iâ€™ve thought up secret plans and clever tricks.â€\n",
      "\"Clever tricks?â€™ cried the Notsobig One. \"Youâ€™ve never done\n",
      "anythin g clever in your life! Youâ€™re the stupidest croc on the whole\n",
      "river!â€\n",
      "\"Iâ€™m the cleverest croc on the whole river,â€ the Enormous\n",
      "Crocodile answered. \"For my lunch today I shall feast upon a fat\n",
      "juicy little c hild while you lie here in the river feeling hungry.\n",
      "Goodbye.â€\n",
      "The Enormous Crocod ile swam to the side of the river, and\n",
      "crawled out of the water.\n",
      "A gigantic creature was standing in the slimy oozy m ud on the\n",
      "river-bank. It was Humpy-Rumpy, the Hippopotamus.\n",
      "\"Hello, hello,â€ said H umpy-Rumpy. \"Where on earth are you off\n",
      "to at this time of day?â€\n",
      "\"I have secret plans and clever tricks,â€ said the Crocodile.\n",
      "\"Oh dear,â€ said H umpy-Rumpy. \"Iâ€™ll bet youâ€™re going to do\n",
      "something horrid.â€\n",
      "The Enormous Crocodile grinned at Humpy-Rumpy and said:\n",
      "\"Iâ€™m going to fill my hungry empty tummy\n",
      "With something yummy yummy yummy yummy!â€\n",
      "\"Whatâ€™s so yummy?â€ asked Humpy-Rumpy.\n",
      "\"Try to guess,â€ said the Crocodile. \"Itâ€™s something that walks on\n",
      "two legs.â€\n",
      "\"You donâ€™t mean ...â€ said Hum py-Rumpy. \"You donâ€™t really mean\n",
      "youâ€™re going to eat a little child?â€\n",
      "\"Of course I am,â€ said the Crocodile.\n",
      "\"Oh, you horrid greedy grumptious brute!â€ cried Humpy- Rumpy .\n",
      "\"I hope you get caught and cooked and turned into crocodile soup!â€\n",
      "The Enormous Crocodile laughed out loud at Humpy-Rumpy.\n",
      "Then he waddled off into the jungle.\n",
      "Inside the jungle, he met Trunky, the Elephant. Trunky was nibbling\n",
      "leaves from the top of a tall tree, and he d idnâ€™t notice the Crocodile at\n",
      "first. So the Crocodile bit him on the leg.\n",
      "\"Ow!â€ said Trunky in his big deep voice. \"Who did that?\n",
      "Oh, itâ€™s you, is it, you beastly Crocodile. W hy donâ€™t you go back to the\n",
      "big brown muddy river where you belong?â€\n",
      "\"I have secret plans and clever tricks,â€ said the Crocodile.\n",
      "\"You mean youâ€™ve nasty plans and nasty tricks,â€ said Trunky.\n",
      "\"Youâ€™ve never done a nice thing in your life.â€\n",
      "The Enormous Crocodile grinned up at Trunky and said:\n",
      "'Iâ€™m off to find a yummy child for lunch.\n",
      "Keep listening and youâ€™ll hear the bones go crunch!â€\n",
      "\"Oh, you wicked beastly beast!â€ cried Trunky. \"Oh, you foul and\n",
      "filthy fiend! I hope you get squ ashed and squished and squizzled and\n",
      "boiled up into crocodile stew!â€\n",
      "The Enorm ous Crocodile laughed out loud and disappeared into the\n",
      "thick jungle.\n",
      "A bit further on, he met Mugg le-Wump, the Monkey. Muggle- Wump\n",
      "was sitting in a tree, eating nuts.\n",
      "\"Hello, Crocky,â€ said Muggle-Wump. \"What are you up to now?â€\n",
      "\"I have secret plans and clever tricks,â€ said the Croco dile.\n",
      "\"Would you like some nuts?â€ asked Muggle-Wump.\n",
      "\"I have better things to eat than nuts,â€ sniffed the Crocodile.\n",
      "\"I did nâ€™t think there was anything better than nuts,â€ said Muggle-\n",
      "Wump.\n",
      "\"Ah-ha,â€ said the Enormous Crocodile,\n",
      "\"The sort of things that Iâ€™m going to eat\n",
      "Have fingers, toe-nails, arms and legs and feet!â€\n",
      "Muggle-Wump went pale and began to shake all over. \"You arenâ€™t\n",
      "really going to gobble up a little child, are you?â€ he said.\n",
      "\"Of course I am,â€ said th e Crocodile. \"Clothes and all. They taste\n",
      "better with the clothes on.â€\n",
      "\"Oh, you horrid hoggish croc!â€ cried Muggle-Wump. \"You slimy\n",
      "creature! I hope the b uttons and buckles all stick in your throat and\n",
      "choke you to death!â€\n",
      "The Crocodile grinned up at Muggle-Wump and said, \"I eat\n",
      "monkeys, too.â€ And quick as a flash, with one bite of his huge\n",
      "jaws, he bit through the tree that Muggle-Wump was sitting in,\n",
      "and down it came. But just in time, Muggle-Wump j umped into\n",
      "the next tree and swung away through the branches.\n",
      "A bit further on, the Enormous Crocodile met the Roly- Poly Bird.\n",
      "The Roly-Poly Bird was building a nest in an orange tree.\n",
      "\"Hello there, Enormous Crocodile!â€ sang the Roly-Poly Bird.\n",
      "\"We donâ€™t often see you up here in the jungle.â€\n",
      "\"Ah,â€ said the Crocodile. \"I have secret plans and clev er tricks. \"I\n",
      "hope itâ€™s not something nasty,â€ sang the Roly-Poly Bird .\n",
      "\"Nasty!â€ cri ed the Crocodile. \"Of course itâ€™s not nasty!\n",
      "Itâ€™s delicious!â€\n",
      "\"Itâ€™s luscious, itâ€™s super,\n",
      "Itâ€™s mushious, itâ€™s duper, Itâ€™s\n",
      "better than rotten old fish. You\n",
      "mash it and mun ch it, You chew\n",
      "it and crunch it!\n",
      "Itâ€™s lovely to hear it go squish!â€\n",
      "\"It must be berries,â€ sang the Roly-Poly Bird. \"Berr ies are my\n",
      "favourite food in the world. I s it raspberries, perhaps?\n",
      "Or could it be strawberries?â€\n",
      "The Enormous Crocodile laughed so much his teeth\n",
      "rattled together like pennies in a moneybox. \"Crocodiles donâ€™t eat\n",
      "berries,â€ he said. \"We eat little boys and girls. And sometimes we eat\n",
      "Roly-Poly Birds, as well.â€ Very quickly, the Crocodile reached up\n",
      "and snapped his jaws at the Roly-Poly Bird. He just missed the Bird,\n",
      "but he managed to catch hold of the long beautiful feathers in its tail.\n",
      "The Roly-Poly Bird gave a shriek of terror and shot straight up into\n",
      "the air, leaving its tail feathers behind in the Enormous Crocodileâ€™s\n",
      "mouth.\n",
      "At last, the Enormous Crocodile came out of the other side of the\n",
      "jungle into the sunshine. He could see the town not far away.\n",
      "\"Ho-ho!â€ he said, talking aloud to himself. \"Ha-ha! That walk\n",
      "through the jungle has made me hungrier than ever. One child isnâ€™t\n",
      "going to be nearly enough for me today. I wonâ€™t be full up until Iâ€™ve\n",
      "eaten at least three juicy little children!â€\n",
      "He started to creep forward towards the town.\n",
      "The Enormous Cr ocodile crept over to a place where there were a\n",
      "lot of coconut trees.\n",
      "He knew that children from the town often came here looking for\n",
      "coconuts. The trees were too tall for them to climb, but the re were\n",
      "always some coconuts on the ground that had fallen down.\n",
      "The Enormous Crocodile quickly collected all the coconuts that\n",
      "were lying on the ground. He also gathered together several fallen\n",
      "branches.\n",
      "â€œNow for Clever Trick Number One!â€ he whispered to him self. \"It\n",
      "wonâ€™t be long before I am eating the first part of my lunch!â€\n",
      "He took all the coconut branches and held them between his teeth.\n",
      "He grasped the coconuts in his front paw s. Then he stood straight\n",
      "up in the air, balancing himself on his tail.\n",
      "He arranged the branches and the coconuts so cleverly that he now\n",
      "looked exactly like a small coconut tree standing among the big\n",
      "coconut trees.\n",
      "Soon, two children came along. They were brother and sister. The boy was\n",
      "called Toto. His sister was called Mary. They walked around looking for fallen\n",
      "coconuts, but they co uldnâ€™t find any because the Enormous Crocodile had\n",
      "gathered them all up.\n",
      "\"Oh look!â€ cried Toto. \"That tree over there is much smaller than the others!\n",
      "And itâ€™s full of coco nuts! I think I could climb that one quite easily if you help\n",
      "me up the first bit.â€\n",
      "Toto and Mary ran towards what they thought was the small coconut tree.\n",
      "The Enormous Crocodile peered through the branches, watching them as they\n",
      "came closer and closer. He licked his lips. He began to dribble with excitement.\n",
      "& -\n",
      "Suddenly there was a tremendous whooshing noise. It was\n",
      "Humpy-Rumpy, the Hippopotamus. He came crashing and snorting\n",
      "out of the jung le. His head was down low and he was galloping at a\n",
      "terrific speed.\n",
      "\"Look out, Toto!â€ shouted Humpy-Rumpy. \"Look out, Mary!\n",
      "Thatâ€™s not a co conut tree! Itâ€™s the Enormous Crocodile and he wants\n",
      "to eat you up!â€\n",
      "Humpy-Rumpy charged straight at the Enormous Crocodile. He\n",
      "caught him with his giant head and sent him tumbling and skidding\n",
      "over the ground.\n",
      "\"Ow-eeee!â€ cried the Crocodile. \"Help! Stop! Where am I?â€\n",
      "Toto and Mary ran back to the town as fast as they could.\n",
      "But croc odiles are tough. It is difficult for even a Hippopotamus to\n",
      "hurt them.\n",
      "The Enormous Crocodile picked himself up and crept towards the\n",
      "place where the childrenâ€™s playground was.\n",
      "\"Now for Clever Trick Num ber Two!â€ he said to himself.\n",
      "\"This one is certain to work!â€\n",
      "There were no c hildren in the playground at that moment. They\n",
      "were all in school.\n",
      "The Enormous Crocodile found a large piece of wood and placed\n",
      "it in the middle of the playground. Then he lay across the piece of\n",
      "wood an d tucked in his feet so that he looked almost exactly like a\n",
      "see-saw.\n",
      "When sch ool was over, the children all came running on to the\n",
      "playground.\n",
      "\"Oh look!â€ they cried. 'â€™Weâ€™ve got a new see-saw!â€\n",
      "They all crowded round, sh outing with excitement.\n",
      "\"Bags I have the first go!â€\n",
      "\"Iâ€™ll get on the other end!â€\n",
      "\"I want to go first!â€\n",
      "\"So do I! So do I!â€\n",
      "Then, a girl who was older than the others said, \"Itâ€™s rather a\n",
      "funny knob bly sort of a see-saw, isnâ€™t it? Do you think itâ€™ll be safe\n",
      "to sit on?â€\n",
      "\"Of course it will!â€ the others said. \"It looks strong as anything!â€\n",
      "The Enormous Crocodile opened one eye just a tiny bit and\n",
      "watched the children who were crowding around him. Soon, he\n",
      "thought, one of them is going to sit on my head, then I will give a\n",
      "jerk and a snap, and after that it will be yum yum yum.\n",
      "At that moment, there was a flash of brown and som ething jumped into the\n",
      "playground and hopped up on to the to p of the swings.\n",
      "It was Muggle-Wump, the Monkey.\n",
      "\"Run!â€ Muggle-Wump shouted to the children. \"All of you, run, run, run!\n",
      "Thatâ€™s not a see-saw! Itâ€™s the Enormous Crocod ile and he wants to eat you up!â€\n",
      "The children screamed and ran for their lives.\n",
      "Muggle-Wump disappeared back into the ju ngle, and the Enormous\n",
      "Crocodile was left all alone in the playground.\n",
      "\n",
      "He cursed the Monkey and waddled back into the bushes to hide.\n",
      "\"Iâ€™m getting hungrier a nd hungrier!â€ he said. \"I shall have to eat at least four children\n",
      "now before I am full up!â€\n",
      "The E normous Crocodile crept around the edge of the town, taking great care not to\n",
      "be seen.\n",
      "He came to a place where they were getting ready to have a fair. There were slides\n",
      "and swings and do dgem-cars and people selling popcorn and candy-floss. There was also\n",
      "a big roundabout.\n",
      "The roundabout had marvellous wooden creatures for the children to ride on. There\n",
      "were white horses and lions and tigers and mermaids w ith fishesâ€™ tails and fearsome\n",
      "dragons with red tongues sticking out of their mouths.\n",
      "\"Now for Clever Trick Number Three,â€ said the Enormous Crocodile, licking his lips.\n",
      "When no one was looking, he crept up on to the roundabout and put himself between\n",
      "a wooden lion and a fearsome dragon. He sat up a bit on his back le gs and he kept very\n",
      "still. He looked exactly like a wooden crocodile on the roundabout.\n",
      "Soon, all sorts of children came flo cking into the fair. Several of them ran towards the\n",
      "roundabout. They were very excited.\n",
      "\"Iâ€™m going to ride on a dragon!â€ cried one.\n",
      "\"Iâ€™m going on a lovely white horse!â€ cri ed another.\n",
      "\"Iâ€™m going on a lion!â€ cried a third one.\n",
      "And one little girl, whose name wa s Jill said, \"Iâ€™m going to ride\n",
      "on that funny old wooden crocodile!â€\n",
      "The Enormous Crocodile kept very still, but he could see the little\n",
      "girl coming towards him. \"Y ummy-yum-yum,â€ he thought. \"Iâ€™ll gulp\n",
      "her up easily in one gollop.â€\n",
      "\n",
      "Suddenly there was a swish and a swoosh and something came swishing\n",
      "and swooshing out of the sky .\n",
      "It was the Roly-Poly Bird.\n",
      "He flew round and round the roundabout, singing, \"L ook out,\n",
      "Jill! Look out! Look out! Don â€™t ride on that crocodile!â€\n",
      "Jill stopped and looked up.\n",
      "\"Thatâ€™s not a wooden crocodile!â€ sang the Roly-Poly Bird. \"Itâ€™s a real\n",
      "one! Itâ€™s the Enormous Crocodile from the river and he wants to eat you up!â€\n",
      "Jill turned and ran. So did all the other children. Even the man who w as\n",
      "working the roundabout jumped off it and ran away as fast as he could.\n",
      "The Enormous Croc odile cursed the Roly-Poly Bird and waddled back\n",
      "into the bushes to hide.\n",
      "\"Iâ€™m so h ungry now,â€ he said to himself, \"I could eat six children before I\n",
      "am full up!â€\n",
      "\n",
      "Just outside the town, there was a pretty little field with trees and\n",
      "bushes all round it. This was called The Picnic Place. There were\n",
      "several wooden tables and long benche s, and people were allowed to\n",
      "go there and have a picnic at any time.\n",
      "The Enormous Cr ocodile crept over to The Picnic Place. There\n",
      "was no one in sight.\n",
      "\"Now for Clever Trick Number Four!â€ he whispered to himself.\n",
      "He p icked a lovely bunch of flowers and arranged it on one of the\n",
      "tables.\n",
      "From the sa me table, he took away one of the benches and hid it\n",
      "in the bushes.\n",
      "Then he put himself in the place where the bench had been.\n",
      "By tucking his head under his chest, and by twisting his tail out of\n",
      "sight, he made himself look very much like a long wooden bench\n",
      "with four legs.\n",
      "Soon, two boys and two girls came along carrying baskets of food.\n",
      "They were all from one family, an d their mother had said they could\n",
      "go out and have a picnic together.\n",
      "\"Which table shall we sit at?â€ said one.\n",
      "\"Letâ€™s take the table with the lovely flowers on it,â€ said another.\n",
      "The Enormous Crocodile kept as quiet as a mouse. \"I shall eat\n",
      "them all,â€ he said to himself. \"They will come and sit on my back\n",
      "and I will swizzle my h ead around quickly, and after that itâ€™ll be\n",
      "squish crunch gollop.â€\n",
      "Suddenly a big deep voice from the jungle shouted, \"Stand back,\n",
      "children! Stand back! Stand back!â€\n",
      "The childre n stopped and stared at the place where the voice was\n",
      "coming from.\n",
      "Then, with a crashing o f branches, Trunky the Elephant came\n",
      "rushing out of the jungle.\n",
      "\"Thatâ€™s not a bench you were going to sit on!â€ he bello wed. \"Itâ€™s\n",
      "the Enormous Crocodile, and he wants to eat you all up!â€\n",
      "Trunky trotted over to the spot where the Enormous Crocodile was\n",
      "standing, and quick as a flash he wrapped his tr unk around the\n",
      "Crocodileâ€™s tail and hoisted him up into the air.\n",
      "\"Hey! Let me go!â€ yelled the Enormous Croc odile, who was now\n",
      "dangling upside down. \"Let me go! Let me go!â€\n",
      "\"No,â€ Trunky said. \"I will n ot let you go. Weâ€™ve all had quite\n",
      "enough of your clever tricks.â€\n",
      "Trunky began to swing the Crocodile round and round in the air. At\n",
      "first he swung him slowly.\n",
      "Then he swung h im faster..\n",
      "And FASTER ...\n",
      "And FASTER ...\n",
      "And FASTER STILL...\n",
      "Soon the Enormous Crocodile was just a blurry circle going\n",
      "round and round Trunkyâ€™s head.\n",
      "Suddenly, Trunky let go of the Crocodileâ€™s tail, and the\n",
      "Crocod ile went shooting high up into the sky like a huge green\n",
      "rocket.\n",
      "Up and up he went...\n",
      "Higher and higher . ..\n",
      "Faster and faster ...\n",
      "He was going so fast and so high that soon the earth was just\n",
      "a tiny dot miles below.\n",
      "He whizzed on and on.\n",
      "He whizzed far into space.\n",
      "He whizzed past the moon.\n",
      "He whizzed past stars and planets.\n",
      "Until at last....\n",
      "With the most tremendous BANG\n",
      "the Enormous Crocodile crashed headfirst into the hot hot sun.\n",
      "And he was sizzled up like a sausage!\n"
     ]
    }
   ],
   "source": [
    "for book_id in range(50):\n",
    "    title = df.iloc[book_id].Title\n",
    "    if title == 'The Enormous Crocodile':\n",
    "        print(\"Book: \", title)\n",
    "        print(df.iloc[book_id].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "   completion_1 = run_task_1(\n",
    "        full_text=df[df.Title=='The Enormous Crocodile'].iloc[0].Text, \n",
    "        client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=df[df.Title=='The Enormous Crocodile'].iloc[0].Text, \n",
    "    client=client,\n",
    "    task_1_completion=completion_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 397 column 7 (char 14591)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25744/1906393050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m completion_1, completion_2 = run_task_2(\n\u001b[1;32m      2\u001b[0m     \u001b[0mfull_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTitle\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'The Enormous Crocodile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/tmp/ipykernel_25744/3693093833.py\u001b[0m in \u001b[0;36mrun_task_2\u001b[0;34m(full_text, client, task_1_completion, seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m     task_2_prompt_string = get_task_2_prompt_string(\n\u001b[1;32m     12\u001b[0m         \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtask_1_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_completion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 397 column 7 (char 14591)"
     ]
    }
   ],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=df[df.Title=='The Enormous Crocodile'].iloc[0].Text, \n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    \\nIn the biggest brownest muddiest river in Af...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[df.Title==title].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 407 column 1 (char 14571)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25744/701216768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcharacters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maliases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;32m/tmp/ipykernel_25744/2225652110.py\u001b[0m in \u001b[0;36mrun_task_3\u001b[0;34m(full_text, client, characters, aliases, task_2_completion, task_1_completion, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtask_1_completion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_2_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25744/3693093833.py\u001b[0m in \u001b[0;36mrun_task_2\u001b[0;34m(full_text, client, task_1_completion, seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m     task_2_prompt_string = get_task_2_prompt_string(\n\u001b[1;32m     12\u001b[0m         \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtask_1_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_completion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 407 column 1 (char 14571)"
     ]
    }
   ],
   "source": [
    "title = 'The Enormous Crocodile'\n",
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=df[df.Title==title].iloc[0].Text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_response=json.loads(completion_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Elephant',\n",
       "   'recipient': 'Crocodile',\n",
       "   'speech_text': 'Good morning, Crocodile.',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Crocodile',\n",
       "   'recipient': 'Elephant',\n",
       "   'speech_text': 'Good morning, Elephant. What are you doing?',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Elephant',\n",
       "   'recipient': 'Crocodile',\n",
       "   'speech_text': 'I am going to the river to drink some water.',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Crocodile',\n",
       "   'recipient': 'Elephant',\n",
       "   'speech_text': 'Be careful, Elephant. The river is very deep.',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Elephant',\n",
       "   'recipient': 'Crocodile',\n",
       "   'speech_text': 'Thank you, Crocodile. I will be careful.',\n",
       "   'speech_section_id': 4}]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results dicts to dataframe of all speech sections and save to disk:\n",
    "\n",
    "all_speech_sections = {\n",
    "    'book': [],\n",
    "    'speech_section_id': [], # speech section id within book\n",
    "    'speaker': [],\n",
    "    'recipient': [],\n",
    "    'speaker_matched': [],\n",
    "    'recipient_matched': [],\n",
    "    'speech_text': [],\n",
    "    'spoken_words_only': [],\n",
    "    'spoken_word_count': []\n",
    "}\n",
    "\n",
    "for book in c3_results_dict.keys():\n",
    "    print(book)\n",
    "    for si, section in enumerate(c3_results_dict[book]['speech_sections']):\n",
    "        all_speech_sections['book'].append(book)\n",
    "        for key in all_speech_sections.keys():\n",
    "            if key not in ['book', 'spoken_word_count', 'speech_text', 'spoken_words_only']:\n",
    "                all_speech_sections[key].append(section[key])\n",
    "        \n",
    "        all_speech_sections['speech_text'].append(c1_results_dict[book]['speech_sections'][si]['speech_text'])\n",
    "        all_speech_sections['spoken_words_only'].append(c2_results_dict[book]['speech_sections'][si]['spoken_words_only'])\n",
    "        all_speech_sections['spoken_word_count'].append(len(c2_results_dict[book]['speech_sections'][si]['spoken_words_only']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = len(all_speech_sections['spoken_word_count'])\n",
    "\n",
    "# for key in all_speech_sections.keys():\n",
    "#     all_speech_sections[key] = all_speech_sections[key][0:l]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections = pd.DataFrame(all_speech_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We add the metacharacter data to the character table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_data = pd.DataFrame({\n",
    "    'book': ['all' for c in meta_character_list],\n",
    "    'name': [c for c in meta_character_list],\n",
    "    'gender': ['NGS' for c in meta_character_list],\n",
    "    'human': ['NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "    'alias_count': [0 for c in meta_character_list]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.concat([\n",
    "    characters, meta_character_data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'self' with character name for ease of analysis (and flag self)\n",
    "all_speech_sections['self_talk_flag'] = [\n",
    "    True if r == 'Self'\n",
    "    else False \n",
    "    for r in all_speech_sections.recipient_matched\n",
    "]\n",
    "all_speech_sections['recipient_matched'] = [\n",
    "    s if r == 'Self'\n",
    "    else r \n",
    "    for s,r in zip(all_speech_sections.speaker_matched, all_speech_sections.recipient_matched)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aliases # add 'Hany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = all_speech_sections.merge(characters, how='left', left_on=['speaker_matched', 'book'], right_on=['name', 'book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = speakers.merge(characters, how='left', left_on=['recipient_matched', 'book'], right_on=['name', 'book'], suffixes=['_speaker', '_recipient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "    \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Happy\\nChristmas to all, and to all a good\\nni...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>Unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! came a voice, and there stood a beast Wi...</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         book  speech_section_id       speaker  recipient  \\\n",
       "0  The Night Before Christmas                  0  St. Nicholas   Reindeer   \n",
       "1  The Night Before Christmas                  1  St. Nicholas   Everyone   \n",
       "2   Sugarlump and the Unicorn                  0     Sugarlump    himself   \n",
       "3   Sugarlump and the Unicorn                  1     Sugarlump    himself   \n",
       "4   Sugarlump and the Unicorn                  2       Unicorn  Sugarlump   \n",
       "\n",
       "  speaker_matched recipient_matched  \\\n",
       "0    St. Nicholas           Unknown   \n",
       "1    St. Nicholas        The Reader   \n",
       "2       Sugarlump         Sugarlump   \n",
       "3       Sugarlump         Sugarlump   \n",
       "4         unicorn         Sugarlump   \n",
       "\n",
       "                                         speech_text  \\\n",
       "0  Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...   \n",
       "1  Happy\\nChristmas to all, and to all a good\\nni...   \n",
       "2  \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3  \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4  \"Done!\" came a voice, and there stood a beast\\...   \n",
       "\n",
       "                                   spoken_words_only  spoken_word_count  \\\n",
       "0  Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1   Happy Christmas to all, and to all a good night!                 48   \n",
       "2  Here in the children's bedroom Is where I want...                106   \n",
       "3  Oh to be out in the big wide world! I wish I c...                 65   \n",
       "4  Done! came a voice, and there stood a beast Wi...                128   \n",
       "\n",
       "   self_talk_flag  name_speaker gender_speaker human_speaker  \\\n",
       "0           False  St. Nicholas              M             H   \n",
       "1           False  St. Nicholas              M             H   \n",
       "2            True     Sugarlump              M            NH   \n",
       "3            True     Sugarlump              M            NH   \n",
       "4           False       unicorn              F            NH   \n",
       "\n",
       "   alias_count_speaker name_recipient gender_recipient human_recipient  \\\n",
       "0                  1.0            NaN              NaN             NaN   \n",
       "1                  1.0     The Reader              NGS               H   \n",
       "2                  0.0      Sugarlump                M              NH   \n",
       "3                  0.0      Sugarlump                M              NH   \n",
       "4                  0.0      Sugarlump                M              NH   \n",
       "\n",
       "   alias_count_recipient  \n",
       "0                    NaN  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05230125523012552"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23057953144266338"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "187/811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1506276150627615"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "['The Night Before Christmas' 'Sugarlump and the Unicorn'\n",
      " 'The Monstrous Tale of Celery Crumble' 'Peace at Last'\n",
      " 'Sing A Song Of Bottoms' 'Barry The Fish With Fingers' 'The Troll'\n",
      " 'The Storm Whale In Winter' \"There's A Monster In Your Book\"\n",
      " 'Once Upon A Unicorn Horn' 'Mind Your Manners'\n",
      " 'The Princess and the Wizard' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Open Very Carefully, A Book With Bite!'\n",
      " 'The Most Wonderful Gift In The World' 'Elmer and Grandpa Eldo'\n",
      " 'Tabby McTat' 'Harry and the Dinosaurs at the Museum'\n",
      " \"The Hedgehog's Balloon\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_recipient.isna()].book.unique()))\n",
    "print(speakers[speakers.name_recipient.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['Sing A Song Of Bottoms' \"There's A Monster In Your Book\"\n",
      " 'Once Upon A Unicorn Horn' 'Mind Your Manners' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Open Very Carefully, A Book With Bite!'\n",
      " 'The Most Wonderful Gift In The World' 'Elmer and Grandpa Eldo'\n",
      " 'Tabby McTat' 'Harry and the Dinosaurs at the Museum']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_speaker.isna()].book.unique()))\n",
    "print(speakers[speakers.name_speaker.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Harry</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Mum</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Sam</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Gran</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>T-Rex</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Museum Guard</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Pterodactyl</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Triceratops</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Anchisaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Apatosaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Scelidosaurs</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        book          name gender human  \\\n",
       "index                                                                     \n",
       "40     Harry and the Dinosaurs at the Museum         Harry      M     H   \n",
       "367    Harry and the Dinosaurs at the Museum           Mum      F     H   \n",
       "368    Harry and the Dinosaurs at the Museum           Sam      F     H   \n",
       "369    Harry and the Dinosaurs at the Museum          Gran      F     H   \n",
       "370    Harry and the Dinosaurs at the Museum         T-Rex      M    NH   \n",
       "371    Harry and the Dinosaurs at the Museum  Museum Guard      M     H   \n",
       "372    Harry and the Dinosaurs at the Museum   Pterodactyl      M    NH   \n",
       "373    Harry and the Dinosaurs at the Museum   Triceratops    NGS    NH   \n",
       "374    Harry and the Dinosaurs at the Museum   Anchisaurus    NGS    NH   \n",
       "375    Harry and the Dinosaurs at the Museum   Apatosaurus    NGS    NH   \n",
       "376    Harry and the Dinosaurs at the Museum  Scelidosaurs    NGS    NH   \n",
       "\n",
       "       alias_count  \n",
       "index               \n",
       "40               0  \n",
       "367              0  \n",
       "368              0  \n",
       "369              0  \n",
       "370              1  \n",
       "371              0  \n",
       "372              0  \n",
       "373              0  \n",
       "374              0  \n",
       "375              0  \n",
       "376              0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.book == 'Harry and the Dinosaurs at the Museum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alias, character, character_id, book]\n",
       "Index: []"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aliases[aliases.character_id==196]\n",
    "aliases[aliases.character=='the Enormous Crocodile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Happy\\nChristmas to all, and to all a good\\nni...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>65</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>3</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Self</td>\n",
       "      <td>\"Here in the open countryside is where\\nI like...</td>\n",
       "      <td>Here in the open countryside is where I like t...</td>\n",
       "      <td>104</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>The Hedgehog's Balloon</td>\n",
       "      <td>0</td>\n",
       "      <td>Percy</td>\n",
       "      <td>himself</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Self</td>\n",
       "      <td>â€œTwo red ones. . . a blue one. . . thereâ€™s\\na ...</td>\n",
       "      <td>Two red ones. . . a blue one. . . thereâ€™s a ye...</td>\n",
       "      <td>85</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>The Hedgehog's Balloon</td>\n",
       "      <td>1</td>\n",
       "      <td>Percy</td>\n",
       "      <td>himself</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Self</td>\n",
       "      <td>â€œI wonder where theyâ€™re\\ncoming from,â€ he said...</td>\n",
       "      <td>I wonder where theyâ€™re coming from. Somebody m...</td>\n",
       "      <td>67</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>The Hedgehog's Balloon</td>\n",
       "      <td>2</td>\n",
       "      <td>Percy</td>\n",
       "      <td>himself</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Self</td>\n",
       "      <td>â€œWell, if nobody wants them,â€ he said,\\nâ€œI thi...</td>\n",
       "      <td>Well, if nobody wants them, I think Iâ€™ll help ...</td>\n",
       "      <td>53</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>The Hedgehog's Balloon</td>\n",
       "      <td>3</td>\n",
       "      <td>Percy</td>\n",
       "      <td>himself</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Self</td>\n",
       "      <td>â€œSomeoneâ€™s crying,â€ said Percy.\\nâ€œOh dear.â€</td>\n",
       "      <td>Someoneâ€™s crying. Oh dear.</td>\n",
       "      <td>26</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>The Hedgehog's Balloon</td>\n",
       "      <td>12</td>\n",
       "      <td>Percy</td>\n",
       "      <td>himself</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Self</td>\n",
       "      <td>â€œAnother satisfied customer,â€ said\\nPercy, fee...</td>\n",
       "      <td>Another satisfied customer.</td>\n",
       "      <td>27</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           book  speech_section_id       speaker recipient  \\\n",
       "0    The Night Before Christmas                  0  St. Nicholas  Reindeer   \n",
       "1    The Night Before Christmas                  1  St. Nicholas  Everyone   \n",
       "2     Sugarlump and the Unicorn                  0     Sugarlump   himself   \n",
       "3     Sugarlump and the Unicorn                  1     Sugarlump   himself   \n",
       "5     Sugarlump and the Unicorn                  3     Sugarlump   himself   \n",
       "..                          ...                ...           ...       ...   \n",
       "419      The Hedgehog's Balloon                  0         Percy   himself   \n",
       "420      The Hedgehog's Balloon                  1         Percy   himself   \n",
       "421      The Hedgehog's Balloon                  2         Percy   himself   \n",
       "422      The Hedgehog's Balloon                  3         Percy   himself   \n",
       "431      The Hedgehog's Balloon                 12         Percy   himself   \n",
       "\n",
       "    speaker_matched recipient_matched  \\\n",
       "0      St. Nicholas           Unknown   \n",
       "1      St. Nicholas        The Reader   \n",
       "2         Sugarlump              Self   \n",
       "3         Sugarlump              Self   \n",
       "5         Sugarlump              Self   \n",
       "..              ...               ...   \n",
       "419           Percy              Self   \n",
       "420           Percy              Self   \n",
       "421           Percy              Self   \n",
       "422           Percy              Self   \n",
       "431           Percy              Self   \n",
       "\n",
       "                                           speech_text  \\\n",
       "0    Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...   \n",
       "1    Happy\\nChristmas to all, and to all a good\\nni...   \n",
       "2    \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3    \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "5    \"Here in the open countryside is where\\nI like...   \n",
       "..                                                 ...   \n",
       "419  â€œTwo red ones. . . a blue one. . . thereâ€™s\\na ...   \n",
       "420  â€œI wonder where theyâ€™re\\ncoming from,â€ he said...   \n",
       "421  â€œWell, if nobody wants them,â€ he said,\\nâ€œI thi...   \n",
       "422        â€œSomeoneâ€™s crying,â€ said Percy.\\nâ€œOh dear.â€   \n",
       "431  â€œAnother satisfied customer,â€ said\\nPercy, fee...   \n",
       "\n",
       "                                     spoken_words_only  spoken_word_count  \\\n",
       "0    Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1     Happy Christmas to all, and to all a good night!                 48   \n",
       "2    Here in the children's bedroom Is where I want...                106   \n",
       "3    Oh to be out in the big wide world! I wish I c...                 65   \n",
       "5    Here in the open countryside is where I like t...                104   \n",
       "..                                                 ...                ...   \n",
       "419  Two red ones. . . a blue one. . . thereâ€™s a ye...                 85   \n",
       "420  I wonder where theyâ€™re coming from. Somebody m...                 67   \n",
       "421  Well, if nobody wants them, I think Iâ€™ll help ...                 53   \n",
       "422                         Someoneâ€™s crying. Oh dear.                 26   \n",
       "431                        Another satisfied customer.                 27   \n",
       "\n",
       "     name_speaker gender_speaker human_speaker  alias_count_speaker  \\\n",
       "0    St. Nicholas              M             H                  1.0   \n",
       "1    St. Nicholas              M             H                  1.0   \n",
       "2       Sugarlump              M            NH                  0.0   \n",
       "3       Sugarlump              M            NH                  0.0   \n",
       "5       Sugarlump              M            NH                  0.0   \n",
       "..            ...            ...           ...                  ...   \n",
       "419         Percy              M             H                  0.0   \n",
       "420         Percy              M             H                  0.0   \n",
       "421         Percy              M             H                  0.0   \n",
       "422         Percy              M             H                  0.0   \n",
       "431         Percy              M             H                  0.0   \n",
       "\n",
       "    name_recipient gender_recipient human_recipient  alias_count_recipient  \n",
       "0              NaN              NaN             NaN                    NaN  \n",
       "1              NaN              NaN             NaN                    NaN  \n",
       "2              NaN              NaN             NaN                    NaN  \n",
       "3              NaN              NaN             NaN                    NaN  \n",
       "5              NaN              NaN             NaN                    NaN  \n",
       "..             ...              ...             ...                    ...  \n",
       "419            NaN              NaN             NaN                    NaN  \n",
       "420            NaN              NaN             NaN                    NaN  \n",
       "421            NaN              NaN             NaN                    NaN  \n",
       "422            NaN              NaN             NaN                    NaN  \n",
       "431            NaN              NaN             NaN                    NaN  \n",
       "\n",
       "[72 rows x 17 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.name_recipient.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_character_count = sum(characters.gender == 'F')\n",
    "male_character_count = sum(characters.gender == 'M')\n",
    "ngs_character_count = sum(characters.gender == 'NGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_word_count = speakers[speakers.gender_speaker == 'M'].spoken_word_count.sum()\n",
    "female_spoken_word_count = speakers[speakers.gender_speaker == 'F'].spoken_word_count.sum()\n",
    "ngs_spoken_word_count = speakers[speakers.gender_speaker == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.18846153846154"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.43558282208589"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.39605734767025"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_spoken_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269230769230769"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_received_word_count = speakers[speakers.gender_recipient == 'M'].spoken_word_count.sum()\n",
    "female_received_word_count = speakers[speakers.gender_recipient == 'F'].spoken_word_count.sum()\n",
    "ngs_received_word_count = speakers[speakers.gender_recipient == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.03846153846154"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_received_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.423312883435583"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_received_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.24731182795699"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_received_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speech_sections = len(speakers[speakers.gender_speaker == 'M'])\n",
    "female_speech_sections = len(speakers[speakers.gender_speaker == 'F'])\n",
    "ngs_speech_sections = len(speakers[speakers.gender_speaker == 'NGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211538461538461"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588957055214724"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22939068100358423"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mum</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mum</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mummy</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Granny</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinderella</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Bear</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nan</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldilocks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow White</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Bird</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheep</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Griselda</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book  gender  human  alias_count\n",
       "name                                        \n",
       "Mum           18      18     18           18\n",
       "mum           10      10     10           10\n",
       "Mummy          8       8      8            8\n",
       "Sam            7       7      7            7\n",
       "Granny         5       5      5            5\n",
       "mother         5       5      5            5\n",
       "Cinderella     5       5      5            5\n",
       "Mary           5       5      5            5\n",
       "girl           5       5      5            5\n",
       "cow            5       5      5            5\n",
       "I              4       4      4            4\n",
       "Mrs Bear       4       4      4            4\n",
       "Nan            4       4      4            4\n",
       "Goldilocks     4       4      4            4\n",
       "hen            4       4      4            4\n",
       "Snow White     3       3      3            3\n",
       "Miss Bird      3       3      3            3\n",
       "granny         3       3      3            3\n",
       "sheep          3       3      3            3\n",
       "Griselda       3       3      3            3"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.gender == 'F'].groupby('name').agg('count').sort_values('book', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Proceeds as follows:\n",
    "\n",
    "#### Notes:\n",
    "- For speaker matching, inspect 'unknowns' and 'The Reader' and 'Self' separately: how many instances? Binary clasification metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for several books to test outputs, save format etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': 0,\n",
    "    'completion_tokens': [],\n",
    "    'prompt_tokens': [],\n",
    "    'total_tokens': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "results_dict = {\n",
    "    \n",
    "}\n",
    "\n",
    "for book_id in range(10):\n",
    "    \n",
    "    print(\"Book: \", df.iloc[book_id].Title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    data = {\n",
    "        'full_text': df.iloc[book_id].Text,\n",
    "        'sentences': dict(\n",
    "            zip(\n",
    "                sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "                [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    prompt = get_prompt_string(data)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation.\"},\n",
    "        {\"role\": \"user\", \"content\": r\"{}\".format(prompt)}\n",
    "      ],\n",
    "     temperature=0.0,\n",
    "     response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion.choices[0].message.content)\n",
    "    \n",
    "    book_df['completion_tokens'].append(completion.usage.completion_tokens)\n",
    "    book_df['prompt_tokens'].append(completion.usage.prompt_tokens)\n",
    "    book_df['total_tokens'].append(completion.usage.total_tokens)\n",
    "    book_df['title'].append(df.iloc[book_id].Title)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'] += len(json_response['speech_sections'])\n",
    "    \n",
    "    results_dict[df.iloc[book_id].Title] = json_response\n",
    "    \n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech_section_count</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>runtime_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>154</td>\n",
       "      <td>234</td>\n",
       "      <td>1949</td>\n",
       "      <td>2183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>154</td>\n",
       "      <td>1114</td>\n",
       "      <td>2295</td>\n",
       "      <td>3409</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Gruffalo</td>\n",
       "      <td>154</td>\n",
       "      <td>2821</td>\n",
       "      <td>3055</td>\n",
       "      <td>5876</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Monstrous Tale of Celery Crumble</td>\n",
       "      <td>154</td>\n",
       "      <td>802</td>\n",
       "      <td>2631</td>\n",
       "      <td>3433</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace at Last</td>\n",
       "      <td>154</td>\n",
       "      <td>754</td>\n",
       "      <td>1855</td>\n",
       "      <td>2609</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>154</td>\n",
       "      <td>71</td>\n",
       "      <td>1427</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barry The Fish With Fingers</td>\n",
       "      <td>154</td>\n",
       "      <td>595</td>\n",
       "      <td>1530</td>\n",
       "      <td>2125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>154</td>\n",
       "      <td>2891</td>\n",
       "      <td>4854</td>\n",
       "      <td>7745</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Storm Whale In Winter</td>\n",
       "      <td>154</td>\n",
       "      <td>274</td>\n",
       "      <td>1544</td>\n",
       "      <td>1818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There's A Monster In Your Book</td>\n",
       "      <td>154</td>\n",
       "      <td>254</td>\n",
       "      <td>1351</td>\n",
       "      <td>1605</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  speech_section_count  \\\n",
       "0            The Night Before Christmas                   154   \n",
       "1             Sugarlump and the Unicorn                   154   \n",
       "2                          The Gruffalo                   154   \n",
       "3  The Monstrous Tale of Celery Crumble                   154   \n",
       "4                         Peace at Last                   154   \n",
       "5                Sing A Song Of Bottoms                   154   \n",
       "6           Barry The Fish With Fingers                   154   \n",
       "7                             The Troll                   154   \n",
       "8             The Storm Whale In Winter                   154   \n",
       "9        There's A Monster In Your Book                   154   \n",
       "\n",
       "   completion_tokens  prompt_tokens  total_tokens  runtime_seconds  \n",
       "0                234           1949          2183                3  \n",
       "1               1114           2295          3409               17  \n",
       "2               2821           3055          5876               37  \n",
       "3                802           2631          3433               13  \n",
       "4                754           1855          2609               11  \n",
       "5                 71           1427          1498                1  \n",
       "6                595           1530          2125                9  \n",
       "7               2891           4854          7745               52  \n",
       "8                274           1544          1818                4  \n",
       "9                254           1351          1605                4  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['The Night Before Christmas', 'Sugarlump and the Unicorn', 'The Gruffalo', 'The Monstrous Tale of Celery Crumble', 'Peace at Last', 'Sing A Song Of Bottoms', 'Barry The Fish With Fingers', 'The Troll', 'The Storm Whale In Winter', \"There's A Monster In Your Book\"])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be out in the big wide world!\\nI wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.\\n\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.\\nClippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be free of this heavy load.\\nI wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.\\nGallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to slow down and have some fun!\\nI wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.\\nDancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh for a child to ride me!\\nI want to go home,\" he said',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.\\nMerrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}],\n",
       " 'sentences_with_speech': [{'sentence_id': 5,\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 6,\n",
       "   'speech_text': 'Happily rocking to and fro.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 7,\n",
       "   'speech_text': 'This is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 9,\n",
       "   'speech_text': '\"Oh to be out in the big wide world!',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 10,\n",
       "   'speech_text': 'I wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 11,\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 12,\n",
       "   'speech_text': '\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 18,\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 19,\n",
       "   'speech_text': 'Clippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 22,\n",
       "   'speech_text': '\"Oh to be free of this heavy load.',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 23,\n",
       "   'speech_text': 'I wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 25,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'sentence_id': 31,\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 32,\n",
       "   'speech_text': 'Gallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 35,\n",
       "   'speech_text': '\"Oh to slow down and have some fun!',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 36,\n",
       "   'speech_text': 'I wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 37,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'sentence_id': 41,\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 42,\n",
       "   'speech_text': 'Dancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 44,\n",
       "   'speech_text': '\"Oh for a child to ride me!',\n",
       "   'speech_section_id': 11},\n",
       "  {'sentence_id': 45,\n",
       "   'speech_text': 'I want to go home,\" he said \"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'sentence_id': 49,\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'sentence_id': 50,\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'sentence_id': 55,\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.',\n",
       "   'speech_section_id': 15},\n",
       "  {'sentence_id': 56,\n",
       "   'speech_text': 'Merrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}]}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['Sugarlump and the Unicorn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk \n",
    "with open('./results/gpt4o_results_dict.pk', 'wb') as outfile:\n",
    "    pk.dump(results_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_csv('./results/gpt4o_book_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now extend the conversation to pull out only the spoken words only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "new_json_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in new_json_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For the speech sections that you just found, which I reproduce below, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "\n",
    "        Data: {previous_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_prompt_string(previous_response):\n",
    "    \n",
    "    return f\"\"\"\n",
    "        For the speech sections that you just found, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry and the Dinosaurs Go Wild'"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id = 21\n",
    "df.iloc[book_id].Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'full_text': df.iloc[book_id].Text,\n",
    "    'sentences': dict(\n",
    "        zip(\n",
    "            sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "            [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=992, prompt_tokens=2418, total_tokens=3410)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))},\n",
    "    {\"role\": \"assistant\", \"content\": completion.choices[0].message.content},\n",
    "    {\"role\": \"system\", \"content\": f\"Please use the following schema for your JSON response: {new_json_schema}\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_second_prompt_string(json.loads(completion.choices[0].message.content)))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=944, prompt_tokens=3557, total_tokens=4501)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'speech_text': 'â€œThatâ€™s a\\nrhinoceros,â€ said Hany.',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'speech_text': 'â€œI\\nwant to save some animals,â€ he said.\\nâ€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'speech_text': 'â€œWait till Iâ€™ve finished my blue whale,â€ said Harry.\\nâ€œBlue whales are bigger than trains, bigger than\\ndinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'speech_text': 'â€œArmy tanks donâ€™t need saving!â€ said Triceratops.\\nâ€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhy not talk to Mr Bopsom?\\nHe might put up a poster in his shop window!\\nThen people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œThatâ€™s a shame,â€ said Mr Bopsom.\\nâ€œBecause saving animals is\\nimportant!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œIâ€™ve had an idea!â€ he said. â€œCan you do me lots more\\npictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œMarvellous!â€\\nâ€œWhat a brilliant idea!â€\\nâ€œSo original!â€\\nâ€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhat a\\nwonderful thing youâ€™ve done!â€ she said.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Apatosaurus.\\nâ€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Pterodactyl.\\nâ€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œQuite right, my dinosaurs! Because even\\nif you are as tiny as a tick on the tail of a green turtle, you can\\nstill do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a rhinoceros,â€',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'spoken_words_only': 'â€œI want to save some animals,â€ â€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'spoken_words_only': 'â€œWait till Iâ€™ve finished my blue whale,â€ â€œBlue whales are bigger than trains, bigger than dinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'spoken_words_only': 'â€œArmy tanks donâ€™t need saving!â€ â€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhy not talk to Mr Bopsom? He might put up a poster in his shop window! Then people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a shame,â€ â€œBecause saving animals is important!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œIâ€™ve had an idea!â€ â€œCan you do me lots more pictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œMarvellous!â€ â€œWhat a brilliant idea!â€ â€œSo original!â€ â€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhat a wonderful thing youâ€™ve done!â€',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œQuite right, my dinosaurs! Because even if you are as tiny as a tick on the tail of a green turtle, you can still do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(second_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now trialling format for manual validation:\n",
    "\n",
    "We have already used the student manual coding for validate speech detection, so now we can just focus on detected speech...\n",
    "\n",
    "1. Select book at random, select passage of detected speech at random. \n",
    "2. Show user the passage and some of the text either side of the passage\n",
    "3. Ask is it speech? Is speaker correct? Is recipient correct? [Give option to view more text]\n",
    "4. Save result.\n",
    "\n",
    "#### Note: handle case when sentence is not found in text e.g. The Troll sentence 7 is split across two setences (7 and 8) due to bad pdfplumber output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = randint(0, 1)\n",
    "# book_selection = 4  # Peace at Last\n",
    "book_selection = 1  # Sugarlump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sugarlump and the Unicorn'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_book = list(results_dict.keys())[book_selection]\n",
    "selected_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_sections = json.loads(completion.choices[0].message.content)['speech_sections']\n",
    "speech_sections = results_dict[selected_book]['speech_sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(v_vec):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_section(df, res, speech_section_result, padding=200):\n",
    "\n",
    "    speech_section = speech_section_result['speech_text']\n",
    "    book_text = df[df.Title == selected_book].iloc[0].Text\n",
    "    this_text = book_text[0:res] + '**' + book_text[res:res+len(speech_section)] + '**' + book_text[res+len(speech_section):]\n",
    "    this_text = this_text[max(res-padding-2, 0):min(res+len(speech_section)+padding+2, len(this_text))]\n",
    "    display(Markdown(this_text.replace('\\n', '<br>')))\n",
    "\n",
    "    display(Markdown('**' + 'Result:' + '**'))\n",
    "    display(speech_section_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_selection = randint(0, len(speech_sections))\n",
    "section_selection = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = df[df.Title == selected_book].iloc[0].Text.find(speech_sections[section_selection]['speech_text']) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ht and blue. And when<br>she hears a horse's wish, She can<br>make that wish come tine.<br>Sugarlump was a rocking horse.<br>He belonged to a girl and boy.<br>To and fro, to and fro,<br>They rode on their favourite toy.<br>**\"Here in the children's bedroom<br>Is where I want to be.<br>Happily rocking to and fro.<br>This is the life for me!\"**<br><br>But when the children were out at school Sugarlump hung his head.<br>\"Oh to be out in the big wide world!<br>I wish I could trot,\" he said.<br><br>\"Done!\" came a voice, and there stood a beast<br>With a twisty s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'speaker': 'Sugarlump',\n",
       " 'recipient': 'himself',\n",
       " 'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       " 'speech_section_id': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_section(df, res, speech_sections[section_selection])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please indicate with '1' which are correct: [speech, speaker, recipient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vector = [1, 1, 1]\n",
    "validate(validation_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
