{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: fix word count column!\n",
    "\n",
    "## TODO: add 'and' handling to task 3 prompt and examples. Then postprocess by detecting 'ands'. Also handle comma separation with 3 or more characters. Handle split titles eg. Mr and Mrs Large, Tim and Betty Box etc\n",
    "## TODO: add instruction to be case insensitive in task 3 e.g. mole -> Mole. Add example of case-insentive matching (with aliases also?)\n",
    "\n",
    "# TODO: handle uncoed characters (e.g. 'the boy next to her', 'someone she is playing with' in Eleanor)\n",
    "\n",
    "# TODO: test GRinch and famrer duck separately\n",
    "\n",
    "## Add 'themsevles' example to prompt. 'Each other' -> 'The Reader' but not working when capitalised?\n",
    "\n",
    "## TODO: add fixed split legnth for different books (How grinch..3794)\n",
    "## TODO: SAVE book_df and sentence_df\n",
    "\n",
    "### Task decomposition and prompt development.\n",
    "\n",
    "We provide here a framework for developing sequential prompts for a complex NLP task using GPT4o.\n",
    "\n",
    "The complex tasks is decompsed into as sequence of simpler tasks that each build on the previous one.\n",
    "\n",
    "For each task in the sequence we produce a number of examples to show GPT4o, and a number of further examples to use for automated testing of the response. This borrows ideas from unit testing of software, since iterative changes to the prompt may break functionality that was previously working.\n",
    "\n",
    "This framework can be adapted to use with other LLMs and NLP tasks.\n",
    "\n",
    "#### We decompose into the following tasks:\n",
    "- Task 1: identify sections of direct speech, and the name of the speaker and recipient\n",
    "- Task 1b: locate pre-defined sentences in these detected sections of speech (for comparison with human coding)\n",
    "- Task 2: pull out the spoken words only from each section (removing e.g. 'he said' etc)\n",
    "- Task 3: locate and replace the names of the speakers and recipients using a pre-defined character map  \n",
    "\n",
    "#### On gender and character coding (for article and data entry tools):\n",
    "- We code mixed plural/groups as NGS, and NH\n",
    "- We ask users to include groups as a separate character (e.g. pigs in three pigs, reindeer in...)\n",
    "- We ask users to code all characters that speak or are spoken to including inaimate objects (NH)\n",
    "\n",
    "#### Notes:\n",
    "- Determinism is not guaranteed. But well structured prompts should produce near deterministic outputs, along with temperature=0, fixed seed. It is also worth storing the system finerprint for future reference, as changes to this may be the cause of differing results in the future.  \n",
    "- The lack of determinism can make tests quite brittle. It is worth repeating tests several times to confirm their behvaiour. And then running the full manual validation on a single static result set.\n",
    "- Where possible, the sequential tasks should b tackled as a new completion API, using formatted output from the previous task as the inupt. This is preferrable to chaining of prompts and outputs to produce a chat style conversation, but this increases the risk of conflict or confusion between prompts/instructions sets. And also increases the length of the context window.\n",
    "- Need to ensure consistency between instructions, schemas and examples. Otherwise results may be inconsistent e.g. 'reproduce all punctuation all it appears' conflicted with 'remove  speech marks' example.\n",
    "- Should typos be accounted for (e.g. task_3 name matching?)\n",
    "- Cost: \\\\$1.22 left after developing prompts. Added \\\\$10 to run for 50 books (so ~0.25 full dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work:\n",
    "- handle unnamed characters that are still gendered and speaf (e.g. a girl who was older -> older girl: Enormous Croc)\n",
    "- Improve current mapping: speaking to 'each other' -> The Reader \n",
    "- Refactor run_task and run_test methods and move them to separate files\n",
    "- Use SpaCy doc/spans to hanlde speech sections, which knowledge base of characters and aliases, and tags for who is speaking etc.\n",
    "- Then can use the spans to handle splitting books with some overlap to avoid splitting speech/conversations resulting in 'unknown' speaker/recipient. \n",
    "- Add further analysis of speech sections: what is being said - commands, questions, statements, sentiment, who is being spoken about etc.\n",
    "- Better handling of cases where the speech section get split in later tasks (or ideally prevent this from happening).\n",
    "- Add handling for difficult ways of referring to characters by their role or identity rather than a name or alias e.g. 'his siblings' or 'the postman'\n",
    "- Add logic or mapping for same character across multiple books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating this using the Chat GPT API:\n",
    "\n",
    "## TODO:\n",
    " \n",
    " - When in pipeline to spellcheck/ correct typos? (e.g. Hany in the Dinosaurs (book 21).\n",
    " - what to do about inconsitent sentence detection? e.g \"Now Dasher!\" being at the end of sentence 7 was causing GPT confusion...\n",
    " - add an instruction about how to refer to 'general audience' or 'narrator' or 'I'\n",
    " - provide example of input and what the output should look like (within the prompt)\n",
    " - should temp be close to 0 (but not exactly 0)?\n",
    " - ask for output of reaosning/thought process?\n",
    " - ask for a confidence score?\n",
    " - do we need to specify (in system prompt), not to use MD or any other formatting in the json output?\n",
    " \n",
    "## Note: ideas to explore if we need performance boost...\n",
    "\n",
    "- system message to edit assistant role\n",
    "- vary temperature or top_p parameter\n",
    "- fine_tuning a model with bespoke training data (how much is necessary?)\n",
    "- improved instructions or prompt engineering (see e.g. paper on iterative prompting)\n",
    "- compare results with gpt-3.5-turbo? - does not seem to work well for our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./key.txt', 'r') as infile:\n",
    "    api_key = infile.read().splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tempdf.pickle', 'rb') as outfile:\n",
    "    df = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our prompts, example data (for in-context learning), and test data for unit testing each task: \n",
    "from openai_api.examples import example_data\n",
    "from openai_api.tests import build_test_data\n",
    "\n",
    "test_data = build_test_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.utilities import spacy_extract_sentences\n",
    "sentences = spacy_extract_sentences(df, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)\n",
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    \n",
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build OpenAI API code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.schemas import build_task_1_input_schema, build_task_1_response_schema\n",
    "from openai_api.utilities import *\n",
    "\n",
    "task_1_response_schema_str = build_task_1_response_schema()\n",
    "task_1_input_schema_str = build_task_1_input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.tests import run_task_1_test_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.prompts import (\n",
    "    get_task_1_prompt_string, get_task_1_system_prompt,\n",
    "    get_task_2_prompt_string, get_task_2_system_prompt,\n",
    "    get_task_3_prompt_string, get_task_3_system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(full_text, client, seed=42):\n",
    "    \n",
    "    prompt_string = get_task_1_prompt_string(\n",
    "            data={'full_text': full_text}, \n",
    "        )\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_task_1_system_prompt()},\n",
    "            {\"role\": \"user\", \"content\": r\"{}\".format(prompt_string)}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return completion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "        \n",
    "        completion = run_task_1(test_data['strings'][test_id], client=client)\n",
    "        \n",
    "        if run_task_1_test_i(test_id, test_data, completion, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 5\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 6\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 7\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 8\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 9\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 10\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 11\n",
      "Running test: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10772/533159088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running repeat {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msuccess_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/668737001.py\u001b[0m in \u001b[0;36mrun_task_1_tests\u001b[0;34m(test_data, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running test: {test_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'strings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_task_1_test_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/926607395.py\u001b[0m in \u001b[0;36mrun_task_1\u001b[0;34m(full_text, client, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresponse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"json_object\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatCompletionChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         )\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     def patch(\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m             \u001b[0mremaining_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             )\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         )\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m                 )\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m                 trace.return_value = (\n\u001b[1;32m    101\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 data = self._network_stream.read(\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    929\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(20):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_1_tests(test_data)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b: recognising pre-defined sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for comparison with student speech flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: pulling out spoken words only.\n",
    "\n",
    "#### TODO:\n",
    "- refactor run_test_i method\n",
    "- move schemas and test and example data to files\n",
    "- rename as tak 2 or rename functions and strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(full_text, client, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_1_completion is None:\n",
    "        task_1_completion = run_task_1(full_text, client)\n",
    "        \n",
    "    task_1_prompt_string = get_task_1_prompt_string(\n",
    "        data={'full_text': full_text}\n",
    "    )\n",
    "    \n",
    "    task_2_prompt_string = get_task_2_prompt_string(\n",
    "        task_1_response=json.loads(task_1_completion.choices[0].message.content)\n",
    "    )\n",
    "    \n",
    "    task_2_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_2_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_2_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=156, prompt_tokens=684, total_tokens=840)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"Thatâ€™s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_2_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'spoken_words_only': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, completion_2 = run_task_2(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client\n",
    "        )\n",
    "           \n",
    "        if run_task_2_test_i(test_id, test_data, completion_2, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_2_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: mappnig character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(\n",
    "    full_text, client, characters, aliases, \n",
    "    task_2_completion=None, \n",
    "    task_1_completion=None, \n",
    "    _meta_character_list=meta_character_list,\n",
    "    seed=42\n",
    "):\n",
    "    \n",
    "    if task_2_completion is None:\n",
    "        task_1_completion, task_2_completion = run_task_2(full_text, client)\n",
    "        \n",
    "    \n",
    "    task_3_prompt_string = get_task_3_prompt_string(\n",
    "        task_2_response=json.loads(task_2_completion.choices[0].message.content),\n",
    "        characters=characters,\n",
    "        aliases=aliases,\n",
    "        meta_characters=_meta_character_list\n",
    "    )\n",
    "    \n",
    "    task_3_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_3_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_3_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion, task_3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client,\n",
    "    characters=test_data['task_3_characters'][test_id],\n",
    "    aliases=test_data['task_3_aliases'][test_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=155, prompt_tokens=988, total_tokens=1143)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"speaker_matched\": \"Unknown\",\n",
      "      \"recipient_matched\": \"Apatosaurus\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"speaker_matched\": \"Harry\",\n",
      "      \"recipient_matched\": \"Mum\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"speaker_matched\": \"Mum\",\n",
      "      \"recipient_matched\": \"Harry\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_3_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speaker_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "        'recipient_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "#         'spoken_words_only': {\n",
    "#             'case_sensitive': True,\n",
    "#             'remove_leading_the': False\n",
    "#         },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, _, completion_3 = run_task_3(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client,\n",
    "            characters=test_data['task_3_characters'][test_id],\n",
    "            aliases=test_data['task_3_aliases'][test_id]\n",
    "        )\n",
    "           \n",
    "        if run_task_3_test_i(test_id, test_data, completion_3, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_3_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for corpus\n",
    "\n",
    "Now that our prompts are passing all tests, we run the method for all books in the corpus and save the results to disk....\n",
    "\n",
    "# TODO:\n",
    "- add a 'self' match example to data (still usig himself)\n",
    "- check Noi and 'his dad' - shouldn't it be Dad? (The Storm Whale In Winter)\n",
    "- add Narrator handling/example (e.g. There's A Monster In Your Book)\n",
    "- add a flag for if it is a character match or something else ('Everyone' Narrator' etc!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: that this only handles two chunks currently. And is not an optimal way of splitting since sections of speech may be separated, for example.\n",
    "# max_chunk_size = 9677\n",
    "multi_chunk_books = {\n",
    "    'The Enormous Crocodile': 9677,\n",
    "    'How The Grinch Stole Christmas': 3794, \n",
    "    'Farmer Duck': 1160\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['book_length'] = np.array([len(t) for t in df.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not story books and are also the longest so would possibly need splitting.\n",
    "remove_non_stories = [\n",
    "    'All Year Round', 'All About Feelings', 'Ten in the Bed and Other Counting Rhymes', 'Why Am I An Insect',\n",
    "    'How The Grinch Stole Christmas', \n",
    "    'Farmer Duck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='book_length', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(\n",
    "    title, chunk_name, chunk_text, client, book_df, \n",
    "    c1_results_dict, c2_results_dict, c3_results_dict\n",
    "):\n",
    "    \n",
    "    print(\"Book: \", title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    completion_1, completion_2, completion_3 = run_task_3(\n",
    "        full_text=chunk_text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title],\n",
    "        _meta_character_list=meta_character_list\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion_3.choices[0].message.content)\n",
    "    \n",
    "    book_df['c1_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c1_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c1_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c1_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c2_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c2_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c2_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c2_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c3_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c3_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c3_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c3_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    \n",
    "    book_df['title'].append(chunk_name)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'].append(len(json_response['speech_sections']))\n",
    "    \n",
    "    c3_results_dict[chunk_name] = json_response\n",
    "    \n",
    "    c1_results_dict[chunk_name] = json.loads(completion_1.choices[0].message.content)\n",
    "    c2_results_dict[chunk_name] = json.loads(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Bad-Tempered Ladybird\n",
      "Book:  Harry and the Dinosaurs go to School\n",
      "Book:  Gruff the Grump\n",
      "Book:  Night Monkey Day Monkey\n",
      "Book:  The Paper Dolls\n",
      "Book:  Snow White, Star Striker\n",
      "Book:  Caterpillar Butterfly\n",
      "Book:  These Are Animals\n",
      "Book:  Elmer and the Wind\n",
      "Book:  Father Christmas Needs A Wee\n",
      "Book:  Eleanor Won't Share\n",
      "Book:  Romp in the Swamp\n",
      "Book:  The Polar Express\n",
      "Book:  Superworm\n",
      "Book:  Mini Beasties\n",
      "Book:  Elmer and Rose\n",
      "Book:  The Smartest Giant in Town\n",
      "Book:  Supertato Veggies Assemble\n",
      "Book:  Ten Tall Giraffes\n",
      "Book:  Wiggling Worms At Work\n",
      "Book:  Too Shy For Show And Tell\n",
      "Book:  Born to be a Butterfly\n",
      "Book:  All For One\n",
      "Book:  Knock Knock Dinosaur\n",
      "Book:  Barry the Fish With Fingers and the Hairy Scary Monster\n",
      "Book:  Squash the Spider\n",
      "Book:  Little by Little\n",
      "Book:  The Tiger Who Came To Tea\n",
      "Book:  Stick Man\n",
      "Book:  When Granny Saved Christmas\n",
      "Book:  After the Storm\n",
      "Book:  Cinderella's Ballet Shoes\n",
      "Book:  Bottoms Up!\n",
      "Book:  Supertato\n",
      "Book:  Who Will Sing My Puff-a-bye\n",
      "Book:  Can't You Sleep Little Bear\n",
      "Book:  The Duchess and Guy\n",
      "Book:  Grandad's Island\n",
      "Book:  Harry and the Robots\n",
      "Book:  You Can't Take An Elephant On The Bus\n",
      "Book:  Where's My Cuddle\n",
      "Book:  Jesus' Christmas Party\n",
      "Book:  Princess Mirror-Belle And The Dragon Pox\n",
      "Book:  We're Going on a Bear Hunt\n",
      "Book:  The Ugly Duckling\n",
      "Book:  Room on the Broom\n",
      "Book:  Harry and the Bucketful of Dinosaurs\n",
      "Book:  Grandma Bird\n",
      "Book:  We're Going On A Lion Hunt\n",
      "Book:  The Wheels on the Bus\n",
      "Book:  The Cave\n",
      "Book:  Where's My Teddy\n",
      "Book:  The Singing Mermaid\n",
      "Book:  What The Ladybird Heard Next\n",
      "Book:  The Pirates Next Door\n",
      "Book:  Captain Duck\n",
      "Book:  The Little Bully\n",
      "Book:  All In One Piece\n",
      "Book:  The Gruffalo's Child\n",
      "Book:  Elephant Learns to Share\n",
      "Book:  One Snowy Night\n",
      "Book:  Each Peach Pear Plum\n",
      "Book:  The Squirrels Who Squabbled\n",
      "Book:  Knock Knock Pirate\n",
      "Book:  Who Will Save Us\n",
      "Book:  Jack Breaks The Beanstalk\n",
      "Book:  The Snowiest Christmas Ever\n",
      "Book:  Jack and the Beanstalk\n",
      "Book:  Super Sid The Silly Sausage Dog\n",
      "Book:  The Christmas Extravaganza Hotel\n",
      "Book:  Cinder the Bubble-Blowing Dragon\n",
      "Book:  The Animal Boogie\n",
      "Book:  The Truth According to Arthur\n",
      "Book:  Monkey Puzzle\n",
      "Book:  Little Monkey\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': [],\n",
    "    'c1_completion_tokens': [],\n",
    "    'c1_prompt_tokens': [],\n",
    "    'c1_total_tokens': [],\n",
    "    'c1_system_fingerprint': [],\n",
    "    'c2_completion_tokens': [],\n",
    "    'c2_prompt_tokens': [],\n",
    "    'c2_total_tokens': [],\n",
    "    'c2_system_fingerprint': [],\n",
    "    'c3_completion_tokens': [],\n",
    "    'c3_prompt_tokens': [],\n",
    "    'c3_total_tokens': [],\n",
    "    'c3_system_fingerprint': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "c1_results_dict = {}\n",
    "c2_results_dict = {}\n",
    "c3_results_dict = {}\n",
    "\n",
    "for book_id in df.index:\n",
    "    \n",
    "    title = df.iloc[book_id].Title\n",
    "    \n",
    "    if title not in remove_non_stories and book_id>119:\n",
    "        book_text = df.iloc[book_id].Text\n",
    "#         if len(book_text) > max_chunk_size:\n",
    "    \n",
    "        if title in multi_chunk_books.keys():\n",
    "            max_chunk_size = multi_chunk_books[title]\n",
    "            last_newline = book_text[0:max_chunk_size].rfind('\\n')\n",
    "            chunks = {\n",
    "                ''.join(['_chunk_a_', title]): book_text[0:max_chunk_size],\n",
    "                ''.join(['_chunk_b_', title]): book_text[max_chunk_size:]\n",
    "            }\n",
    "            for chunk in chunks.keys():\n",
    "                process_chunk(\n",
    "                    title=title, \n",
    "                    chunk_name=chunk, \n",
    "                    chunk_text=chunks[chunk], \n",
    "                    client=client, \n",
    "                    book_df=book_df, \n",
    "                    c1_results_dict=c1_results_dict, \n",
    "                    c2_results_dict=c2_results_dict, \n",
    "                    c3_results_dict=c3_results_dict\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            process_chunk(\n",
    "                title=title, \n",
    "                chunk_name=title, \n",
    "                chunk_text=book_text, \n",
    "                client=client, \n",
    "                book_df=book_df, \n",
    "                c1_results_dict=c1_results_dict, \n",
    "                c2_results_dict=c2_results_dict, \n",
    "                c3_results_dict=c3_results_dict\n",
    "            )\n",
    "\n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(characters.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_df_complete = book_df.copy().reset_index().drop(columns='index')\n",
    "# book_df_complete.to_json('data/gpt4_output_summary_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/gpt4_output_summary_corpus.json', 'r') as outfile:\n",
    "#     temp_bdf = pd.read_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_df = pd.concat([temp_bdf, book_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.Title =='Farmer Duck'].iloc[0].Text.find('just before dawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.Title =='How The Grinch Stole Christmas']#.iloc[0].Text.find('Then he slunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Night Before Christmas\n",
      "Sugarlump and the Unicorn\n",
      "The Gruffalo\n",
      "The Monstrous Tale of Celery Crumble\n",
      "Peace at Last\n",
      "Sing A Song Of Bottoms\n",
      "Barry The Fish With Fingers\n",
      "The Troll\n",
      "The Storm Whale In Winter\n",
      "There's A Monster In Your Book\n",
      "Once Upon A Unicorn Horn\n",
      "Mind Your Manners\n",
      "The Princess and the Wizard\n",
      "Kipper's Toybox\n",
      "Oi Frog!\n",
      "Elmer and the Lost Teddy\n",
      "The Hungry Caterpillar\n",
      "A Squash and a Squeeze\n",
      "Keith The Cat With The Magic Hat\n",
      "Santa is Coming to Devon\n",
      "_chunk_a_The Enormous Crocodile\n",
      "_chunk_b_The Enormous Crocodile\n",
      "Harry and the Dinosaurs Go Wild\n",
      "Open Very Carefully, A Book With Bite!\n",
      "The Most Wonderful Gift In The World\n",
      "Elmer and Grandpa Eldo\n",
      "Tabby McTat\n",
      "Harry and the Dinosaurs at the Museum\n",
      "The Hedgehog's Balloon\n",
      "Jasper's Jungle Journey\n",
      "The Owl Who Was Afraid Of The Dark\n",
      "The Cross Rabbit\n",
      "Shark In The Dark\n",
      "A Thing Called Snow\n",
      "Yoga Babies\n",
      "The Way Home For Wolf\n",
      "Elmer and Wilbur\n",
      "One Starry Night\n",
      "I Need A Wee\n",
      "Harry and the Dinosaurs say Raahh!\n",
      "An Alphabet Of Stories\n",
      "The Owl's Lesson\n",
      "The Very Lazy Ladybird\n",
      "The Dinosaur Department Store\n",
      "The Fox's Hiccups\n",
      "You Choose\n",
      "Whatever Next!\n",
      "Cave Baby\n",
      "The Rescue Party\n",
      "Elmer and the Stranger\n",
      "Dinosaurs Love Underpants\n",
      "Zog\n",
      "Lost in Snow\n",
      "Monkey Needs to Listen\n",
      "Gordon's Great Escape\n",
      "Dogger\n",
      "Is It Betime Wibbly Pig\n",
      "Wide-awake Hedgehog\n",
      "Doug The Bug That Went Boing\n",
      "Tyrannosaurus Drip\n",
      "Elmer in the Snow\n",
      "Sharing A Shell\n",
      "The Rhyming Rabbit\n",
      "The Enormous Turnip\n",
      "The Same But Different Too\n",
      "Sir Charlie Stinky Socks and the Really Big Adventure\n",
      "The Snail and the Whale\n",
      "Ruby's Worry\n",
      "The Smeds and The Smoos\n",
      "I Am Amelia Earhart\n",
      "It's Christmas\n",
      "She Rex\n",
      "Wake Up, Sleeping Beauty\n",
      "No-Bot\n",
      "The Bumblebear\n",
      "Mole Hill\n",
      "Dragon Post\n",
      "A Letter to Santa\n",
      "Oi Dog!\n",
      "Scruffy Bear and the Six White Mice\n",
      "The Gingerbread Man\n",
      "The Lighthouse Keeper's Lunch\n",
      "Dogs Don't Do Ballet\n",
      "Hippo Owns Up\n",
      "Lost and Found\n",
      "Elmer on Stilts\n",
      "Giraffe is Left Out\n",
      "The Tree That's Meant To Be\n",
      "The Dinosaur That Pooped Christmas\n",
      "Lion's in a Flap\n",
      "How to Catch a Star\n",
      "The Very Busy Spider\n",
      "The Detective Dog\n",
      "The Book With No Pictures\n",
      "The First Christmas\n",
      "Careful Santa!\n",
      "Norman The Slug With The Silly Shell\n",
      "Owl Babies\n",
      "The Jolly Postman or Other People's Letters\n",
      "What The Ladybird Heard\n",
      "Charlie Cook's Favourite Book\n",
      "The Storm Whale\n",
      "Ravi's Roar\n",
      "The Runaway Pea\n",
      "Goldilocks and the Three Bears\n",
      "Zog and the Flying Doctors\n",
      "Kipper's A to Z\n",
      "Little Red Riding Hood\n",
      "The Three Little Pigs\n",
      "Lenny Makes A Wish\n",
      "The Christmas Story\n",
      "Knock Knock Alien\n",
      "Boogie Bear\n",
      "Tiger Has a Tantrum\n",
      "The Teeny Weeny Tadpole\n",
      "Santa to the Rescue\n",
      "_chunk_a_How The Grinch Stole Christmas\n"
     ]
    }
   ],
   "source": [
    "# Convert results dicts to dataframe of all speech sections and save to disk:\n",
    "\n",
    "all_speech_sections = {\n",
    "    'book': [],\n",
    "    'speech_section_id': [], # speech section id within book\n",
    "    'speaker': [],\n",
    "    'recipient': [],\n",
    "    'speaker_matched': [],\n",
    "    'recipient_matched': [],\n",
    "    'speech_text': [],\n",
    "    'spoken_words_only': [],\n",
    "    'spoken_word_count': []\n",
    "}\n",
    "\n",
    "for book in c3_results_dict.keys():\n",
    "    print(book)\n",
    "    for si, section in enumerate(c3_results_dict[book]['speech_sections']):\n",
    "        all_speech_sections['book'].append(book)\n",
    "        for key in all_speech_sections.keys():\n",
    "            if key not in ['book', 'spoken_word_count', 'speech_text', 'spoken_words_only']:\n",
    "                all_speech_sections[key].append(section[key])\n",
    "        \n",
    "        # Handling edge cases where a speach section is split:\n",
    "        si_corrected = si\n",
    "        if si >= len(c1_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c1_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['speech_text'].append(c1_results_dict[book]['speech_sections'][si_corrected]['speech_text'])\n",
    "        \n",
    "        if si >= len(c2_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c2_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['spoken_words_only'].append(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only'])\n",
    "        all_speech_sections['spoken_word_count'].append(len(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections = pd.DataFrame(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ass = all_speech_sections.copy().reset_index().drop(columns='index')\n",
    "# ass.to_json('data/gpt4_all_speech_sections_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/gpt4_all_speech_sections_corpus.json', 'r') as outfile:\n",
    "    all_speech_sections = pd.read_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_speech_sections = pd.concat([temp_ass, all_speech_sections])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We replace any chunked book titles with the original, adding columns to retain chunk information in case needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections['chunk_titles'] = all_speech_sections['book']\n",
    "all_speech_sections['book'] = [\n",
    "    title\n",
    "    if '_chunk_' not in title\n",
    "    else title.split('_')[3]\n",
    "    for title in all_speech_sections.book]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We replace compound characters ('and' and ','):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_compound_characters(_speech_sections, characters, character_type='speaker'):\n",
    "    \n",
    "    compound_character_data = {\n",
    "        'book': [],#'all' for c in meta_character_list],\n",
    "        'name': [],#c for c in meta_character_list],\n",
    "        'gender': [],#'NGS' for c in meta_character_list],\n",
    "        'human': [],#'NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "        'alias_count': [],#0 for c in meta_character_list]\n",
    "    }\n",
    "\n",
    "    matched_character = []\n",
    "    compound_count = 0\n",
    "    for ri, row in _speech_sections.iterrows():\n",
    "        \n",
    "        book_characters = characters[characters.book == row.book]\n",
    "        \n",
    "        cpts = flatten([\n",
    "            s.split(',') for s in row[character_type].split('and')\n",
    "        ])\n",
    "                                \n",
    "        if len(cpts) > 1:\n",
    "            compound_count += 1\n",
    "            cpts = [c.strip() for c in cpts]\n",
    "            character_list = []\n",
    "            for cpt in cpts:\n",
    "                if cpt.lower() in list(book_characters.name.str.lower()):\n",
    "                    character_list.append(cpt)\n",
    "\n",
    "            if len(cpts) != len(character_list):\n",
    "                # handles mr + mrs surname etc\n",
    "#                 print(row[character_type])\n",
    "                try:\n",
    "                    broadcast_name = cpts[0] + ' ' + cpts[1].split(' ')[1].strip()\n",
    "                    if broadcast_name.lower() in list(book_characters.name.str.lower()):\n",
    "                        character_list.append(broadcast_name)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "            genders = []        \n",
    "            humans = []\n",
    "            for c in character_list:\n",
    "                _char = book_characters[book_characters.name.str.lower() == c.lower()].iloc[0]\n",
    "                genders.append(_char.gender)\n",
    "                humans.append(_char.human)\n",
    "\n",
    "            if sum([g == 'F' for g in genders]) == len(genders):\n",
    "                compound_gender = 'F'\n",
    "            elif sum([g == 'M' for g in genders]) == len(genders):\n",
    "                compound_gender = 'M'\n",
    "            else:\n",
    "                compound_gender = 'NGS'\n",
    "\n",
    "            if sum([h == 'H' for h in humans]) == len(humans):\n",
    "                compound_human = 'H'\n",
    "            else:\n",
    "                compound_human = 'NH'\n",
    "\n",
    "            compound_character_data['book'].append(row.book)\n",
    "            compound_character_data['alias_count'].append(0)\n",
    "            compound_character_data['name'].append(row[character_type])\n",
    "            compound_character_data['gender'].append(compound_gender)\n",
    "            compound_character_data['human'].append(compound_human)\n",
    "            \n",
    "            matched_character.append(row[character_type])\n",
    "        else:\n",
    "            matched_character.append(row[f\"{character_type}_matched\"])\n",
    "            \n",
    "    _speech_sections[f\"{character_type}_matched\"] = matched_character\n",
    "    print(f\"Compound count = {compound_count}\")\n",
    "    return pd.DataFrame(compound_character_data), _speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound count = 135\n",
      "Compound count = 320\n"
     ]
    }
   ],
   "source": [
    "compound_speakers, all_speech_sections = replace_compound_characters(all_speech_sections, characters, character_type='speaker')\n",
    "compound_recipients, all_speech_sections = replace_compound_characters(all_speech_sections, characters, character_type='recipient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3913"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_characters = pd.concat([compound_speakers, compound_recipients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['and' in s for s in all_speech_sections.speaker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_characters = compound_characters.groupby(['book', 'name']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We add the metacharacter data to the character table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_data = pd.DataFrame({\n",
    "    'book': ['all' for c in meta_character_list],\n",
    "    'name': [c for c in meta_character_list],\n",
    "    'gender': ['NGS' for c in meta_character_list],\n",
    "    'human': ['NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "    'alias_count': [0 for c in meta_character_list]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.concat([\n",
    "    characters, meta_character_data#, compound_characters\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'self' with character name for ease of analysis (and flag self)\n",
    "all_speech_sections['self_talk_flag'] = [\n",
    "    True if r == 'Self'\n",
    "    else False \n",
    "    for r in all_speech_sections.recipient_matched\n",
    "]\n",
    "all_speech_sections['recipient_matched'] = [\n",
    "    s if r == 'Self'\n",
    "    else r \n",
    "    for s,r in zip(all_speech_sections.speaker_matched, all_speech_sections.recipient_matched)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = all_speech_sections.merge(characters, how='left', left_on=['speaker_matched', 'book'], right_on=['name', 'book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = speakers.merge(characters, how='left', left_on=['recipient_matched', 'book'], right_on=['name', 'book'], suffixes=['_speaker', '_recipient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "# for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "for c in [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs'#, 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]:\n",
    "  \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "# for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "for c in compound_characters.name:\n",
    "  \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>\"Now, Dasher! now, Dancer!\\nnow, Prancer and V...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>\"Happy\\nChristmas to all, and to all a good\\nn...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>False</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>56</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>True</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! I can grant horses' wishes.</td>\n",
       "      <td>33</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>False</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         book  speech_section_id       speaker  recipient  \\\n",
       "0  The Night Before Christmas                  0  St. Nicholas   Reindeer   \n",
       "1  The Night Before Christmas                  1  St. Nicholas   Everyone   \n",
       "2   Sugarlump and the Unicorn                  0     Sugarlump    himself   \n",
       "3   Sugarlump and the Unicorn                  1     Sugarlump    himself   \n",
       "4   Sugarlump and the Unicorn                  2       unicorn  Sugarlump   \n",
       "\n",
       "  speaker_matched recipient_matched  \\\n",
       "0    St. Nicholas          Reindeer   \n",
       "1    St. Nicholas          Everyone   \n",
       "2       Sugarlump         Sugarlump   \n",
       "3       Sugarlump         Sugarlump   \n",
       "4         unicorn         Sugarlump   \n",
       "\n",
       "                                         speech_text  \\\n",
       "0  \"Now, Dasher! now, Dancer!\\nnow, Prancer and V...   \n",
       "1  \"Happy\\nChristmas to all, and to all a good\\nn...   \n",
       "2  \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3  \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4  \"Done!\" came a voice, and there stood a beast\\...   \n",
       "\n",
       "                                   spoken_words_only  spoken_word_count  \\\n",
       "0  Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1   Happy Christmas to all, and to all a good night!                 48   \n",
       "2  Here in the children's bedroom Is where I want...                106   \n",
       "3  Oh to be out in the big wide world! I wish I c...                 56   \n",
       "4                  Done! I can grant horses' wishes.                 33   \n",
       "\n",
       "                 chunk_titles  self_talk_flag  name_speaker gender_speaker  \\\n",
       "0  The Night Before Christmas           False  St. Nicholas              M   \n",
       "1  The Night Before Christmas           False  St. Nicholas              M   \n",
       "2   Sugarlump and the Unicorn            True     Sugarlump              M   \n",
       "3   Sugarlump and the Unicorn            True     Sugarlump              M   \n",
       "4   Sugarlump and the Unicorn           False       unicorn              F   \n",
       "\n",
       "  human_speaker  alias_count_speaker name_recipient gender_recipient  \\\n",
       "0             H                  1.0       Reindeer              NGS   \n",
       "1             H                  1.0       Everyone              NGS   \n",
       "2            NH                  0.0      Sugarlump                M   \n",
       "3            NH                  0.0      Sugarlump                M   \n",
       "4            NH                  0.0      Sugarlump                M   \n",
       "\n",
       "  human_recipient  alias_count_recipient  \n",
       "0              NH                    0.0  \n",
       "1               H                    0.0  \n",
       "2              NH                    0.0  \n",
       "3              NH                    0.0  \n",
       "4              NH                    0.0  "
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3913"
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03628929210324559"
      ]
     },
     "execution_count": 1019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05034500383337592"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03168924099156657"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['and' in s for s in speakers.speaker])/len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3913"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3913"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>34</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>troll</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>Troll</td>\n",
       "      <td>The plank! The plank! Make him walk the plank!</td>\n",
       "      <td>The plank! The plank! Make him walk the plank!</td>\n",
       "      <td>46</td>\n",
       "      <td>The Troll</td>\n",
       "      <td>False</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Troll</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Once Upon A Unicorn Horn</td>\n",
       "      <td>3</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>June</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>June</td>\n",
       "      <td>â€œDonâ€™t worry,â€ Mum and Dad said.\\nâ€œWe can fix ...</td>\n",
       "      <td>Donâ€™t worry. We can fix it together!</td>\n",
       "      <td>36</td>\n",
       "      <td>Once Upon A Unicorn Horn</td>\n",
       "      <td>False</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>June</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>The Most Wonderful Gift In The World</td>\n",
       "      <td>14</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>US?</td>\n",
       "      <td>US?</td>\n",
       "      <td>3</td>\n",
       "      <td>The Most Wonderful Gift In The World</td>\n",
       "      <td>False</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>3</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>What a lovely surprise. Whatâ€™s that balanced o...</td>\n",
       "      <td>What a lovely surprise. Whatâ€™s that balanced o...</td>\n",
       "      <td>58</td>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>False</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>5</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Fancy you remembering that.</td>\n",
       "      <td>Fancy you remembering that.</td>\n",
       "      <td>27</td>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>False</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>12</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>â€œAll the better\\nto hear you with.â€</td>\n",
       "      <td>All the better to hear you with.</td>\n",
       "      <td>32</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>False</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>14</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>â€œAll the better\\nto see you withâ€</td>\n",
       "      <td>All the better to see you with</td>\n",
       "      <td>30</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>False</td>\n",
       "      <td>wolf (disguised as grandmother)</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Three Little Pigs</td>\n",
       "      <td>15</td>\n",
       "      <td>man pulling a cart laden with heavy bricks and...</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>man pulling a cart laden with heavy bricks and...</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>â€œIâ€™d be glad to,â€ said the man. â€œPulling this\\...</td>\n",
       "      <td>Iâ€™d be glad to. Pulling this load is hard work.</td>\n",
       "      <td>47</td>\n",
       "      <td>The Three Little Pigs</td>\n",
       "      <td>False</td>\n",
       "      <td>man pulling a cart laden with heavy bricks and...</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>The Three Little Pigs</td>\n",
       "      <td>17</td>\n",
       "      <td>first and second little pigs</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>first and second little pigs</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>â€œItâ€™s us. Your brothers. Please let us in.â€</td>\n",
       "      <td>Itâ€™s us. Your brothers. Please let us in.</td>\n",
       "      <td>41</td>\n",
       "      <td>The Three Little Pigs</td>\n",
       "      <td>False</td>\n",
       "      <td>first and second little pigs</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>third little pig</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Tiger Has a Tantrum</td>\n",
       "      <td>3</td>\n",
       "      <td>Lion and Little Lion</td>\n",
       "      <td>Miss Bird</td>\n",
       "      <td>Lion and Little Lion</td>\n",
       "      <td>Miss Bird</td>\n",
       "      <td>They told Miss Bird.</td>\n",
       "      <td>Miss Bird.</td>\n",
       "      <td>10</td>\n",
       "      <td>Tiger Has a Tantrum</td>\n",
       "      <td>False</td>\n",
       "      <td>Lion and Little Lion</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miss Bird</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      book  speech_section_id  \\\n",
       "126                              The Troll                 34   \n",
       "150               Once Upon A Unicorn Horn                  3   \n",
       "411   The Most Wonderful Gift In The World                 14   \n",
       "415                 Elmer and Grandpa Eldo                  3   \n",
       "417                 Elmer and Grandpa Eldo                  5   \n",
       "...                                    ...                ...   \n",
       "3728                Little Red Riding Hood                 12   \n",
       "3730                Little Red Riding Hood                 14   \n",
       "3755                 The Three Little Pigs                 15   \n",
       "3757                 The Three Little Pigs                 17   \n",
       "3838                   Tiger Has a Tantrum                  3   \n",
       "\n",
       "                                                speaker  \\\n",
       "126                          Ben Buckle and Percy Patch   \n",
       "150                                         Mum and Dad   \n",
       "411                                       Esme and Bear   \n",
       "415                                        Grandpa Eldo   \n",
       "417                                        Grandpa Eldo   \n",
       "...                                                 ...   \n",
       "3728                    wolf (disguised as grandmother)   \n",
       "3730                    wolf (disguised as grandmother)   \n",
       "3755  man pulling a cart laden with heavy bricks and...   \n",
       "3757                       first and second little pigs   \n",
       "3838                               Lion and Little Lion   \n",
       "\n",
       "                   recipient  \\\n",
       "126                    troll   \n",
       "150                     June   \n",
       "411     Little Bunny Boo-Boo   \n",
       "415                    Elmer   \n",
       "417                    Elmer   \n",
       "...                      ...   \n",
       "3728  Little Red Riding Hood   \n",
       "3730  Little Red Riding Hood   \n",
       "3755        third little pig   \n",
       "3757        third little pig   \n",
       "3838               Miss Bird   \n",
       "\n",
       "                                        speaker_matched  \\\n",
       "126                          Ben Buckle and Percy Patch   \n",
       "150                                         Mum and Dad   \n",
       "411                                       Esme and Bear   \n",
       "415                                        Grandpa Eldo   \n",
       "417                                        Grandpa Eldo   \n",
       "...                                                 ...   \n",
       "3728                    wolf (disguised as grandmother)   \n",
       "3730                    wolf (disguised as grandmother)   \n",
       "3755  man pulling a cart laden with heavy bricks and...   \n",
       "3757                       first and second little pigs   \n",
       "3838                               Lion and Little Lion   \n",
       "\n",
       "           recipient_matched  \\\n",
       "126                    Troll   \n",
       "150                     June   \n",
       "411     Little Bunny Boo-Boo   \n",
       "415                    Elmer   \n",
       "417                    Elmer   \n",
       "...                      ...   \n",
       "3728  Little Red Riding Hood   \n",
       "3730  Little Red Riding Hood   \n",
       "3755        third little pig   \n",
       "3757        third little pig   \n",
       "3838               Miss Bird   \n",
       "\n",
       "                                            speech_text  \\\n",
       "126      The plank! The plank! Make him walk the plank!   \n",
       "150   â€œDonâ€™t worry,â€ Mum and Dad said.\\nâ€œWe can fix ...   \n",
       "411                                                 US?   \n",
       "415   What a lovely surprise. Whatâ€™s that balanced o...   \n",
       "417                         Fancy you remembering that.   \n",
       "...                                                 ...   \n",
       "3728                â€œAll the better\\nto hear you with.â€   \n",
       "3730                  â€œAll the better\\nto see you withâ€   \n",
       "3755  â€œIâ€™d be glad to,â€ said the man. â€œPulling this\\...   \n",
       "3757        â€œItâ€™s us. Your brothers. Please let us in.â€   \n",
       "3838                               They told Miss Bird.   \n",
       "\n",
       "                                      spoken_words_only  spoken_word_count  \\\n",
       "126      The plank! The plank! Make him walk the plank!                 46   \n",
       "150                Donâ€™t worry. We can fix it together!                 36   \n",
       "411                                                 US?                  3   \n",
       "415   What a lovely surprise. Whatâ€™s that balanced o...                 58   \n",
       "417                         Fancy you remembering that.                 27   \n",
       "...                                                 ...                ...   \n",
       "3728                   All the better to hear you with.                 32   \n",
       "3730                     All the better to see you with                 30   \n",
       "3755    Iâ€™d be glad to. Pulling this load is hard work.                 47   \n",
       "3757          Itâ€™s us. Your brothers. Please let us in.                 41   \n",
       "3838                                         Miss Bird.                 10   \n",
       "\n",
       "                              chunk_titles  self_talk_flag  \\\n",
       "126                              The Troll           False   \n",
       "150               Once Upon A Unicorn Horn           False   \n",
       "411   The Most Wonderful Gift In The World           False   \n",
       "415                 Elmer and Grandpa Eldo           False   \n",
       "417                 Elmer and Grandpa Eldo           False   \n",
       "...                                    ...             ...   \n",
       "3728                Little Red Riding Hood           False   \n",
       "3730                Little Red Riding Hood           False   \n",
       "3755                 The Three Little Pigs           False   \n",
       "3757                 The Three Little Pigs           False   \n",
       "3838                   Tiger Has a Tantrum           False   \n",
       "\n",
       "                                           name_speaker gender_speaker  \\\n",
       "126                          Ben Buckle and Percy Patch              M   \n",
       "150                                         Mum and Dad            NGS   \n",
       "411                                       Esme and Bear            NGS   \n",
       "415                                        Grandpa Eldo              F   \n",
       "417                                        Grandpa Eldo              F   \n",
       "...                                                 ...            ...   \n",
       "3728                    wolf (disguised as grandmother)              F   \n",
       "3730                    wolf (disguised as grandmother)              F   \n",
       "3755  man pulling a cart laden with heavy bricks and...              M   \n",
       "3757                       first and second little pigs              F   \n",
       "3838                               Lion and Little Lion              M   \n",
       "\n",
       "     human_speaker  alias_count_speaker          name_recipient  \\\n",
       "126              H                  0.0                   Troll   \n",
       "150              H                  0.0                    June   \n",
       "411             NH                  0.0    Little Bunny Boo-Boo   \n",
       "415              H                  0.0                   Elmer   \n",
       "417              H                  0.0                   Elmer   \n",
       "...            ...                  ...                     ...   \n",
       "3728             H                  0.0  Little Red Riding Hood   \n",
       "3730             H                  0.0  Little Red Riding Hood   \n",
       "3755             H                  0.0        third little pig   \n",
       "3757             H                  0.0        third little pig   \n",
       "3838            NH                  0.0               Miss Bird   \n",
       "\n",
       "     gender_recipient human_recipient  alias_count_recipient  \n",
       "126                 M              NH                    0.0  \n",
       "150                 F               H                    0.0  \n",
       "411                 F              NH                    0.0  \n",
       "415                 M              NH                    0.0  \n",
       "417                 M              NH                    0.0  \n",
       "...               ...             ...                    ...  \n",
       "3728                F              H                     0.0  \n",
       "3730                F              H                     0.0  \n",
       "3755                M              NH                    1.0  \n",
       "3757                M              NH                    1.0  \n",
       "3838                F              NH                    0.0  \n",
       "\n",
       "[124 rows x 19 columns]"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[['and' in s for s in speakers.speaker]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['The Troll' 'The Princess and the Wizard' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Harry and the Dinosaurs at the Museum' 'The Cross Rabbit'\n",
      " 'A Thing Called Snow' 'The Way Home For Wolf' 'Elmer and Wilbur'\n",
      " 'I Need A Wee' 'Cave Baby' 'The Rescue Party' 'Zog' 'Dogger'\n",
      " 'Is It Betime Wibbly Pig' 'Wide-awake Hedgehog' 'Tyrannosaurus Drip'\n",
      " 'Sir Charlie Stinky Socks and the Really Big Adventure' \"Ruby's Worry\"\n",
      " 'I Am Amelia Earhart' 'She Rex' 'Mole Hill' 'Oi Dog!'\n",
      " \"The Lighthouse Keeper's Lunch\" \"Dogs Don't Do Ballet\"\n",
      " \"The Tree That's Meant To Be\" 'The Dinosaur That Pooped Christmas'\n",
      " 'The Book With No Pictures' 'What The Ladybird Heard'\n",
      " \"Charlie Cook's Favourite Book\" \"Ravi's Roar\"\n",
      " 'Zog and the Flying Doctors' 'The Three Little Pigs' 'Knock Knock Alien'\n",
      " 'Boogie Bear' 'The Bad-Tempered Ladybird' 'Snow White, Star Striker'\n",
      " 'Elmer and the Wind' \"Eleanor Won't Share\"\n",
      " 'Barry the Fish With Fingers and the Hairy Scary Monster' 'Stick Man'\n",
      " 'Peace at Last' 'Elmer and Grandpa Eldo' 'Elmer and the Stranger'\n",
      " 'Dinosaurs Love Underpants' 'The Enormous Turnip']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_recipient.isna()].book.unique()))\n",
    "print(speakers[speakers.name_recipient.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "['Sing A Song Of Bottoms' 'The Troll' \"Kipper's Toybox\"\n",
      " 'Elmer and the Lost Teddy' 'Santa is Coming to Devon'\n",
      " 'The Enormous Crocodile' 'Harry and the Dinosaurs Go Wild'\n",
      " 'Harry and the Dinosaurs at the Museum' 'The Cross Rabbit' 'Yoga Babies'\n",
      " 'Elmer and Wilbur' 'I Need A Wee' \"The Owl's Lesson\" 'Cave Baby'\n",
      " 'The Rescue Party' 'Zog' 'Dogger' 'Is It Betime Wibbly Pig'\n",
      " 'Wide-awake Hedgehog' 'Tyrannosaurus Drip' 'The Rhyming Rabbit'\n",
      " 'I Am Amelia Earhart' 'She Rex' 'Mole Hill' 'Oi Dog!'\n",
      " \"The Lighthouse Keeper's Lunch\" \"The Tree That's Meant To Be\"\n",
      " 'The Dinosaur That Pooped Christmas'\n",
      " \"The Jolly Postman or Other People's Letters\" 'What The Ladybird Heard'\n",
      " \"Ravi's Roar\" 'The Runaway Pea' 'Zog and the Flying Doctors'\n",
      " 'The Three Little Pigs' 'Lenny Makes A Wish' 'Knock Knock Alien'\n",
      " 'Boogie Bear' 'Father Christmas Needs A Wee' 'The Polar Express'\n",
      " 'Mini Beasties' 'The Smartest Giant in Town'\n",
      " 'Barry the Fish With Fingers and the Hairy Scary Monster' 'Stick Man'\n",
      " 'Sharing A Shell' \"Dogs Don't Do Ballet\" 'Santa to the Rescue']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_speaker.isna()].book.unique()))\n",
    "print(speakers[speakers.name_speaker.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_speaker_books = iter(speakers[speakers.name_speaker.isna()].book.unique())\n",
    "# null_speaker_books = iter(speakers[speakers.name_recipient.isna()].book.unique())\n",
    "# null_speaker_books = iter(\n",
    "#     set(speakers[speakers.name_recipient.isna()].book.unique()) - set(speakers[speakers.name_speaker.isna()].book.unique())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sing A Song Of Bottoms', 'The Troll', \"Kipper's Toybox\", 'Elmer and the Lost Teddy', 'Santa is Coming to Devon', 'The Enormous Crocodile', 'Harry and the Dinosaurs Go Wild', 'Harry and the Dinosaurs at the Museum', 'The Cross Rabbit', 'Yoga Babies', 'Elmer and Wilbur', 'I Need A Wee', \"The Owl's Lesson\", 'Cave Baby', 'The Rescue Party', 'Zog', 'Dogger', 'Is It Betime Wibbly Pig', 'Wide-awake Hedgehog', 'Tyrannosaurus Drip', 'The Rhyming Rabbit', 'I Am Amelia Earhart', 'She Rex', 'Mole Hill', 'Oi Dog!', \"The Lighthouse Keeper's Lunch\", \"The Tree That's Meant To Be\", 'The Dinosaur That Pooped Christmas', \"The Jolly Postman or Other People's Letters\", 'What The Ladybird Heard', \"Ravi's Roar\", 'The Runaway Pea', 'Zog and the Flying Doctors', 'The Three Little Pigs', 'Lenny Makes A Wish', 'Knock Knock Alien', 'Boogie Bear', 'Father Christmas Needs A Wee', 'The Polar Express', 'Mini Beasties', 'The Smartest Giant in Town', 'Barry the Fish With Fingers and the Hairy Scary Monster', 'Stick Man', 'Sharing A Shell', \"Dogs Don't Do Ballet\", 'Santa to the Rescue']\n"
     ]
    }
   ],
   "source": [
    "print(list(null_speaker_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross Rabbit\n"
     ]
    }
   ],
   "source": [
    "current_book = next(null_speaker_books)\n",
    "print(current_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>9</td>\n",
       "      <td>the mice</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Percy</td>\n",
       "      <td>â€œHello Percy!â€ they called. But suddenly they\\...</td>\n",
       "      <td>Hello Percy! Youâ€™re not going to tell us to st...</td>\n",
       "      <td>58</td>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>11</td>\n",
       "      <td>the mice</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Percy</td>\n",
       "      <td>â€œWeâ€™ll try!â€ they squeaked loudly.</td>\n",
       "      <td>Weâ€™ll try!</td>\n",
       "      <td>10</td>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book  speech_section_id   speaker recipient speaker_matched  \\\n",
       "556  The Cross Rabbit                  9  the mice     Percy         Unknown   \n",
       "558  The Cross Rabbit                 11  the mice     Percy         Unknown   \n",
       "\n",
       "    recipient_matched                                        speech_text  \\\n",
       "556             Percy  â€œHello Percy!â€ they called. But suddenly they\\...   \n",
       "558             Percy                 â€œWeâ€™ll try!â€ they squeaked loudly.   \n",
       "\n",
       "                                     spoken_words_only  spoken_word_count  \\\n",
       "556  Hello Percy! Youâ€™re not going to tell us to st...                 58   \n",
       "558                                         Weâ€™ll try!                 10   \n",
       "\n",
       "         chunk_titles  self_talk_flag name_speaker gender_speaker  \\\n",
       "556  The Cross Rabbit           False          NaN            NaN   \n",
       "558  The Cross Rabbit           False          NaN            NaN   \n",
       "\n",
       "    human_speaker  alias_count_speaker name_recipient gender_recipient  \\\n",
       "556           NaN                  NaN          Percy                M   \n",
       "558           NaN                  NaN          Percy                M   \n",
       "\n",
       "    human_recipient  alias_count_recipient  \n",
       "556               H                    0.0  \n",
       "558               H                    0.0  "
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[(speakers.book == current_book) * (speakers.name_speaker.isna())]\n",
    "# speakers[(speakers.book == current_book) * (speakers.name_recipient.isna())]\n",
    "# speakers[(speakers.book == 'Sing A Song Of Bottoms') * (speakers.name_speaker.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Harry</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Mum</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Sam</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Gran</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>T-Rex</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Museum Guard</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Pterodactyl</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Triceratops</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Anchisaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Apatosaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Scelidosaurs</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Nan</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Person in charge</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Stegosaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      book              name gender human  \\\n",
       "40   Harry and the Dinosaurs at the Museum             Harry      M     H   \n",
       "380  Harry and the Dinosaurs at the Museum               Mum      F     H   \n",
       "381  Harry and the Dinosaurs at the Museum               Sam      F     H   \n",
       "382  Harry and the Dinosaurs at the Museum              Gran      F     H   \n",
       "383  Harry and the Dinosaurs at the Museum             T-Rex      M    NH   \n",
       "384  Harry and the Dinosaurs at the Museum      Museum Guard      M     H   \n",
       "385  Harry and the Dinosaurs at the Museum       Pterodactyl      M    NH   \n",
       "386  Harry and the Dinosaurs at the Museum       Triceratops    NGS    NH   \n",
       "387  Harry and the Dinosaurs at the Museum       Anchisaurus    NGS    NH   \n",
       "388  Harry and the Dinosaurs at the Museum       Apatosaurus    NGS    NH   \n",
       "389  Harry and the Dinosaurs at the Museum      Scelidosaurs    NGS    NH   \n",
       "390  Harry and the Dinosaurs at the Museum               Nan      F     H   \n",
       "391  Harry and the Dinosaurs at the Museum  Person in charge    NGS     H   \n",
       "392  Harry and the Dinosaurs at the Museum       Stegosaurus    NGS    NH   \n",
       "\n",
       "     alias_count  \n",
       "40             0  \n",
       "380            0  \n",
       "381            0  \n",
       "382            0  \n",
       "383            1  \n",
       "384            0  \n",
       "385            0  \n",
       "386            0  \n",
       "387            0  \n",
       "388            0  \n",
       "389            0  \n",
       "390            0  \n",
       "391            0  \n",
       "392            0  "
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.book == current_book]\n",
    "# characters[characters.book == 'Sing A Song Of Bottoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>pack</td>\n",
       "      <td>wolves</td>\n",
       "      <td>1084</td>\n",
       "      <td>The Way Home For Wolf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alias character  character_id                   book\n",
       "index                                                     \n",
       "147    pack    wolves          1084  The Way Home For Wolf"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aliases[aliases.character_id==196]\n",
    "aliases[aliases.character=='wolves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gruff the Grump</td>\n",
       "      <td>Mr Bear</td>\n",
       "      <td>5</td>\n",
       "      <td>Gruff the Grump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We</td>\n",
       "      <td>I</td>\n",
       "      <td>16</td>\n",
       "      <td>The Polar Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little dove</td>\n",
       "      <td>her baby</td>\n",
       "      <td>24</td>\n",
       "      <td>The Christmas Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McTat</td>\n",
       "      <td>Tabby McTat</td>\n",
       "      <td>51</td>\n",
       "      <td>Tabby McTat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we're</td>\n",
       "      <td>we</td>\n",
       "      <td>67</td>\n",
       "      <td>We're Going On A Lion Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>everyone</td>\n",
       "      <td>other children</td>\n",
       "      <td>1383</td>\n",
       "      <td>Eleanor Won't Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother duck</td>\n",
       "      <td>1434</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>the swans</td>\n",
       "      <td>white birds</td>\n",
       "      <td>1436</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Granny</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>1449</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>Troll</td>\n",
       "      <td>50</td>\n",
       "      <td>The Troll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  alias       character  character_id  \\\n",
       "index                                                   \n",
       "0       Gruff the Grump         Mr Bear             5   \n",
       "1                    We               I            16   \n",
       "2           little dove        her baby            24   \n",
       "3                McTat      Tabby McTat            51   \n",
       "4                 we're              we            67   \n",
       "...                 ...             ...           ...   \n",
       "164            everyone  other children          1383   \n",
       "165              mother     mother duck          1434   \n",
       "166           the swans     white birds          1436   \n",
       "167              Granny     grandmother          1449   \n",
       "168           The Troll           Troll            50   \n",
       "\n",
       "                             book  \n",
       "index                              \n",
       "0                 Gruff the Grump  \n",
       "1               The Polar Express  \n",
       "2             The Christmas Story  \n",
       "3                     Tabby McTat  \n",
       "4      We're Going On A Lion Hunt  \n",
       "...                           ...  \n",
       "164           Eleanor Won't Share  \n",
       "165             The Ugly Duckling  \n",
       "166             The Ugly Duckling  \n",
       "167        Little Red Riding Hood  \n",
       "168                     The Troll  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_character_count = sum(characters.gender == 'F')\n",
    "male_character_count = sum(characters.gender == 'M')\n",
    "ngs_character_count = sum(characters.gender == 'NGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_word_count = speakers[speakers.gender_speaker == 'M'].spoken_word_count.sum()\n",
    "female_spoken_word_count = speakers[speakers.gender_speaker == 'F'].spoken_word_count.sum()\n",
    "ngs_spoken_word_count = speakers[speakers.gender_speaker == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205.41698113207548"
      ]
     },
     "execution_count": 1207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.50746268656715"
      ]
     },
     "execution_count": 1208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.4375"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_spoken_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22742701968771215"
      ]
     },
     "execution_count": 1397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / (male_character_count + female_character_count + ngs_character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35980991174473864"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_character_count / (male_character_count + female_character_count + ngs_character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6320754716981132"
      ]
     },
     "execution_count": 1399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_received_word_count = speakers[speakers.gender_recipient == 'M'].spoken_word_count.sum()\n",
    "female_received_word_count = speakers[speakers.gender_recipient == 'F'].spoken_word_count.sum()\n",
    "ngs_received_word_count = speakers[speakers.gender_recipient == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.32264150943396"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_received_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.57910447761193"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_received_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.68092105263158"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_received_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speech_sections = len(speakers[speakers.gender_speaker == 'M'])\n",
    "female_speech_sections = len(speakers[speakers.gender_speaker == 'F'])\n",
    "ngs_speech_sections = len(speakers[speakers.gender_speaker == 'NGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6962264150943396"
      ]
     },
     "execution_count": 1216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.537313432835821"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.350328947368421"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396694214876033"
      ]
     },
     "execution_count": 1219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23415977961432508"
      ]
     },
     "execution_count": 1220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22617079889807162"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128964935670641"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / (male_spoken_word_count + female_spoken_word_count + ngs_spoken_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22806182779235584"
      ]
     },
     "execution_count": 1223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / (male_spoken_word_count + female_spoken_word_count + ngs_spoken_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_words = speakers[speakers.gender_speaker == 'M'].spoken_words_only\n",
    "female_spoken_words = speakers[speakers.gender_speaker == 'F'].spoken_words_only\n",
    "ngs_spoken_words = speakers[speakers.gender_speaker == 'NGS'].spoken_words_only\n",
    "\n",
    "male_received_words = speakers[speakers.gender_recipient == 'M'].spoken_words_only\n",
    "female_received_words = speakers[speakers.gender_recipient == 'F'].spoken_words_only\n",
    "ngs_received_words = speakers[speakers.gender_recipient == 'NGS'].spoken_words_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011435552167243802"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(male_spoken_words)]) / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010142532534600289"
      ]
     },
     "execution_count": 1387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(female_spoken_words)]) / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013821700069108501"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(ngs_spoken_words)]) / ngs_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004491554224724674"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(male_spoken_words)]) / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003966122701921091"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(female_spoken_words)]) / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010142869562697424"
      ]
     },
     "execution_count": 1392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(male_received_words)]) / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012995742773918888"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(female_received_words)]) / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012929959256076942"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(ngs_received_words)]) / ngs_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004742999005032796"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(male_received_words)]) / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004929419672865786"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(female_received_words)]) / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "      <th>is_protagonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mum</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mum</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mummy</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nan</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinderella</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Granny</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldilocks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Bear</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Bird</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Griselda</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow White</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book  gender  human  alias_count  is_protagonist\n",
       "name                                                        \n",
       "Mum           19      19     19           19              19\n",
       "mum            9       9      9            9               9\n",
       "Mummy          8       8      8            8               8\n",
       "Sam            7       7      7            7               7\n",
       "mother         6       6      6            6               6\n",
       "Nan            5       5      5            5               5\n",
       "girl           5       5      5            5               5\n",
       "cow            5       5      5            5               5\n",
       "Mary           5       5      5            5               5\n",
       "Cinderella     5       5      5            5               5\n",
       "Granny         5       5      5            5               5\n",
       "hen            4       4      4            4               4\n",
       "Goldilocks     4       4      4            4               4\n",
       "I              4       4      4            4               4\n",
       "Mrs Bear       4       4      4            4               4\n",
       "Miss Bird      4       4      4            4               4\n",
       "Griselda       3       3      3            3               3\n",
       "Snow White     3       3      3            3               3\n",
       "granny         3       3      3            3               3\n",
       "lady           3       3      3            3               3"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.gender == 'F'].groupby('name').agg('count').sort_values('book', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much female speech is by Mum compared to male speech by Dad (option include Granny/Grandpa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "mum_map = ['mum', 'mother', 'mummy', 'mom', 'mommy', 'ma', 'mama', 'mumma', 'mamma']\n",
    "dad_map = ['dad', 'father', 'daddy', 'dada', 'dadda', 'da', 'pa', 'papa']\n",
    "gran_map = ['gran', 'granny', 'nan', 'nana', 'nanna', 'grandma', 'gradmother', 'granmother'] \n",
    "grandpa_map = ['grandpa', 'gramps', 'grandfather', 'grandad', 'granddad']\n",
    "\n",
    "def match_map(_map, _name, verbose=False):\n",
    "    exclusions = ['christmas', 'xmas', 'nature', 'earth', 'time', 'clock']\n",
    "    \n",
    "    if not pd.isna(_name):\n",
    "        _name = str(_name)\n",
    "    else:\n",
    "        _name=''\n",
    "   \n",
    "    is_exclusion = sum([\n",
    "        m in _name.lower() for m in exclusions\n",
    "    ]) > 0\n",
    "    if is_exclusion:\n",
    "        return False\n",
    "    \n",
    "    is_match = sum([\n",
    "        m in _name.lower().split() for m in _map\n",
    "    ]) > 0\n",
    "    if is_match and verbose:\n",
    "        print(_name)\n",
    "\n",
    "    return is_match #| is_short_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_map(mum_map, 'ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16716417910447762"
      ]
     },
     "execution_count": 1341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(mum_map, s)\n",
    "#     for s in characters.name]) / len(characters)\n",
    "    for s in characters.name]) / sum(characters.gender=='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062264150943396226"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(dad_map, s)\n",
    "#     for s in characters.name]) / len(characters)\n",
    "     for s in characters.name]) / sum(characters.gender=='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_characters = characters[characters.is_protagonist==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07888040712468193"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(dad_map, s)\n",
    "    for s in secondary_characters.name]) / sum(secondary_characters.gender=='M')\n",
    "#     for s in secondary_characters.name]) / len(secondary_characters.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17905405405405406"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(mum_map, s)\n",
    "    for s in secondary_characters.name]) / sum(secondary_characters.gender=='F')\n",
    "#     for s in secondary_characters.name]) / len(secondary_characters.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers['speaker_is_mum'] = [\n",
    "    match_map(mum_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_dad'] = [\n",
    "    match_map(dad_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_granny'] = [\n",
    "    match_map(gran_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_grandpa'] = [\n",
    "    match_map(grandpa_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "\n",
    "speakers['recipient_is_mum'] = [\n",
    "    match_map(mum_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_dad'] = [\n",
    "    match_map(dad_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_granny'] = [\n",
    "    match_map(gran_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_grandpa'] = [\n",
    "    match_map(grandpa_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_mum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_dad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_granny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_grandpa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09902912621359224"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_mum].spoken_word_count.sum() / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01990429039872877"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_dad].spoken_word_count.sum() / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02189630241685602"
      ]
     },
     "execution_count": 1354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_granny].spoken_word_count.sum() / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03337895307290279"
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_grandpa].spoken_word_count.sum() / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1223529411764706"
      ]
     },
     "execution_count": 1357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_mum]) / female_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022460438999489536"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_dad]) / male_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15286802599148555"
      ]
     },
     "execution_count": 1368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.recipient_is_mum].spoken_word_count.sum() / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023589416640102008"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.recipient_is_dad].spoken_word_count.sum() / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_doc = nlp(' '.join(female_spoken_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [token.lemma_\n",
    "         for token in fem_doc\n",
    "         if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [token.lemma_\n",
    "         for token in fem_doc\n",
    "         if (not token.is_stop and\n",
    "             not token.is_punct and\n",
    "             token.pos_ == \"NOUN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_doc = nlp(' '.join(male_spoken_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = [token.lemma_\n",
    "         for token in male_doc\n",
    "         if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_word_freq = Counter(male_words)\n",
    "male_common_words = male_word_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_nouns = [token.lemma_\n",
    "         for token in male_doc\n",
    "         if (not token.is_stop and\n",
    "             not token.is_punct and\n",
    "             token.pos_ == \"NOUN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_noun_freq = Counter(male_nouns)\n",
    "male_common_nouns = male_noun_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 39),\n",
       " ('house', 36),\n",
       " ('friend', 24),\n",
       " ('thing', 21),\n",
       " ('squash', 18),\n",
       " ('squeeze', 18),\n",
       " ('rabbit', 16),\n",
       " ('bear', 16),\n",
       " ('head', 14),\n",
       " ('ladybird', 14),\n",
       " ('room', 13),\n",
       " ('man', 13),\n",
       " ('today', 12),\n",
       " ('bee', 12),\n",
       " ('day', 11)]"
      ]
     },
     "execution_count": 1429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 53),\n",
       " ('time', 39),\n",
       " ('thing', 37),\n",
       " ('child', 36),\n",
       " ('friend', 36),\n",
       " ('dragon', 33),\n",
       " ('gruffalo', 32),\n",
       " ('idea', 30),\n",
       " ('book', 28),\n",
       " ('tree', 24),\n",
       " ('monster', 24),\n",
       " ('dinosaur', 24),\n",
       " ('house', 23),\n",
       " ('goat', 23),\n",
       " ('day', 23)]"
      ]
     },
     "execution_count": 1432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_common_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oh', 84),\n",
       " ('dear', 71),\n",
       " ('look', 45),\n",
       " ('good', 44),\n",
       " ('come', 43),\n",
       " ('like', 40),\n",
       " ('time', 39),\n",
       " ('say', 39),\n",
       " ('house', 36),\n",
       " ('help', 34),\n",
       " ('play', 32),\n",
       " ('old', 31),\n",
       " ('zzzz', 30),\n",
       " ('sorry', 29),\n",
       " ('little', 29)]"
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('come', 133),\n",
       " ('oh', 123),\n",
       " ('like', 105),\n",
       " ('look', 98),\n",
       " ('let', 88),\n",
       " ('say', 87),\n",
       " ('go', 83),\n",
       " ('eat', 77),\n",
       " ('think', 73),\n",
       " ('good', 72),\n",
       " ('want', 68),\n",
       " ('know', 67),\n",
       " ('help', 62),\n",
       " ('find', 61),\n",
       " ('little', 60)]"
      ]
     },
     "execution_count": 1421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005051850355007302"
      ]
     },
     "execution_count": 1423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_word_freq['sorry'] / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005990497831026648"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq['sorry'] / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04830053667262969"
      ]
     },
     "execution_count": 1442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((speakers.gender_speaker == 'F')*(speakers.gender_recipient == 'F')) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2223529411764706"
      ]
     },
     "execution_count": 1444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((speakers.gender_speaker == 'F')*(speakers.gender_recipient == 'F')) / female_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23255813953488372"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((speakers.gender_speaker == 'M')*(speakers.gender_recipient == 'M')) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46452271567126086"
      ]
     },
     "execution_count": 1445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((speakers.gender_speaker == 'M')*(speakers.gender_recipient == 'M')) / male_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2014388489208633"
      ]
     },
     "execution_count": 1450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[(speakers.gender_speaker == 'F')*(speakers.gender_recipient == 'F')].book.unique()) / len(speakers.book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5539568345323741"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[(speakers.gender_speaker == 'M')*(speakers.gender_recipient == 'M')].book.unique()) / len(speakers.book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48201438848920863"
      ]
     },
     "execution_count": 1452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[(speakers.gender_speaker == 'M')*(speakers.gender_recipient == 'F')].book.unique()) / len(speakers.book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49640287769784175"
      ]
     },
     "execution_count": 1453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[(speakers.gender_speaker == 'F')*(speakers.gender_recipient == 'M')].book.unique()) / len(speakers.book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 1515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([\"i \" in s.lower() for s in speakers[speakers.gender_speaker == 'F'].spoken_words_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03411764705882353"
      ]
     },
     "execution_count": 1482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([\"iâ€™m \" in s.lower() for s in speakers[speakers.gender_speaker == 'F'].spoken_words_only]) / female_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08779989790709546"
      ]
     },
     "execution_count": 1483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([\"iâ€™m \" in s.lower() for s in speakers[speakers.gender_speaker == 'M'].spoken_words_only]) / male_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words_dict(female_spoken_words):\n",
    "    _next_words_list = []\n",
    "    _next_next_words_list = []\n",
    "    c=0\n",
    "    for section in female_spoken_words:\n",
    "\n",
    "        index = section.lower().find('i ')\n",
    "        _section = section\n",
    "        while index != -1:\n",
    "            c+=1\n",
    "            next_words = _section[index:].split()\n",
    "            if len(next_words) >= 2:\n",
    "                next_word = next_words[1]\n",
    "            if len(next_words) >= 3:\n",
    "                next_next_word = next_words[2]\n",
    "            else:\n",
    "                next_next_word = ''\n",
    "\n",
    "            _next_words_list.append(next_word)\n",
    "            _next_next_words_list.append(next_next_word)\n",
    "    #         print(next_next_next_word)\n",
    "\n",
    "    #         _section = _section[_section.lower().find(next_next_word):]\n",
    "    #         index = _section.lower().find('i ')\n",
    "            index=-1\n",
    "    print(c)\n",
    "    return _next_words_list, _next_next_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "female_next_words = next_words_dict(female_spoken_words)\n",
    "male_next_words = next_words_dict(male_spoken_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 1529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnw = Counter(female_next_words[0])#.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, count in fcnw.items():\n",
    "    fcnw[item] /= len(female_next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canâ€™t', 0.06358381502890173),\n",
       " ('can', 0.057803468208092484),\n",
       " ('think', 0.05202312138728324),\n",
       " ('was', 0.046242774566473986),\n",
       " ('am', 0.046242774566473986),\n",
       " ('have', 0.03468208092485549),\n",
       " ('shall', 0.03468208092485549),\n",
       " ('bet', 0.028901734104046242),\n",
       " ('knew', 0.028901734104046242),\n",
       " ('love', 0.028901734104046242)]"
      ]
     },
     "execution_count": 1538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcnw.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnw = Counter(male_next_words[0])#.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, count in mcnw.items():\n",
    "    mcnw[item] /= len(male_next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canâ€™t', 0.0598669623059867),\n",
       " ('want', 0.050997782705099776),\n",
       " ('donâ€™t', 0.04434589800443459),\n",
       " ('think', 0.04212860310421286),\n",
       " ('wish', 0.03991130820399113),\n",
       " ('have', 0.037694013303769404),\n",
       " ('shall', 0.031042128603104215),\n",
       " ('must', 0.028824833702882482),\n",
       " ('know', 0.026607538802660754),\n",
       " ('hope', 0.026607538802660754)]"
      ]
     },
     "execution_count": 1543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcnw.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_word = \"want\" #\"canâ€™t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'Dogger.',\n",
       " 'to',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'Dogger.',\n",
       " 'to',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my',\n",
       " 'my']"
      ]
     },
     "execution_count": 1567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nn for n, nn in zip(male_next_words[0], male_next_words[1]) if n==lead_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dance', 'you', 'you']"
      ]
     },
     "execution_count": 1568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nn for n, nn in zip(female_next_words[0], female_next_words[1]) if n==lead_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.to_json('data/gpt4_speakers_recipients_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Proceeds as follows:\n",
    "\n",
    "#### Notes:\n",
    "- For speaker matching, inspect 'unknowns' and 'The Reader' and 'Self' separately: how many instances? Binary clasification metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for several books to test outputs, save format etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': 0,\n",
    "    'completion_tokens': [],\n",
    "    'prompt_tokens': [],\n",
    "    'total_tokens': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "results_dict = {\n",
    "    \n",
    "}\n",
    "\n",
    "for book_id in range(10):\n",
    "    \n",
    "    print(\"Book: \", df.iloc[book_id].Title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    data = {\n",
    "        'full_text': df.iloc[book_id].Text,\n",
    "        'sentences': dict(\n",
    "            zip(\n",
    "                sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "                [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    prompt = get_prompt_string(data)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation.\"},\n",
    "        {\"role\": \"user\", \"content\": r\"{}\".format(prompt)}\n",
    "      ],\n",
    "     temperature=0.0,\n",
    "     response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion.choices[0].message.content)\n",
    "    \n",
    "    book_df['completion_tokens'].append(completion.usage.completion_tokens)\n",
    "    book_df['prompt_tokens'].append(completion.usage.prompt_tokens)\n",
    "    book_df['total_tokens'].append(completion.usage.total_tokens)\n",
    "    book_df['title'].append(df.iloc[book_id].Title)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'] += len(json_response['speech_sections'])\n",
    "    \n",
    "    results_dict[df.iloc[book_id].Title] = json_response\n",
    "    \n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech_section_count</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>runtime_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>154</td>\n",
       "      <td>234</td>\n",
       "      <td>1949</td>\n",
       "      <td>2183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>154</td>\n",
       "      <td>1114</td>\n",
       "      <td>2295</td>\n",
       "      <td>3409</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Gruffalo</td>\n",
       "      <td>154</td>\n",
       "      <td>2821</td>\n",
       "      <td>3055</td>\n",
       "      <td>5876</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Monstrous Tale of Celery Crumble</td>\n",
       "      <td>154</td>\n",
       "      <td>802</td>\n",
       "      <td>2631</td>\n",
       "      <td>3433</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peace at Last</td>\n",
       "      <td>154</td>\n",
       "      <td>754</td>\n",
       "      <td>1855</td>\n",
       "      <td>2609</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sing A Song Of Bottoms</td>\n",
       "      <td>154</td>\n",
       "      <td>71</td>\n",
       "      <td>1427</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barry The Fish With Fingers</td>\n",
       "      <td>154</td>\n",
       "      <td>595</td>\n",
       "      <td>1530</td>\n",
       "      <td>2125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>154</td>\n",
       "      <td>2891</td>\n",
       "      <td>4854</td>\n",
       "      <td>7745</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Storm Whale In Winter</td>\n",
       "      <td>154</td>\n",
       "      <td>274</td>\n",
       "      <td>1544</td>\n",
       "      <td>1818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There's A Monster In Your Book</td>\n",
       "      <td>154</td>\n",
       "      <td>254</td>\n",
       "      <td>1351</td>\n",
       "      <td>1605</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  speech_section_count  \\\n",
       "0            The Night Before Christmas                   154   \n",
       "1             Sugarlump and the Unicorn                   154   \n",
       "2                          The Gruffalo                   154   \n",
       "3  The Monstrous Tale of Celery Crumble                   154   \n",
       "4                         Peace at Last                   154   \n",
       "5                Sing A Song Of Bottoms                   154   \n",
       "6           Barry The Fish With Fingers                   154   \n",
       "7                             The Troll                   154   \n",
       "8             The Storm Whale In Winter                   154   \n",
       "9        There's A Monster In Your Book                   154   \n",
       "\n",
       "   completion_tokens  prompt_tokens  total_tokens  runtime_seconds  \n",
       "0                234           1949          2183                3  \n",
       "1               1114           2295          3409               17  \n",
       "2               2821           3055          5876               37  \n",
       "3                802           2631          3433               13  \n",
       "4                754           1855          2609               11  \n",
       "5                 71           1427          1498                1  \n",
       "6                595           1530          2125                9  \n",
       "7               2891           4854          7745               52  \n",
       "8                274           1544          1818                4  \n",
       "9                254           1351          1605                4  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['The Night Before Christmas', 'Sugarlump and the Unicorn', 'The Gruffalo', 'The Monstrous Tale of Celery Crumble', 'Peace at Last', 'Sing A Song Of Bottoms', 'Barry The Fish With Fingers', 'The Troll', 'The Storm Whale In Winter', \"There's A Monster In Your Book\"])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be out in the big wide world!\\nI wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.\\n\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.\\nClippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to be free of this heavy load.\\nI wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.\\nGallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh to slow down and have some fun!\\nI wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.\\nDancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"Oh for a child to ride me!\\nI want to go home,\" he said',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'himself',\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'speaker': 'unicorn',\n",
       "   'recipient': 'Sugarlump',\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'speaker': 'Sugarlump',\n",
       "   'recipient': 'children',\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.\\nMerrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}],\n",
       " 'sentences_with_speech': [{'sentence_id': 5,\n",
       "   'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 6,\n",
       "   'speech_text': 'Happily rocking to and fro.',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 7,\n",
       "   'speech_text': 'This is the life for me!\"',\n",
       "   'speech_section_id': 1},\n",
       "  {'sentence_id': 9,\n",
       "   'speech_text': '\"Oh to be out in the big wide world!',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 10,\n",
       "   'speech_text': 'I wish I could trot,\" he said.',\n",
       "   'speech_section_id': 2},\n",
       "  {'sentence_id': 11,\n",
       "   'speech_text': '\"Done!\" came a voice, and there stood a beast\\nWith a twisty silver horn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 12,\n",
       "   'speech_text': '\"I can grant horses\\' wishes,\" Said the snow-\\nwhite unicorn.',\n",
       "   'speech_section_id': 3},\n",
       "  {'sentence_id': 18,\n",
       "   'speech_text': '\"Here in the open countryside is where\\nI like to be.',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 19,\n",
       "   'speech_text': 'Clippety-dop, clippety-dop, This is the\\nlife for me!\"',\n",
       "   'speech_section_id': 4},\n",
       "  {'sentence_id': 22,\n",
       "   'speech_text': '\"Oh to be free of this heavy load.',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 23,\n",
       "   'speech_text': 'I wish I could gallop!\"',\n",
       "   'speech_section_id': 5},\n",
       "  {'sentence_id': 25,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 6},\n",
       "  {'sentence_id': 31,\n",
       "   'speech_text': '\"Here on this famous race course Is where I like to be.',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 32,\n",
       "   'speech_text': 'Gallop-a-jump, gallop-a-jump, This is the life for me!\"',\n",
       "   'speech_section_id': 7},\n",
       "  {'sentence_id': 35,\n",
       "   'speech_text': '\"Oh to slow down and have some fun!',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 36,\n",
       "   'speech_text': 'I wish I could dance,\" he said.',\n",
       "   'speech_section_id': 8},\n",
       "  {'sentence_id': 37,\n",
       "   'speech_text': '\"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 9},\n",
       "  {'sentence_id': 41,\n",
       "   'speech_text': '\"Here in this splendid circus\\nIs where I like to be.',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 42,\n",
       "   'speech_text': 'Dancing and prancing, prancing and dancing,\\nThis is the life for me!\"',\n",
       "   'speech_section_id': 10},\n",
       "  {'sentence_id': 44,\n",
       "   'speech_text': '\"Oh for a child to ride me!',\n",
       "   'speech_section_id': 11},\n",
       "  {'sentence_id': 45,\n",
       "   'speech_text': 'I want to go home,\" he said \"Done!\" came the voice of the unicorn,\\nAnd she flashed her eyes of blue.',\n",
       "   'speech_section_id': 12},\n",
       "  {'sentence_id': 49,\n",
       "   'speech_text': '\"I wish I had never been born!\"',\n",
       "   'speech_section_id': 13},\n",
       "  {'sentence_id': 50,\n",
       "   'speech_text': '\"But I have a better wish for you,\" Came the voice of the unicorn.',\n",
       "   'speech_section_id': 14},\n",
       "  {'sentence_id': 55,\n",
       "   'speech_text': '\"Here in this fabulous fairground Is\\nwhere I love to be.',\n",
       "   'speech_section_id': 15},\n",
       "  {'sentence_id': 56,\n",
       "   'speech_text': 'Merrily, merrily, round and round, This is\\nthe life for me!\"',\n",
       "   'speech_section_id': 15}]}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['Sugarlump and the Unicorn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk \n",
    "with open('./results/gpt4o_results_dict.pk', 'wb') as outfile:\n",
    "    pk.dump(results_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_csv('./results/gpt4o_book_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now extend the conversation to pull out only the spoken words only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_schema = {\n",
    "    \"speaker\": \"string\",\n",
    "    \"recipient\": \"string\",\n",
    "    \"spoken_words_only\": \"string\",\n",
    "    \"speech_section_id\": \"integer\"\n",
    "}\n",
    "    \n",
    "new_json_schema_str = ', '.join([f\"'{key}': {value}\" for key, value in new_json_schema.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For the speech sections that you just found, which I reproduce below, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "\n",
    "        Data: {previous_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_prompt_string(previous_response):\n",
    "    \n",
    "    return f\"\"\"\n",
    "        For the speech sections that you just found, please pull out the words that are spoken\n",
    "        and add them as a new field in the JSON called spoken_words_only, replacing the speech_text field.\n",
    "        So you will need to remove all non-speech words such as 'she said' etc.\n",
    "        \n",
    "        Please use provide your response in JSON.\n",
    "        Please reproduce punctuation as it is written using regular double quotes \"\" for speech marks.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry and the Dinosaurs Go Wild'"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id = 21\n",
    "df.iloc[book_id].Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'full_text': df.iloc[book_id].Text,\n",
    "    'sentences': dict(\n",
    "        zip(\n",
    "            sentences[sentences.book == df.iloc[book_id].Title].sentence_index,\n",
    "            [span.text for span in sentences[sentences.book == df.iloc[book_id].Title].sentence]\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=992, prompt_tokens=2418, total_tokens=3410)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"You are a data analysis assistant, capable of accurate and precise natural language processing. Output your response in JSON format using the following schema: {json_schema_str}. When reproducing text data please preserve newline characters and punctuation. Please start all indexing of lists and arrays at 0 rather than 1.\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_prompt_string(data))},\n",
    "    {\"role\": \"assistant\", \"content\": completion.choices[0].message.content},\n",
    "    {\"role\": \"system\", \"content\": f\"Please use the following schema for your JSON response: {new_json_schema}\"},\n",
    "    {\"role\": \"user\", \"content\": r\"{}\".format(get_second_prompt_string(json.loads(completion.choices[0].message.content)))}\n",
    "  ],\n",
    " temperature=0.0,\n",
    " response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=944, prompt_tokens=3557, total_tokens=4501)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'speech_text': 'â€œThatâ€™s a\\nrhinoceros,â€ said Hany.',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'speech_text': 'â€œI\\nwant to save some animals,â€ he said.\\nâ€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'speech_text': 'â€œWait till Iâ€™ve finished my blue whale,â€ said Harry.\\nâ€œBlue whales are bigger than trains, bigger than\\ndinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'speech_text': 'â€œArmy tanks donâ€™t need saving!â€ said Triceratops.\\nâ€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhy not talk to Mr Bopsom?\\nHe might put up a poster in his shop window!\\nThen people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œThatâ€™s a shame,â€ said Mr Bopsom.\\nâ€œBecause saving animals is\\nimportant!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œIâ€™ve had an idea!â€ he said. â€œCan you do me lots more\\npictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œMarvellous!â€\\nâ€œWhat a brilliant idea!â€\\nâ€œSo original!â€\\nâ€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'speech_text': 'â€œWhat a\\nwonderful thing youâ€™ve done!â€ she said.',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Apatosaurus.\\nâ€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œRaahh!â€ said Pterodactyl.\\nâ€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'speech_text': 'â€œQuite right, my dinosaurs! Because even\\nif you are as tiny as a tick on the tail of a green turtle, you can\\nstill do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech_sections': [{'speaker': 'Hany',\n",
       "   'recipient': 'Apatosaurus',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a rhinoceros,â€',\n",
       "   'speech_section_id': 0},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Mum',\n",
       "   'spoken_words_only': 'â€œI want to save some animals,â€ â€œWhat can I do, Mum?â€',\n",
       "   'speech_section_id': 1},\n",
       "  {'speaker': 'Sam',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œTuh! What a waste of time!â€',\n",
       "   'speech_section_id': 2},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Pterodactyl',\n",
       "   'spoken_words_only': 'â€œWait till Iâ€™ve finished my blue whale,â€ â€œBlue whales are bigger than trains, bigger than dinosaurs, bigger than thirty-two elephants!â€',\n",
       "   'speech_section_id': 3},\n",
       "  {'speaker': 'Triceratops',\n",
       "   'recipient': 'Stegosaurus',\n",
       "   'spoken_words_only': 'â€œArmy tanks donâ€™t need saving!â€ â€œDo a tree frog instead.â€',\n",
       "   'speech_section_id': 4},\n",
       "  {'speaker': 'Nan',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhy not talk to Mr Bopsom? He might put up a poster in his shop window! Then people can see the pictures when they go shopping!â€',\n",
       "   'speech_section_id': 5},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œThatâ€™s a shame,â€ â€œBecause saving animals is important!â€',\n",
       "   'speech_section_id': 6},\n",
       "  {'speaker': 'Mr Bopsom',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œIâ€™ve had an idea!â€ â€œCan you do me lots more pictures?â€',\n",
       "   'speech_section_id': 7},\n",
       "  {'speaker': 'Everybody',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œMarvellous!â€ â€œWhat a brilliant idea!â€ â€œSo original!â€ â€œFour cards for me, please!â€',\n",
       "   'speech_section_id': 8},\n",
       "  {'speaker': 'The lady from the paper',\n",
       "   'recipient': 'Harry',\n",
       "   'spoken_words_only': 'â€œWhat a wonderful thing youâ€™ve done!â€',\n",
       "   'speech_section_id': 9},\n",
       "  {'speaker': 'Apatosaurus',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the strawberry poison arrow frog!â€',\n",
       "   'speech_section_id': 10},\n",
       "  {'speaker': 'Pterodactyl',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œRaahh!â€ â€œSave the teeny blue tongued skink!â€',\n",
       "   'speech_section_id': 11},\n",
       "  {'speaker': 'Harry',\n",
       "   'recipient': 'Everyone',\n",
       "   'spoken_words_only': 'â€œQuite right, my dinosaurs! Because even if you are as tiny as a tick on the tail of a green turtle, you can still do something that makes a BIG difference.â€',\n",
       "   'speech_section_id': 12}],\n",
       " 'sentences_with_speech': {'2': 0,\n",
       "  '14': 1,\n",
       "  '15': 1,\n",
       "  '16': 2,\n",
       "  '17': 2,\n",
       "  '33': 3,\n",
       "  '34': 3,\n",
       "  '36': 4,\n",
       "  '37': 4,\n",
       "  '41': 5,\n",
       "  '42': 5,\n",
       "  '43': 5,\n",
       "  '47': 6,\n",
       "  '48': 6,\n",
       "  '54': 7,\n",
       "  '55': 7,\n",
       "  '56': 7,\n",
       "  '62': 8,\n",
       "  '63': 8,\n",
       "  '64': 8,\n",
       "  '65': 8,\n",
       "  '67': 9,\n",
       "  '68': 9,\n",
       "  '69': 10,\n",
       "  '70': 10,\n",
       "  '71': 11,\n",
       "  '72': 11,\n",
       "  '73': 12,\n",
       "  '74': 12}}"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(second_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now trialling format for manual validation:\n",
    "\n",
    "We have already used the student manual coding for validate speech detection, so now we can just focus on detected speech...\n",
    "\n",
    "1. Select book at random, select passage of detected speech at random. \n",
    "2. Show user the passage and some of the text either side of the passage\n",
    "3. Ask is it speech? Is speaker correct? Is recipient correct? [Give option to view more text]\n",
    "4. Save result.\n",
    "\n",
    "#### Note: handle case when sentence is not found in text e.g. The Troll sentence 7 is split across two setences (7 and 8) due to bad pdfplumber output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = randint(0, 1)\n",
    "# book_selection = 4  # Peace at Last\n",
    "book_selection = 1  # Sugarlump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sugarlump and the Unicorn'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_book = list(results_dict.keys())[book_selection]\n",
    "selected_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_sections = json.loads(completion.choices[0].message.content)['speech_sections']\n",
    "speech_sections = results_dict[selected_book]['speech_sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(v_vec):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_section(df, res, speech_section_result, padding=200):\n",
    "\n",
    "    speech_section = speech_section_result['speech_text']\n",
    "    book_text = df[df.Title == selected_book].iloc[0].Text\n",
    "    this_text = book_text[0:res] + '**' + book_text[res:res+len(speech_section)] + '**' + book_text[res+len(speech_section):]\n",
    "    this_text = this_text[max(res-padding-2, 0):min(res+len(speech_section)+padding+2, len(this_text))]\n",
    "    display(Markdown(this_text.replace('\\n', '<br>')))\n",
    "\n",
    "    display(Markdown('**' + 'Result:' + '**'))\n",
    "    display(speech_section_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_selection = randint(0, len(speech_sections))\n",
    "section_selection = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = df[df.Title == selected_book].iloc[0].Text.find(speech_sections[section_selection]['speech_text']) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ht and blue. And when<br>she hears a horse's wish, She can<br>make that wish come tine.<br>Sugarlump was a rocking horse.<br>He belonged to a girl and boy.<br>To and fro, to and fro,<br>They rode on their favourite toy.<br>**\"Here in the children's bedroom<br>Is where I want to be.<br>Happily rocking to and fro.<br>This is the life for me!\"**<br><br>But when the children were out at school Sugarlump hung his head.<br>\"Oh to be out in the big wide world!<br>I wish I could trot,\" he said.<br><br>\"Done!\" came a voice, and there stood a beast<br>With a twisty s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Result:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'speaker': 'Sugarlump',\n",
       " 'recipient': 'himself',\n",
       " 'speech_text': '\"Here in the children\\'s bedroom\\nIs where I want to be.\\nHappily rocking to and fro.\\nThis is the life for me!\"',\n",
       " 'speech_section_id': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_section(df, res, speech_sections[section_selection])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please indicate with '1' which are correct: [speech, speaker, recipient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_vector = [1, 1, 1]\n",
    "validate(validation_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
