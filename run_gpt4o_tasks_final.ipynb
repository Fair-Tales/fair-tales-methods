{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task decomposition and prompt development.\n",
    "\n",
    "We provide here a framework for developing sequential prompts for a complex NLP task using GPT4o.\n",
    "\n",
    "The complex tasks is decompsed into as sequence of simpler tasks that each build on the previous one.\n",
    "\n",
    "For each task in the sequence we produce a number of examples to show GPT4o, and a number of further examples to use for automated testing of the response. This borrows ideas from unit testing of software, since iterative changes to the prompt may break functionality that was previously working.\n",
    "\n",
    "This framework can be adapted to use with other LLMs and NLP tasks.\n",
    "\n",
    "#### We decompose into the following tasks:\n",
    "- Task 1: identify sections of direct speech, and the name of the speaker and recipient\n",
    "- Task 1b: locate pre-defined sentences in these detected sections of speech (for comparison with human coding)\n",
    "- Task 2: pull out the spoken words only from each section (removing e.g. 'he said' etc)\n",
    "- Task 3: locate and replace the names of the speakers and recipients using a pre-defined character map  \n",
    "\n",
    "#### On gender and character coding (for article and data entry tools):\n",
    "- We code mixed plural/groups as NGS, and NH\n",
    "- We ask users to include groups as a separate character (e.g. pigs in three pigs, reindeer in...)\n",
    "- We ask users to code all characters that speak or are spoken to including inaimate objects (NH)\n",
    "\n",
    "#### Notes:\n",
    "- Determinism is not guaranteed. But well structured prompts should produce near deterministic outputs, along with temperature=0, fixed seed. It is also worth storing the system finerprint for future reference, as changes to this may be the cause of differing results in the future.  \n",
    "- The lack of determinism can make tests quite brittle. It is worth repeating tests several times to confirm their behvaiour. And then running the full manual validation on a single static result set.\n",
    "- Where possible, the sequential tasks should b tackled as a new completion API, using formatted output from the previous task as the inupt. This is preferrable to chaining of prompts and outputs to produce a chat style conversation, but this increases the risk of conflict or confusion between prompts/instructions sets. And also increases the length of the context window.\n",
    "- Need to ensure consistency between instructions, schemas and examples. Otherwise results may be inconsistent e.g. 'reproduce all punctuation all it appears' conflicted with 'remove  speech marks' example.\n",
    "- Should typos be accounted for (e.g. task_3 name matching?)\n",
    "- Cost: \\\\$1.22 left after developing prompts. Added \\\\$10 to run for 50 books (so ~0.25 full dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automating this using the Chat GPT API:\n",
    "\n",
    "## TODO:\n",
    " \n",
    " - When in pipeline to spellcheck/ correct typos? (e.g. Hany in the Dinosaurs (book 21).\n",
    " - what to do about inconsitent sentence detection? e.g \"Now Dasher!\" being at the end of sentence 7 was causing GPT confusion...\n",
    " - add an instruction about how to refer to 'general audience' or 'narrator' or 'I'\n",
    " - ask for output of reasoning/thought process?\n",
    " - ask for a confidence score?\n",
    " - do we need to specify (in system prompt), not to use MD or any other formatting in the json output?\n",
    " \n",
    "## Note: ideas to explore if we need performance boost...\n",
    "\n",
    "- system message to edit assistant role\n",
    "- vary temperature or top_p parameter\n",
    "- fine_tuning a model with bespoke training data (how much data is necessary?)\n",
    "- improved instructions or prompt engineering (see e.g. paper on iterative prompting)\n",
    "- compare results with gpt-3.5-turbo? - does not seem to work well for our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./key.txt', 'r') as infile:\n",
    "    api_key = infile.read().splitlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tempdf.pickle', 'rb') as outfile:\n",
    "    df = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our prompts, example data (for in-context learning), and test data for unit testing each task: \n",
    "from openai_api.examples import example_data\n",
    "from openai_api.tests import build_test_data\n",
    "\n",
    "test_data = build_test_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the full dataset into a dataframe of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.utilities import spacy_extract_sentences\n",
    "sentences = spacy_extract_sentences(df, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that this sample contains the same sentences that were manually coded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sample = sentences.sample(frac=0.15, axis=0, random_state=42)\n",
    "manually_coded = pd.read_csv('./sentences_for_coding/sample_15pc.csv', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_equal = [\n",
    "    i == j.text\n",
    "    for i,j in\n",
    "    zip(manually_coded.sentence, coding_sample.sentence)\n",
    "]    \n",
    "assert sum(text_equal) == len(text_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build OpenAI API code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.schemas import build_task_1_input_schema, build_task_1_response_schema\n",
    "from openai_api.utilities import *\n",
    "\n",
    "task_1_response_schema_str = build_task_1_response_schema()\n",
    "task_1_input_schema_str = build_task_1_input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.tests import run_task_1_test_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_api.prompts import (\n",
    "    get_task_1_prompt_string, get_task_1_system_prompt,\n",
    "    get_task_2_prompt_string, get_task_2_system_prompt,\n",
    "    get_task_3_prompt_string, get_task_3_system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1(full_text, client, seed=42):\n",
    "    \n",
    "    prompt_string = get_task_1_prompt_string(\n",
    "            data={'full_text': full_text}, \n",
    "        )\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_task_1_system_prompt()},\n",
    "            {\"role\": \"user\", \"content\": r\"{}\".format(prompt_string)}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return completion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_1_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "        \n",
    "        completion = run_task_1(test_data['strings'][test_id], client=client)\n",
    "        \n",
    "        if run_task_1_test_i(test_id, test_data, completion, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 5\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 6\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 7\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 8\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 9\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 10\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 11\n",
      "Running test: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10772/533159088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running repeat {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msuccess_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/668737001.py\u001b[0m in \u001b[0;36mrun_task_1_tests\u001b[0;34m(test_data, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running test: {test_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_task_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'strings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_task_1_test_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10772/926607395.py\u001b[0m in \u001b[0;36mrun_task_1\u001b[0;34m(full_text, client, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresponse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"json_object\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatCompletionChunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         )\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     def patch(\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m             \u001b[0mremaining_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             )\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         )\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m                 )\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m                 trace.return_value = (\n\u001b[1;32m    101\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 data = self._network_stream.read(\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/Research/gender/Gender in Children's Literature/code_new_version/newenv/lib/python3.7/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    929\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(20):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_1_tests(test_data)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: pulling out spoken words only.\n",
    "\n",
    "#### TODO:\n",
    "- refactor run_test_i method\n",
    "- move schemas and test and example data to files\n",
    "- rename as tak 2 or rename functions and strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2(full_text, client, task_1_completion=None, seed=42):\n",
    "    \n",
    "    if task_1_completion is None:\n",
    "        task_1_completion = run_task_1(full_text, client)\n",
    "        \n",
    "    task_1_prompt_string = get_task_1_prompt_string(\n",
    "        data={'full_text': full_text}\n",
    "    )\n",
    "    \n",
    "    task_2_prompt_string = get_task_2_prompt_string(\n",
    "        task_1_response=json.loads(task_1_completion.choices[0].message.content)\n",
    "    )\n",
    "    \n",
    "    task_2_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_2_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_2_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2 = run_task_2(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=156, prompt_tokens=679, total_tokens=835, completion_tokens_details={'reasoning_tokens': 0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"spoken_words_only\": \"That’s a rhinoceros. Triceratops has got more horns.\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"spoken_words_only\": \"I want to save some animals. What can I do, Mum?\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"spoken_words_only\": \"Tuh! What a waste of time!\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_2_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'spoken_words_only': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_2_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, completion_2 = run_task_2(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client\n",
    "        )\n",
    "           \n",
    "        if run_task_2_test_i(test_id, test_data, completion_2, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_2_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: mappnig character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3(\n",
    "    full_text, client, characters, aliases, \n",
    "    task_2_completion=None, \n",
    "    task_1_completion=None, \n",
    "    _meta_character_list=meta_character_list,\n",
    "    seed=42\n",
    "):\n",
    "    \n",
    "    if task_2_completion is None:\n",
    "        task_1_completion, task_2_completion = run_task_2(full_text, client)\n",
    "        \n",
    "    \n",
    "    task_3_prompt_string = get_task_3_prompt_string(\n",
    "        task_2_response=json.loads(task_2_completion.choices[0].message.content),\n",
    "        characters=characters,\n",
    "        aliases=aliases,\n",
    "        meta_characters=_meta_character_list\n",
    "    )\n",
    "    \n",
    "    task_3_completion = client.chat.completions.create(\n",
    "       model=\"gpt-4o\",\n",
    "       messages=[\n",
    "           {\n",
    "               \"role\": \"system\", \n",
    "               \"content\": get_task_3_system_prompt()\n",
    "           },\n",
    "           {\n",
    "               \"role\": \"user\", \n",
    "               \"content\": r\"{}\".format(task_3_prompt_string)\n",
    "           }\n",
    "       ],\n",
    "       temperature=0.0,\n",
    "       response_format={\"type\": \"json_object\"},\n",
    "       seed=seed\n",
    "    )\n",
    "    return task_1_completion, task_2_completion, task_3_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_1, completion_2, completion_3 = run_task_3(\n",
    "    full_text=test_data['strings'][test_id],\n",
    "    client=client,\n",
    "    characters=test_data['task_3_characters'][test_id],\n",
    "    aliases=test_data['task_3_aliases'][test_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=155, prompt_tokens=942, total_tokens=1097, completion_tokens_details={'reasoning_tokens': 0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speech_sections\": [\n",
      "    {\n",
      "      \"speaker\": \"Hany\",\n",
      "      \"recipient\": \"Apatosaurus\",\n",
      "      \"speaker_matched\": \"Unknown\",\n",
      "      \"recipient_matched\": \"Apatosaurus\",\n",
      "      \"speech_section_id\": 0\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Harry\",\n",
      "      \"recipient\": \"Mum\",\n",
      "      \"speaker_matched\": \"Harry\",\n",
      "      \"recipient_matched\": \"Mum\",\n",
      "      \"speech_section_id\": 1\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"Sam\",\n",
      "      \"recipient\": \"Harry\",\n",
      "      \"speaker_matched\": \"Mum\",\n",
      "      \"recipient_matched\": \"Harry\",\n",
      "      \"speech_section_id\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_test_i(test_id, test_data, completion, verbose=False):\n",
    "    response = json.loads(completion.choices[0].message.content)\n",
    "    correct_speech_sections = test_data['task_3_responses'][test_id]['speech_sections']\n",
    "\n",
    "    pass_flag = True\n",
    "\n",
    "    try:\n",
    "        assert len(response['speech_sections']) == len(correct_speech_sections)\n",
    "    except AssertionError:\n",
    "        print(f\"Failed test: speech section lists are different lengths.\")\n",
    "        if verbose:\n",
    "            print(response['speech_sections'])\n",
    "            print(correct_speech_sections)\n",
    "            pass_flag = False\n",
    "            \n",
    "    test_elemtents = {\n",
    "        'speaker': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'recipient': {\n",
    "            'case_sensitive': False,\n",
    "            'remove_leading_the': True\n",
    "        },\n",
    "        'speaker_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "        'recipient_matched': {\n",
    "            'case_sensitive': True,\n",
    "            'remove_leading_the': False\n",
    "        },\n",
    "#         'spoken_words_only': {\n",
    "#             'case_sensitive': True,\n",
    "#             'remove_leading_the': False\n",
    "#         },\n",
    "    }\n",
    "    \n",
    "    for correct_section, section in zip(correct_speech_sections, response['speech_sections']):\n",
    "\n",
    "        try:\n",
    "            assert section['speech_section_id'] == correct_section['speech_section_id']\n",
    "        except AssertionError:\n",
    "            print(f\"Failed test: speech section_id not equal.\")\n",
    "            if verbose:\n",
    "                print(correct_section)\n",
    "                print(section)\n",
    "                \n",
    "        for element in test_elemtents.keys():\n",
    "            try:\n",
    "                assert compare_strings(\n",
    "                    correct_section[element], \n",
    "                    section[element], \n",
    "                    _case_sensitive=test_elemtents[element]['case_sensitive'],\n",
    "                    _remove_leading_the=test_elemtents[element]['remove_leading_the']\n",
    "                )\n",
    "            except AssertionError:\n",
    "                print(f\"Failed {element} test for section: {section}\")\n",
    "                if verbose:\n",
    "                    print(correct_section[element])\n",
    "                pass_flag = False\n",
    "                \n",
    "    return pass_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_3_tests(test_data, verbose=False):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    pass_all = True\n",
    "    \n",
    "    for test_id in test_data['test_ids']:\n",
    "        print(f\"Running test: {test_id}\")\n",
    "\n",
    "        _, _, completion_3 = run_task_3(\n",
    "            full_text=test_data['strings'][test_id], \n",
    "            client=client,\n",
    "            characters=test_data['task_3_characters'][test_id],\n",
    "            aliases=test_data['task_3_aliases'][test_id]\n",
    "        )\n",
    "           \n",
    "        if run_task_3_test_i(test_id, test_data, completion_3, verbose=verbose):\n",
    "            print(f\"Test {test_id}: pass\")\n",
    "        else: \n",
    "            print(f\"Test {test_id}: fail\")\n",
    "            pass_all = False\n",
    "    \n",
    "    return pass_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running repeat 0\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 1\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 2\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 3\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Running repeat 4\n",
      "Running test: 0\n",
      "Test 0: pass\n",
      "Running test: 1\n",
      "Test 1: pass\n",
      "Running test: 2\n",
      "Test 2: pass\n",
      "\n",
      "\n",
      "Success count: 5\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "for i in range(5):\n",
    "    print(f\"Running repeat {i}\")\n",
    "    \n",
    "    success = run_task_3_tests(test_data, verbose=True)\n",
    "    success_count += success\n",
    "    print('\\n')\n",
    "\n",
    "print(f\"Success count: {success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running for full corpus\n",
    "\n",
    "Now that our prompts are passing all tests, we run the method for all books in the corpus and save the results to disk....\n",
    "\n",
    "#### TODO:\n",
    "- add a 'self' match example to data (still using himself)\n",
    "- check Noi and 'his dad' - shouldn't it be Dad? (The Storm Whale In Winter)\n",
    "- add Narrator handling/example (e.g. There's A Monster In Your Book)\n",
    "- add a flag for if it is a character match or something else ('Everyone' Narrator' etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: that this only handles two chunks currently. And is not an optimal way of splitting since sections of speech may be separated, for example.\n",
    "# max_chunk_size = 9677\n",
    "multi_chunk_books = {\n",
    "    'The Enormous Crocodile': 9677,\n",
    "    'How The Grinch Stole Christmas': 3794, \n",
    "    'Farmer Duck': 1160,\n",
    "    \"Ravi's Roar\": 1140\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['book_length'] = np.array([len(t) for t in df.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not story books and are also the longest so would possibly need splitting.\n",
    "remove_non_stories = [\n",
    "    'All Year Round', 'All About Feelings', 'Ten in the Bed and Other Counting Rhymes', 'Why Am I An Insect'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='book_length', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(\n",
    "    title, chunk_name, chunk_text, client, book_df, \n",
    "    c1_results_dict, c2_results_dict, c3_results_dict\n",
    "):\n",
    "    \n",
    "    print(\"Book: \", title)\n",
    "    start = datetime.datetime.now()    \n",
    "    \n",
    "    completion_1, completion_2, completion_3 = run_task_3(\n",
    "        full_text=chunk_text, \n",
    "        client=client,\n",
    "        characters=characters[characters.book==title],\n",
    "        aliases=aliases[aliases.book==title],\n",
    "        _meta_character_list=meta_character_list\n",
    "    )\n",
    "    \n",
    "    json_response = json.loads(completion_3.choices[0].message.content)\n",
    "    \n",
    "    book_df['c1_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c1_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c1_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c1_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c2_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c2_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c2_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c2_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    book_df['c3_completion_tokens'].append(completion_1.usage.completion_tokens)\n",
    "    book_df['c3_prompt_tokens'].append(completion_1.usage.prompt_tokens)\n",
    "    book_df['c3_total_tokens'].append(completion_1.usage.total_tokens)\n",
    "    book_df['c3_system_fingerprint'].append(completion_1.system_fingerprint)\n",
    "    \n",
    "    book_df['title'].append(chunk_name)\n",
    "    book_df['runtime_seconds'].append((datetime.datetime.now() - start).seconds)\n",
    "    book_df['speech_section_count'].append(len(json_response['speech_sections']))\n",
    "    \n",
    "    c3_results_dict[chunk_name] = json_response\n",
    "    \n",
    "    c1_results_dict[chunk_name] = json.loads(completion_1.choices[0].message.content)\n",
    "    c2_results_dict[chunk_name] = json.loads(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book:  The Night Before Christmas\n",
      "Book:  Sugarlump and the Unicorn\n",
      "Book:  The Gruffalo\n",
      "Book:  The Monstrous Tale of Celery Crumble\n",
      "Book:  Peace at Last\n",
      "Book:  Sing A Song Of Bottoms\n",
      "Book:  Barry The Fish With Fingers\n",
      "Book:  The Troll\n",
      "Book:  The Storm Whale In Winter\n",
      "Book:  There's A Monster In Your Book\n",
      "Book:  Once Upon A Unicorn Horn\n",
      "Book:  Mind Your Manners\n",
      "Book:  The Princess and the Wizard\n",
      "Book:  Kipper's Toybox\n",
      "Book:  Oi Frog!\n",
      "Book:  Elmer and the Lost Teddy\n",
      "Book:  The Hungry Caterpillar\n",
      "Book:  A Squash and a Squeeze\n",
      "Book:  Keith The Cat With The Magic Hat\n",
      "Book:  Santa is Coming to Devon\n",
      "Book:  The Enormous Crocodile\n",
      "Book:  The Enormous Crocodile\n",
      "Book:  Harry and the Dinosaurs Go Wild\n",
      "Book:  Open Very Carefully, A Book With Bite!\n",
      "Book:  The Most Wonderful Gift In The World\n",
      "Book:  Elmer and Grandpa Eldo\n",
      "Book:  Tabby McTat\n",
      "Book:  Harry and the Dinosaurs at the Museum\n",
      "Book:  The Hedgehog's Balloon\n",
      "Book:  Jasper's Jungle Journey\n",
      "Book:  The Owl Who Was Afraid Of The Dark\n",
      "Book:  The Cross Rabbit\n",
      "Book:  Shark In The Dark\n",
      "Book:  A Thing Called Snow\n",
      "Book:  Yoga Babies\n",
      "Book:  The Way Home For Wolf\n",
      "Book:  Elmer and Wilbur\n",
      "Book:  One Starry Night\n",
      "Book:  I Need A Wee\n",
      "Book:  Harry and the Dinosaurs say Raahh!\n",
      "Book:  An Alphabet Of Stories\n",
      "Book:  The Owl's Lesson\n",
      "Book:  The Very Lazy Ladybird\n",
      "Book:  The Dinosaur Department Store\n",
      "Book:  The Fox's Hiccups\n",
      "Book:  You Choose\n",
      "Book:  Whatever Next!\n",
      "Book:  Cave Baby\n",
      "Book:  The Rescue Party\n",
      "Book:  Elmer and the Stranger\n",
      "Book:  Dinosaurs Love Underpants\n",
      "Book:  Zog\n",
      "Book:  Lost in Snow\n",
      "Book:  Monkey Needs to Listen\n",
      "Book:  Gordon's Great Escape\n",
      "Book:  Dogger\n",
      "Book:  Is It Betime Wibbly Pig\n",
      "Book:  Wide-awake Hedgehog\n",
      "Book:  Doug The Bug That Went Boing\n",
      "Book:  Tyrannosaurus Drip\n",
      "Book:  Elmer in the Snow\n",
      "Book:  Sharing A Shell\n",
      "Book:  The Rhyming Rabbit\n",
      "Book:  The Enormous Turnip\n",
      "Book:  The Same But Different Too\n",
      "Book:  Sir Charlie Stinky Socks and the Really Big Adventure\n",
      "Book:  The Snail and the Whale\n",
      "Book:  Ruby's Worry\n",
      "Book:  The Smeds and The Smoos\n",
      "Book:  I Am Amelia Earhart\n",
      "Book:  It's Christmas\n",
      "Book:  She Rex\n",
      "Book:  Wake Up, Sleeping Beauty\n",
      "Book:  No-Bot\n",
      "Book:  The Bumblebear\n",
      "Book:  Mole Hill\n",
      "Book:  Dragon Post\n",
      "Book:  A Letter to Santa\n",
      "Book:  Oi Dog!\n",
      "Book:  Scruffy Bear and the Six White Mice\n",
      "Book:  The Gingerbread Man\n",
      "Book:  The Lighthouse Keeper's Lunch\n",
      "Book:  Dogs Don't Do Ballet\n",
      "Book:  Hippo Owns Up\n",
      "Book:  Lost and Found\n",
      "Book:  Elmer on Stilts\n",
      "Book:  Giraffe is Left Out\n",
      "Book:  The Tree That's Meant To Be\n",
      "Book:  The Dinosaur That Pooped Christmas\n",
      "Book:  Lion's in a Flap\n",
      "Book:  How to Catch a Star\n",
      "Book:  The Very Busy Spider\n",
      "Book:  The Detective Dog\n",
      "Book:  The Book With No Pictures\n",
      "Book:  The First Christmas\n",
      "Book:  Careful Santa!\n",
      "Book:  Norman The Slug With The Silly Shell\n",
      "Book:  Owl Babies\n",
      "Book:  The Jolly Postman or Other People's Letters\n",
      "Book:  What The Ladybird Heard\n",
      "Book:  Charlie Cook's Favourite Book\n",
      "Book:  The Storm Whale\n",
      "Book:  Ravi's Roar\n",
      "Book:  Ravi's Roar\n",
      "Book:  The Runaway Pea\n",
      "Book:  Goldilocks and the Three Bears\n",
      "Book:  Zog and the Flying Doctors\n",
      "Book:  Kipper's A to Z\n",
      "Book:  Little Red Riding Hood\n",
      "Book:  The Three Little Pigs\n",
      "Book:  Lenny Makes A Wish\n",
      "Book:  The Christmas Story\n",
      "Book:  Knock Knock Alien\n",
      "Book:  Boogie Bear\n",
      "Book:  Tiger Has a Tantrum\n",
      "Book:  The Teeny Weeny Tadpole\n",
      "Book:  Santa to the Rescue\n",
      "Book:  The Bad-Tempered Ladybird\n",
      "Book:  Harry and the Dinosaurs go to School\n",
      "Book:  Gruff the Grump\n",
      "Book:  Night Monkey Day Monkey\n",
      "Book:  The Paper Dolls\n",
      "Book:  Snow White, Star Striker\n",
      "Book:  Caterpillar Butterfly\n",
      "Book:  These Are Animals\n",
      "Book:  Elmer and the Wind\n",
      "Book:  Father Christmas Needs A Wee\n",
      "Book:  Eleanor Won't Share\n",
      "Book:  Romp in the Swamp\n",
      "Book:  The Polar Express\n",
      "Book:  Superworm\n",
      "Book:  Mini Beasties\n",
      "Book:  Elmer and Rose\n",
      "Book:  The Smartest Giant in Town\n",
      "Book:  Supertato Veggies Assemble\n",
      "Book:  Ten Tall Giraffes\n",
      "Book:  Wiggling Worms At Work\n",
      "Book:  Too Shy For Show And Tell\n",
      "Book:  Born to be a Butterfly\n",
      "Book:  All For One\n",
      "Book:  Knock Knock Dinosaur\n",
      "Book:  Barry the Fish With Fingers and the Hairy Scary Monster\n",
      "Book:  Squash the Spider\n",
      "Book:  Little by Little\n",
      "Book:  The Tiger Who Came To Tea\n",
      "Book:  Stick Man\n",
      "Book:  When Granny Saved Christmas\n",
      "Book:  After the Storm\n",
      "Book:  Cinderella's Ballet Shoes\n",
      "Book:  Bottoms Up!\n",
      "Book:  Supertato\n",
      "Book:  Who Will Sing My Puff-a-bye\n",
      "Book:  Can't You Sleep Little Bear\n",
      "Book:  The Duchess and Guy\n",
      "Book:  Grandad's Island\n",
      "Book:  Harry and the Robots\n",
      "Book:  You Can't Take An Elephant On The Bus\n",
      "Book:  Where's My Cuddle\n",
      "Book:  Jesus' Christmas Party\n",
      "Book:  Princess Mirror-Belle And The Dragon Pox\n",
      "Book:  We're Going on a Bear Hunt\n",
      "Book:  The Ugly Duckling\n",
      "Book:  Room on the Broom\n",
      "Book:  Harry and the Bucketful of Dinosaurs\n",
      "Book:  Grandma Bird\n",
      "Book:  We're Going On A Lion Hunt\n",
      "Book:  The Wheels on the Bus\n",
      "Book:  The Cave\n",
      "Book:  Where's My Teddy\n",
      "Book:  The Singing Mermaid\n",
      "Book:  What The Ladybird Heard Next\n",
      "Book:  The Pirates Next Door\n",
      "Book:  Captain Duck\n",
      "Book:  The Little Bully\n",
      "Book:  All In One Piece\n",
      "Book:  The Gruffalo's Child\n",
      "Book:  Elephant Learns to Share\n",
      "Book:  One Snowy Night\n",
      "Book:  Each Peach Pear Plum\n",
      "Book:  The Squirrels Who Squabbled\n",
      "Book:  Knock Knock Pirate\n",
      "Book:  Who Will Save Us\n",
      "Book:  Jack Breaks The Beanstalk\n",
      "Book:  The Snowiest Christmas Ever\n",
      "Book:  Jack and the Beanstalk\n",
      "Book:  Super Sid The Silly Sausage Dog\n",
      "Book:  The Christmas Extravaganza Hotel\n",
      "Book:  Cinder the Bubble-Blowing Dragon\n",
      "Book:  The Animal Boogie\n",
      "Book:  The Truth According to Arthur\n",
      "Book:  Monkey Puzzle\n",
      "Book:  Little Monkey\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "book_df = {\n",
    "    'title': [],\n",
    "    'speech_section_count': [],\n",
    "    'c1_completion_tokens': [],\n",
    "    'c1_prompt_tokens': [],\n",
    "    'c1_total_tokens': [],\n",
    "    'c1_system_fingerprint': [],\n",
    "    'c2_completion_tokens': [],\n",
    "    'c2_prompt_tokens': [],\n",
    "    'c2_total_tokens': [],\n",
    "    'c2_system_fingerprint': [],\n",
    "    'c3_completion_tokens': [],\n",
    "    'c3_prompt_tokens': [],\n",
    "    'c3_total_tokens': [],\n",
    "    'c3_system_fingerprint': [],\n",
    "    'runtime_seconds': []\n",
    "}\n",
    "c1_results_dict = {}\n",
    "c2_results_dict = {}\n",
    "c3_results_dict = {}\n",
    "\n",
    "for book_id in df.index:\n",
    "    \n",
    "    title = df.iloc[book_id].Title\n",
    "    \n",
    "    if title not in remove_non_stories:\n",
    "        book_text = df.iloc[book_id].Text\n",
    "    \n",
    "        if title in multi_chunk_books.keys():\n",
    "            max_chunk_size = multi_chunk_books[title]\n",
    "            last_newline = book_text[0:max_chunk_size].rfind('\\n')\n",
    "            chunks = {\n",
    "                ''.join(['_chunk_a_', title]): book_text[0:max_chunk_size],\n",
    "                ''.join(['_chunk_b_', title]): book_text[max_chunk_size:]\n",
    "            }\n",
    "            for chunk in chunks.keys():\n",
    "                process_chunk(\n",
    "                    title=title, \n",
    "                    chunk_name=chunk, \n",
    "                    chunk_text=chunks[chunk], \n",
    "                    client=client, \n",
    "                    book_df=book_df, \n",
    "                    c1_results_dict=c1_results_dict, \n",
    "                    c2_results_dict=c2_results_dict, \n",
    "                    c3_results_dict=c3_results_dict\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            process_chunk(\n",
    "                title=title, \n",
    "                chunk_name=title, \n",
    "                chunk_text=book_text, \n",
    "                client=client, \n",
    "                book_df=book_df, \n",
    "                c1_results_dict=c1_results_dict, \n",
    "                c2_results_dict=c2_results_dict, \n",
    "                c3_results_dict=c3_results_dict\n",
    "            )\n",
    "\n",
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = pd.DataFrame(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_json('data/gpt4_output_summary_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech_section_count</th>\n",
       "      <th>c1_completion_tokens</th>\n",
       "      <th>c1_prompt_tokens</th>\n",
       "      <th>c1_total_tokens</th>\n",
       "      <th>c1_system_fingerprint</th>\n",
       "      <th>c2_completion_tokens</th>\n",
       "      <th>c2_prompt_tokens</th>\n",
       "      <th>c2_total_tokens</th>\n",
       "      <th>c2_system_fingerprint</th>\n",
       "      <th>c3_completion_tokens</th>\n",
       "      <th>c3_prompt_tokens</th>\n",
       "      <th>c3_total_tokens</th>\n",
       "      <th>c3_system_fingerprint</th>\n",
       "      <th>runtime_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>54</td>\n",
       "      <td>2483</td>\n",
       "      <td>2497</td>\n",
       "      <td>4980</td>\n",
       "      <td>fp_3537616b13</td>\n",
       "      <td>2483</td>\n",
       "      <td>2497</td>\n",
       "      <td>4980</td>\n",
       "      <td>fp_3537616b13</td>\n",
       "      <td>2483</td>\n",
       "      <td>2497</td>\n",
       "      <td>4980</td>\n",
       "      <td>fp_3537616b13</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  speech_section_count  c1_completion_tokens  c1_prompt_tokens  \\\n",
       "7  The Troll                    54                  2483              2497   \n",
       "\n",
       "   c1_total_tokens c1_system_fingerprint  c2_completion_tokens  \\\n",
       "7             4980         fp_3537616b13                  2483   \n",
       "\n",
       "   c2_prompt_tokens  c2_total_tokens c2_system_fingerprint  \\\n",
       "7              2497             4980         fp_3537616b13   \n",
       "\n",
       "   c3_completion_tokens  c3_prompt_tokens  c3_total_tokens  \\\n",
       "7                  2483              2497             4980   \n",
       "\n",
       "  c3_system_fingerprint  runtime_seconds  \n",
       "7         fp_3537616b13              204  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df[book_df.title == 'The Troll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Night Before Christmas\n",
      "Sugarlump and the Unicorn\n",
      "The Gruffalo\n",
      "The Monstrous Tale of Celery Crumble\n",
      "Peace at Last\n",
      "Sing A Song Of Bottoms\n",
      "Barry The Fish With Fingers\n",
      "The Troll\n",
      "The Storm Whale In Winter\n",
      "There's A Monster In Your Book\n",
      "Once Upon A Unicorn Horn\n",
      "Mind Your Manners\n",
      "The Princess and the Wizard\n",
      "Kipper's Toybox\n",
      "Oi Frog!\n",
      "Elmer and the Lost Teddy\n",
      "The Hungry Caterpillar\n",
      "A Squash and a Squeeze\n",
      "Keith The Cat With The Magic Hat\n",
      "Santa is Coming to Devon\n",
      "_chunk_a_The Enormous Crocodile\n",
      "_chunk_b_The Enormous Crocodile\n",
      "Harry and the Dinosaurs Go Wild\n",
      "Open Very Carefully, A Book With Bite!\n",
      "The Most Wonderful Gift In The World\n",
      "Elmer and Grandpa Eldo\n",
      "Tabby McTat\n",
      "Harry and the Dinosaurs at the Museum\n",
      "The Hedgehog's Balloon\n",
      "Jasper's Jungle Journey\n",
      "The Owl Who Was Afraid Of The Dark\n",
      "The Cross Rabbit\n",
      "Shark In The Dark\n",
      "A Thing Called Snow\n",
      "Yoga Babies\n",
      "The Way Home For Wolf\n",
      "Elmer and Wilbur\n",
      "One Starry Night\n",
      "I Need A Wee\n",
      "Harry and the Dinosaurs say Raahh!\n",
      "An Alphabet Of Stories\n",
      "The Owl's Lesson\n",
      "The Very Lazy Ladybird\n",
      "The Dinosaur Department Store\n",
      "The Fox's Hiccups\n",
      "You Choose\n",
      "Whatever Next!\n",
      "Cave Baby\n",
      "The Rescue Party\n",
      "Elmer and the Stranger\n",
      "Dinosaurs Love Underpants\n",
      "Zog\n",
      "Lost in Snow\n",
      "Monkey Needs to Listen\n",
      "Gordon's Great Escape\n",
      "Dogger\n",
      "Is It Betime Wibbly Pig\n",
      "Wide-awake Hedgehog\n",
      "Doug The Bug That Went Boing\n",
      "Tyrannosaurus Drip\n",
      "Elmer in the Snow\n",
      "Sharing A Shell\n",
      "The Rhyming Rabbit\n",
      "The Enormous Turnip\n",
      "The Same But Different Too\n",
      "Sir Charlie Stinky Socks and the Really Big Adventure\n",
      "The Snail and the Whale\n",
      "Ruby's Worry\n",
      "The Smeds and The Smoos\n",
      "I Am Amelia Earhart\n",
      "It's Christmas\n",
      "She Rex\n",
      "Wake Up, Sleeping Beauty\n",
      "No-Bot\n",
      "The Bumblebear\n",
      "Mole Hill\n",
      "Dragon Post\n",
      "A Letter to Santa\n",
      "Oi Dog!\n",
      "Scruffy Bear and the Six White Mice\n",
      "The Gingerbread Man\n",
      "The Lighthouse Keeper's Lunch\n",
      "Dogs Don't Do Ballet\n",
      "Hippo Owns Up\n",
      "Lost and Found\n",
      "Elmer on Stilts\n",
      "Giraffe is Left Out\n",
      "The Tree That's Meant To Be\n",
      "The Dinosaur That Pooped Christmas\n",
      "Lion's in a Flap\n",
      "How to Catch a Star\n",
      "The Very Busy Spider\n",
      "The Detective Dog\n",
      "The Book With No Pictures\n",
      "The First Christmas\n",
      "Careful Santa!\n",
      "Norman The Slug With The Silly Shell\n",
      "Owl Babies\n",
      "The Jolly Postman or Other People's Letters\n",
      "What The Ladybird Heard\n",
      "Charlie Cook's Favourite Book\n",
      "The Storm Whale\n",
      "_chunk_a_Ravi's Roar\n",
      "_chunk_b_Ravi's Roar\n",
      "The Runaway Pea\n",
      "Goldilocks and the Three Bears\n",
      "Zog and the Flying Doctors\n",
      "Kipper's A to Z\n",
      "Little Red Riding Hood\n",
      "The Three Little Pigs\n",
      "Lenny Makes A Wish\n",
      "The Christmas Story\n",
      "Knock Knock Alien\n",
      "Boogie Bear\n",
      "Tiger Has a Tantrum\n",
      "The Teeny Weeny Tadpole\n",
      "Santa to the Rescue\n",
      "The Bad-Tempered Ladybird\n",
      "Harry and the Dinosaurs go to School\n",
      "Gruff the Grump\n",
      "Night Monkey Day Monkey\n",
      "The Paper Dolls\n",
      "Snow White, Star Striker\n",
      "Caterpillar Butterfly\n",
      "These Are Animals\n",
      "Elmer and the Wind\n",
      "Father Christmas Needs A Wee\n",
      "Eleanor Won't Share\n",
      "Romp in the Swamp\n",
      "The Polar Express\n",
      "Superworm\n",
      "Mini Beasties\n",
      "Elmer and Rose\n",
      "The Smartest Giant in Town\n",
      "Supertato Veggies Assemble\n",
      "Ten Tall Giraffes\n",
      "Wiggling Worms At Work\n",
      "Too Shy For Show And Tell\n",
      "Born to be a Butterfly\n",
      "All For One\n",
      "Knock Knock Dinosaur\n",
      "Barry the Fish With Fingers and the Hairy Scary Monster\n",
      "Squash the Spider\n",
      "Little by Little\n",
      "The Tiger Who Came To Tea\n",
      "Stick Man\n",
      "When Granny Saved Christmas\n",
      "After the Storm\n",
      "Cinderella's Ballet Shoes\n",
      "Bottoms Up!\n",
      "Supertato\n",
      "Who Will Sing My Puff-a-bye\n",
      "Can't You Sleep Little Bear\n",
      "The Duchess and Guy\n",
      "Grandad's Island\n",
      "Harry and the Robots\n",
      "You Can't Take An Elephant On The Bus\n",
      "Where's My Cuddle\n",
      "Jesus' Christmas Party\n",
      "Princess Mirror-Belle And The Dragon Pox\n",
      "We're Going on a Bear Hunt\n",
      "The Ugly Duckling\n",
      "Room on the Broom\n",
      "Harry and the Bucketful of Dinosaurs\n",
      "Grandma Bird\n",
      "We're Going On A Lion Hunt\n",
      "The Wheels on the Bus\n",
      "The Cave\n",
      "Where's My Teddy\n",
      "The Singing Mermaid\n",
      "What The Ladybird Heard Next\n",
      "The Pirates Next Door\n",
      "Captain Duck\n",
      "The Little Bully\n",
      "All In One Piece\n",
      "The Gruffalo's Child\n",
      "Elephant Learns to Share\n",
      "One Snowy Night\n",
      "Each Peach Pear Plum\n",
      "The Squirrels Who Squabbled\n",
      "Knock Knock Pirate\n",
      "Who Will Save Us\n",
      "Jack Breaks The Beanstalk\n",
      "The Snowiest Christmas Ever\n",
      "Jack and the Beanstalk\n",
      "Super Sid The Silly Sausage Dog\n",
      "The Christmas Extravaganza Hotel\n",
      "Cinder the Bubble-Blowing Dragon\n",
      "The Animal Boogie\n",
      "The Truth According to Arthur\n",
      "Monkey Puzzle\n",
      "Little Monkey\n"
     ]
    }
   ],
   "source": [
    "# Convert results dicts to dataframe of all speech sections and save to disk:\n",
    "\n",
    "all_speech_sections = {\n",
    "    'book': [],\n",
    "    'speech_section_id': [], # speech section id within book\n",
    "    'speaker': [],\n",
    "    'recipient': [],\n",
    "    'speaker_matched': [],\n",
    "    'recipient_matched': [],\n",
    "    'speech_text': [],\n",
    "    'spoken_words_only': [],\n",
    "    'spoken_word_count': []\n",
    "}\n",
    "\n",
    "for book in c3_results_dict.keys():\n",
    "    print(book)\n",
    "    for si, section in enumerate(c3_results_dict[book]['speech_sections']):\n",
    "        all_speech_sections['book'].append(book)\n",
    "        for key in all_speech_sections.keys():\n",
    "            if key not in ['book', 'spoken_word_count', 'speech_text', 'spoken_words_only']:\n",
    "                all_speech_sections[key].append(section[key])\n",
    "        \n",
    "        # Handling edge cases where a speach section is split:\n",
    "        si_corrected = si\n",
    "        if si >= len(c1_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c1_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['speech_text'].append(c1_results_dict[book]['speech_sections'][si_corrected]['speech_text'])\n",
    "        \n",
    "        if si >= len(c2_results_dict[book]['speech_sections']):\n",
    "            si_corrected = len(c2_results_dict[book]['speech_sections']) - 1\n",
    "        all_speech_sections['spoken_words_only'].append(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only'])\n",
    "        all_speech_sections['spoken_word_count'].append(len(c2_results_dict[book]['speech_sections'][si_corrected]['spoken_words_only']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections = pd.DataFrame(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/gpt4_all_speech_sections_corpus.json', 'r') as outfile:\n",
    "#     all_speech_sections = pd.read_json(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We replace any chunked book titles with the original, adding columns to retain chunk information in case needed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections['chunk_titles'] = all_speech_sections['book']\n",
    "all_speech_sections['book'] = [\n",
    "    title\n",
    "    if '_chunk_' not in title\n",
    "    else title.split('_')[3]\n",
    "    for title in all_speech_sections.book]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We replace compound characters ('and' and ','):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_compound_characters(_speech_sections, characters, character_type='speaker'):\n",
    "    \n",
    "    compound_character_data = {\n",
    "        'book': [],#'all' for c in meta_character_list],\n",
    "        'name': [],#c for c in meta_character_list],\n",
    "        'gender': [],#'NGS' for c in meta_character_list],\n",
    "        'human': [],#'NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "        'alias_count': [],#0 for c in meta_character_list]\n",
    "    }\n",
    "\n",
    "    matched_character = []\n",
    "    compound_count = 0\n",
    "    for ri, row in _speech_sections.iterrows():\n",
    "        \n",
    "        book_characters = characters[characters.book == row.book]\n",
    "        \n",
    "        cpts = flatten([\n",
    "            s.split(',') for s in row[character_type].split('and')\n",
    "        ])\n",
    "                                \n",
    "        if len(cpts) > 1:\n",
    "            compound_count += 1\n",
    "            cpts = [c.strip() for c in cpts]\n",
    "            character_list = []\n",
    "            for cpt in cpts:\n",
    "                if cpt.lower() in list(book_characters.name.str.lower()):\n",
    "                    character_list.append(cpt)\n",
    "\n",
    "            if len(cpts) != len(character_list):\n",
    "                # handles mr + mrs surname etc\n",
    "#                 print(row[character_type])\n",
    "                try:\n",
    "                    broadcast_name = cpts[0] + ' ' + cpts[1].split(' ')[1].strip()\n",
    "                    if broadcast_name.lower() in list(book_characters.name.str.lower()):\n",
    "                        character_list.append(broadcast_name)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "            genders = []        \n",
    "            humans = []\n",
    "            for c in character_list:\n",
    "                _char = book_characters[book_characters.name.str.lower() == c.lower()].iloc[0]\n",
    "                genders.append(_char.gender)\n",
    "                humans.append(_char.human)\n",
    "\n",
    "            if sum([g == 'F' for g in genders]) == len(genders):\n",
    "                compound_gender = 'F'\n",
    "            elif sum([g == 'M' for g in genders]) == len(genders):\n",
    "                compound_gender = 'M'\n",
    "            else:\n",
    "                compound_gender = 'NGS'\n",
    "\n",
    "            if sum([h == 'H' for h in humans]) == len(humans):\n",
    "                compound_human = 'H'\n",
    "            else:\n",
    "                compound_human = 'NH'\n",
    "\n",
    "            compound_character_data['book'].append(row.book)\n",
    "            compound_character_data['alias_count'].append(0)\n",
    "            compound_character_data['name'].append(row[character_type])\n",
    "            compound_character_data['gender'].append(compound_gender)\n",
    "            compound_character_data['human'].append(compound_human)\n",
    "            \n",
    "            matched_character.append(row[character_type])\n",
    "        else:\n",
    "            matched_character.append(row[f\"{character_type}_matched\"])\n",
    "            \n",
    "    _speech_sections[f\"{character_type}_matched\"] = matched_character\n",
    "    print(f\"Compound count = {compound_count}\")\n",
    "    return pd.DataFrame(compound_character_data), _speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound count = 95\n",
      "Compound count = 234\n"
     ]
    }
   ],
   "source": [
    "compound_speakers, all_speech_sections = replace_compound_characters(all_speech_sections, characters, character_type='speaker')\n",
    "compound_recipients, all_speech_sections = replace_compound_characters(all_speech_sections, characters, character_type='recipient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speech_sections.book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_characters = pd.concat([compound_speakers, compound_recipients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['and' in s for s in all_speech_sections.speaker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_characters = compound_characters.groupby(['book', 'name']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We add the metacharacter data to the character table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_list = [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs', 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_character_data = pd.DataFrame({\n",
    "    'book': ['all' for c in meta_character_list],\n",
    "    'name': [c for c in meta_character_list],\n",
    "    'gender': ['NGS' for c in meta_character_list],\n",
    "    'human': ['NH' if c in ['Dinosaurs', 'Reindeer', 'Elmer and Grandpa Eldo'] else 'H' for c in meta_character_list],\n",
    "    'alias_count': [0 for c in meta_character_list]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('character_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = pd.read_sql('select * from aliases', conn, index_col='index')\n",
    "characters = pd.read_sql('select * from characters', conn, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = pd.concat([\n",
    "    characters, meta_character_data#, compound_characters\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'self' with character name for ease of analysis (and flag self)\n",
    "all_speech_sections['self_talk_flag'] = [\n",
    "    True if r == 'Self'\n",
    "    else False \n",
    "    for r in all_speech_sections.recipient_matched\n",
    "]\n",
    "all_speech_sections['recipient_matched'] = [\n",
    "    s if r == 'Self'\n",
    "    else r \n",
    "    for s,r in zip(all_speech_sections.speaker_matched, all_speech_sections.recipient_matched)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = all_speech_sections.merge(characters, how='left', left_on=['speaker_matched', 'book'], right_on=['name', 'book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = speakers.merge(characters, how='left', left_on=['recipient_matched', 'book'], right_on=['name', 'book'], suffixes=['_speaker', '_recipient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "# for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "for c in [\n",
    "    'People','Everyone', 'Reader', 'The Reader', 'Children', 'Adults', 'Narrator',\n",
    "    'Reindeer', 'Dinosaurs'#, 'Mum and Dad', 'Esme and Bear', 'Elmer and Grandpa Eldo'\n",
    "]:\n",
    "  \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        characters[characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the mssing information for the metacharacters\n",
    "# for c in ['People', 'Everyone', 'Reader', 'The Reader']:\n",
    "for c in compound_characters.name:\n",
    "  \n",
    "    speakers['name_speaker'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['gender_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['human_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    speakers['alias_count_speaker'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_speaker, speakers.speaker_matched)\n",
    "    ]\n",
    "    \n",
    "    speakers['name_recipient'] = [\n",
    "        c if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.name_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['gender_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].gender if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.gender_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['human_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].human if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.human_recipient, speakers.recipient_matched)\n",
    "    ]\n",
    "    speakers['alias_count_recipient'] = [\n",
    "        compound_characters[compound_characters.name == c].iloc[0].alias_count if m==c \n",
    "        else n\n",
    "        for n,m in zip(speakers.alias_count_recipient, speakers.recipient_matched)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>...</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>is_protagonist_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "      <th>is_protagonist_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...</td>\n",
       "      <td>Now, Dasher! now, Dancer! now, Prancer and Vix...</td>\n",
       "      <td>183</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reindeer</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Happy\\nChristmas to all, and to all a good\\nni...</td>\n",
       "      <td>Happy Christmas to all, and to all a good night!</td>\n",
       "      <td>48</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Nicholas</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Here in the children's bedroom\\nIs where I wa...</td>\n",
       "      <td>Here in the children's bedroom Is where I want...</td>\n",
       "      <td>106</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>...</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>himself</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Oh to be out in the big wide world!\\nI wish I...</td>\n",
       "      <td>Oh to be out in the big wide world! I wish I c...</td>\n",
       "      <td>65</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>...</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>2</td>\n",
       "      <td>Unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>\"Done!\" came a voice, and there stood a beast\\...</td>\n",
       "      <td>Done! came a voice, and there stood a beast Wi...</td>\n",
       "      <td>128</td>\n",
       "      <td>Sugarlump and the Unicorn</td>\n",
       "      <td>...</td>\n",
       "      <td>unicorn</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sugarlump</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         book  speech_section_id       speaker  recipient  \\\n",
       "0  The Night Before Christmas                  0  St. Nicholas   Reindeer   \n",
       "1  The Night Before Christmas                  1  St. Nicholas   Everyone   \n",
       "2   Sugarlump and the Unicorn                  0     Sugarlump    himself   \n",
       "3   Sugarlump and the Unicorn                  1     Sugarlump    himself   \n",
       "4   Sugarlump and the Unicorn                  2       Unicorn  Sugarlump   \n",
       "\n",
       "  speaker_matched recipient_matched  \\\n",
       "0    St. Nicholas          Reindeer   \n",
       "1    St. Nicholas        The Reader   \n",
       "2       Sugarlump         Sugarlump   \n",
       "3       Sugarlump         Sugarlump   \n",
       "4         unicorn         Sugarlump   \n",
       "\n",
       "                                         speech_text  \\\n",
       "0  Now, Dasher! now, Dancer!\\nnow, Prancer and Vi...   \n",
       "1  Happy\\nChristmas to all, and to all a good\\nni...   \n",
       "2  \"Here in the children's bedroom\\nIs where I wa...   \n",
       "3  \"Oh to be out in the big wide world!\\nI wish I...   \n",
       "4  \"Done!\" came a voice, and there stood a beast\\...   \n",
       "\n",
       "                                   spoken_words_only  spoken_word_count  \\\n",
       "0  Now, Dasher! now, Dancer! now, Prancer and Vix...                183   \n",
       "1   Happy Christmas to all, and to all a good night!                 48   \n",
       "2  Here in the children's bedroom Is where I want...                106   \n",
       "3  Oh to be out in the big wide world! I wish I c...                 65   \n",
       "4  Done! came a voice, and there stood a beast Wi...                128   \n",
       "\n",
       "                 chunk_titles  ...  name_speaker gender_speaker human_speaker  \\\n",
       "0  The Night Before Christmas  ...  St. Nicholas              M             H   \n",
       "1  The Night Before Christmas  ...  St. Nicholas              M             H   \n",
       "2   Sugarlump and the Unicorn  ...     Sugarlump              M            NH   \n",
       "3   Sugarlump and the Unicorn  ...     Sugarlump              M            NH   \n",
       "4   Sugarlump and the Unicorn  ...       unicorn              F            NH   \n",
       "\n",
       "  alias_count_speaker  is_protagonist_speaker  name_recipient  \\\n",
       "0                 1.0                     0.0        Reindeer   \n",
       "1                 1.0                     0.0      The Reader   \n",
       "2                 0.0                     1.0       Sugarlump   \n",
       "3                 0.0                     1.0       Sugarlump   \n",
       "4                 0.0                     0.0       Sugarlump   \n",
       "\n",
       "  gender_recipient human_recipient alias_count_recipient  \\\n",
       "0              NGS              NH                   0.0   \n",
       "1              NGS               H                   0.0   \n",
       "2                M              NH                   0.0   \n",
       "3                M              NH                   0.0   \n",
       "4                M              NH                   0.0   \n",
       "\n",
       "   is_protagonist_recipient  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       1.0  \n",
       "3                       1.0  \n",
       "4                       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speech_sections.to_json('data/gpt4_all_speech_sections_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.to_json('data/gpt4_speakers_recipients_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2923"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018132056106739652"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_speaker.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04002736914129319"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.name_recipient.isna()]) / len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030790283954840916"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['and' in s for s in speakers.speaker])/len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2923"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>...</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>is_protagonist_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "      <th>is_protagonist_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>39</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>troll</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>Troll</td>\n",
       "      <td>The plank! The plank! Make him walk the plank!</td>\n",
       "      <td>The plank! The plank! Make him walk the plank!</td>\n",
       "      <td>46</td>\n",
       "      <td>The Troll</td>\n",
       "      <td>...</td>\n",
       "      <td>Ben Buckle and Percy Patch</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Troll</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Once Upon A Unicorn Horn</td>\n",
       "      <td>3</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>June</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>June</td>\n",
       "      <td>“Don’t worry,” Mum and Dad said.\\n“We can fix ...</td>\n",
       "      <td>Don’t worry. We can fix it together!</td>\n",
       "      <td>36</td>\n",
       "      <td>Once Upon A Unicorn Horn</td>\n",
       "      <td>...</td>\n",
       "      <td>Mum and Dad</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>June</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>The Most Wonderful Gift In The World</td>\n",
       "      <td>15</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>“US?” said Esme and Bear, thinking that perhap...</td>\n",
       "      <td>US?</td>\n",
       "      <td>3</td>\n",
       "      <td>The Most Wonderful Gift In The World</td>\n",
       "      <td>...</td>\n",
       "      <td>Esme and Bear</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Little Bunny Boo-Boo</td>\n",
       "      <td>F</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>3</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>“What\\na lovely surprise,” he said. “What’s th...</td>\n",
       "      <td>What a lovely surprise. What’s that balanced o...</td>\n",
       "      <td>58</td>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>...</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>5</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>“Fancy you remembering\\nthat,” said Eldo.</td>\n",
       "      <td>Fancy you remembering that.</td>\n",
       "      <td>27</td>\n",
       "      <td>Elmer and Grandpa Eldo</td>\n",
       "      <td>...</td>\n",
       "      <td>Grandpa Eldo</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>20</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Ugh, yucky poohey.</td>\n",
       "      <td>Ugh, yucky poohey.</td>\n",
       "      <td>18</td>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>...</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>34</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Really!</td>\n",
       "      <td>Really!</td>\n",
       "      <td>7</td>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>...</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>37</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Oh yes! Yes please!</td>\n",
       "      <td>Oh yes! Yes please!</td>\n",
       "      <td>19</td>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>...</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>39</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>Thank goodness.</td>\n",
       "      <td>Thank goodness.</td>\n",
       "      <td>15</td>\n",
       "      <td>Who Will Save Us</td>\n",
       "      <td>...</td>\n",
       "      <td>Flip, Flap, Waddle, Splash, and Littlest</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old Wise</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>Super Sid The Silly Sausage Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Grandma</td>\n",
       "      <td>Sid</td>\n",
       "      <td>Grandma</td>\n",
       "      <td>Sid</td>\n",
       "      <td>“Clever Sid,” said Grandma.</td>\n",
       "      <td>Clever Sid.</td>\n",
       "      <td>11</td>\n",
       "      <td>Super Sid The Silly Sausage Dog</td>\n",
       "      <td>...</td>\n",
       "      <td>Grandma</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sid</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      book  speech_section_id  \\\n",
       "130                              The Troll                 39   \n",
       "175               Once Upon A Unicorn Horn                  3   \n",
       "417   The Most Wonderful Gift In The World                 15   \n",
       "421                 Elmer and Grandpa Eldo                  3   \n",
       "423                 Elmer and Grandpa Eldo                  5   \n",
       "...                                    ...                ...   \n",
       "2715                      Who Will Save Us                 20   \n",
       "2729                      Who Will Save Us                 34   \n",
       "2732                      Who Will Save Us                 37   \n",
       "2734                      Who Will Save Us                 39   \n",
       "2821       Super Sid The Silly Sausage Dog                  4   \n",
       "\n",
       "                                       speaker             recipient  \\\n",
       "130                 Ben Buckle and Percy Patch                 troll   \n",
       "175                                Mum and Dad                  June   \n",
       "417                              Esme and Bear  Little Bunny Boo-Boo   \n",
       "421                               Grandpa Eldo                 Elmer   \n",
       "423                               Grandpa Eldo                 Elmer   \n",
       "...                                        ...                   ...   \n",
       "2715  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2729  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2732  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2734  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2821                                   Grandma                   Sid   \n",
       "\n",
       "                               speaker_matched     recipient_matched  \\\n",
       "130                 Ben Buckle and Percy Patch                 Troll   \n",
       "175                                Mum and Dad                  June   \n",
       "417                              Esme and Bear  Little Bunny Boo-Boo   \n",
       "421                               Grandpa Eldo                 Elmer   \n",
       "423                               Grandpa Eldo                 Elmer   \n",
       "...                                        ...                   ...   \n",
       "2715  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2729  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2732  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2734  Flip, Flap, Waddle, Splash, and Littlest              Old Wise   \n",
       "2821                                   Grandma                   Sid   \n",
       "\n",
       "                                            speech_text  \\\n",
       "130      The plank! The plank! Make him walk the plank!   \n",
       "175   “Don’t worry,” Mum and Dad said.\\n“We can fix ...   \n",
       "417   “US?” said Esme and Bear, thinking that perhap...   \n",
       "421   “What\\na lovely surprise,” he said. “What’s th...   \n",
       "423           “Fancy you remembering\\nthat,” said Eldo.   \n",
       "...                                                 ...   \n",
       "2715                                 Ugh, yucky poohey.   \n",
       "2729                                            Really!   \n",
       "2732                                Oh yes! Yes please!   \n",
       "2734                                    Thank goodness.   \n",
       "2821                        “Clever Sid,” said Grandma.   \n",
       "\n",
       "                                      spoken_words_only  spoken_word_count  \\\n",
       "130      The plank! The plank! Make him walk the plank!                 46   \n",
       "175                Don’t worry. We can fix it together!                 36   \n",
       "417                                                 US?                  3   \n",
       "421   What a lovely surprise. What’s that balanced o...                 58   \n",
       "423                         Fancy you remembering that.                 27   \n",
       "...                                                 ...                ...   \n",
       "2715                                 Ugh, yucky poohey.                 18   \n",
       "2729                                            Really!                  7   \n",
       "2732                                Oh yes! Yes please!                 19   \n",
       "2734                                    Thank goodness.                 15   \n",
       "2821                                        Clever Sid.                 11   \n",
       "\n",
       "                              chunk_titles  ...  \\\n",
       "130                              The Troll  ...   \n",
       "175               Once Upon A Unicorn Horn  ...   \n",
       "417   The Most Wonderful Gift In The World  ...   \n",
       "421                 Elmer and Grandpa Eldo  ...   \n",
       "423                 Elmer and Grandpa Eldo  ...   \n",
       "...                                    ...  ...   \n",
       "2715                      Who Will Save Us  ...   \n",
       "2729                      Who Will Save Us  ...   \n",
       "2732                      Who Will Save Us  ...   \n",
       "2734                      Who Will Save Us  ...   \n",
       "2821       Super Sid The Silly Sausage Dog  ...   \n",
       "\n",
       "                                  name_speaker gender_speaker human_speaker  \\\n",
       "130                 Ben Buckle and Percy Patch              M             H   \n",
       "175                                Mum and Dad            NGS             H   \n",
       "417                              Esme and Bear            NGS            NH   \n",
       "421                               Grandpa Eldo              F             H   \n",
       "423                               Grandpa Eldo              F             H   \n",
       "...                                        ...            ...           ...   \n",
       "2715  Flip, Flap, Waddle, Splash, and Littlest            NGS            NH   \n",
       "2729  Flip, Flap, Waddle, Splash, and Littlest            NGS            NH   \n",
       "2732  Flip, Flap, Waddle, Splash, and Littlest            NGS            NH   \n",
       "2734  Flip, Flap, Waddle, Splash, and Littlest            NGS            NH   \n",
       "2821                                   Grandma              F             H   \n",
       "\n",
       "     alias_count_speaker  is_protagonist_speaker        name_recipient  \\\n",
       "130                  0.0                     NaN                 Troll   \n",
       "175                  0.0                     NaN                  June   \n",
       "417                  0.0                     NaN  Little Bunny Boo-Boo   \n",
       "421                  0.0                     0.0                 Elmer   \n",
       "423                  0.0                     0.0                 Elmer   \n",
       "...                  ...                     ...                   ...   \n",
       "2715                 0.0                     NaN              Old Wise   \n",
       "2729                 0.0                     NaN              Old Wise   \n",
       "2732                 0.0                     NaN              Old Wise   \n",
       "2734                 0.0                     NaN              Old Wise   \n",
       "2821                 0.0                     0.0                   Sid   \n",
       "\n",
       "     gender_recipient human_recipient alias_count_recipient  \\\n",
       "130                 M              NH                   0.0   \n",
       "175                 F               H                   0.0   \n",
       "417                 F              NH                   0.0   \n",
       "421                 M              NH                   0.0   \n",
       "423                 M              NH                   0.0   \n",
       "...               ...             ...                   ...   \n",
       "2715                M             NH                    0.0   \n",
       "2729                M             NH                    0.0   \n",
       "2732                M             NH                    0.0   \n",
       "2734                M             NH                    0.0   \n",
       "2821                M              NH                   0.0   \n",
       "\n",
       "      is_protagonist_recipient  \n",
       "130                        1.0  \n",
       "175                        1.0  \n",
       "417                        0.0  \n",
       "421                        1.0  \n",
       "423                        1.0  \n",
       "...                        ...  \n",
       "2715                       1.0  \n",
       "2729                       1.0  \n",
       "2732                       1.0  \n",
       "2734                       1.0  \n",
       "2821                       1.0  \n",
       "\n",
       "[90 rows x 21 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[['and' in s for s in speakers.speaker]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "['Peace at Last' 'The Princess and the Wizard' \"Kipper's Toybox\"\n",
      " 'Harry and the Dinosaurs at the Museum' 'A Thing Called Snow' 'Cave Baby'\n",
      " 'Lost in Snow' 'Is It Betime Wibbly Pig' 'Wide-awake Hedgehog'\n",
      " 'Tyrannosaurus Drip'\n",
      " 'Sir Charlie Stinky Socks and the Really Big Adventure'\n",
      " 'I Am Amelia Earhart' \"The Tree That's Meant To Be\"\n",
      " 'What The Ladybird Heard' \"Charlie Cook's Favourite Book\" \"Ravi's Roar\"\n",
      " 'The Runaway Pea' 'Knock Knock Alien' 'Boogie Bear' 'Santa to the Rescue'\n",
      " 'The Bad-Tempered Ladybird' 'Snow White, Star Striker'\n",
      " \"Eleanor Won't Share\" 'Superworm' \"Jesus' Christmas Party\"\n",
      " 'The Ugly Duckling' \"Where's My Teddy\" 'What The Ladybird Heard Next'\n",
      " 'Captain Duck' 'The Christmas Extravaganza Hotel' 'Little Monkey']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_recipient.isna()].book.unique()))\n",
    "print(speakers[speakers.name_recipient.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[\"Kipper's Toybox\" 'Elmer and the Lost Teddy' \"The Owl's Lesson\"\n",
      " 'Lost in Snow' 'Is It Betime Wibbly Pig' 'Wide-awake Hedgehog'\n",
      " 'I Am Amelia Earhart' \"Dogs Don't Do Ballet\" 'The First Christmas'\n",
      " 'What The Ladybird Heard' 'The Runaway Pea' 'Boogie Bear'\n",
      " 'Santa to the Rescue' 'Father Christmas Needs A Wee'\n",
      " \"Eleanor Won't Share\" 'Stick Man' 'Harry and the Robots'\n",
      " \"Jesus' Christmas Party\" 'The Ugly Duckling' 'The Wheels on the Bus'\n",
      " 'What The Ladybird Heard Next' 'Elephant Learns to Share'\n",
      " 'One Snowy Night' 'Little Monkey']\n"
     ]
    }
   ],
   "source": [
    "print(len(speakers[speakers.name_speaker.isna()].book.unique()))\n",
    "print(speakers[speakers.name_speaker.isna()].book.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_speaker_books = iter(speakers[speakers.name_speaker.isna()].book.unique())\n",
    "# null_speaker_books = iter(speakers[speakers.name_recipient.isna()].book.unique())\n",
    "# null_speaker_books = iter(\n",
    "#     set(speakers[speakers.name_recipient.isna()].book.unique()) - set(speakers[speakers.name_speaker.isna()].book.unique())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sing A Song Of Bottoms', 'The Troll', \"Kipper's Toybox\", 'Elmer and the Lost Teddy', 'Santa is Coming to Devon', 'The Enormous Crocodile', 'Harry and the Dinosaurs Go Wild', 'Harry and the Dinosaurs at the Museum', 'The Cross Rabbit', 'Yoga Babies', 'Elmer and Wilbur', 'I Need A Wee', \"The Owl's Lesson\", 'Cave Baby', 'The Rescue Party', 'Zog', 'Dogger', 'Is It Betime Wibbly Pig', 'Wide-awake Hedgehog', 'Tyrannosaurus Drip', 'The Rhyming Rabbit', 'I Am Amelia Earhart', 'She Rex', 'Mole Hill', 'Oi Dog!', \"The Lighthouse Keeper's Lunch\", \"The Tree That's Meant To Be\", 'The Dinosaur That Pooped Christmas', \"The Jolly Postman or Other People's Letters\", 'What The Ladybird Heard', \"Ravi's Roar\", 'The Runaway Pea', 'Zog and the Flying Doctors', 'The Three Little Pigs', 'Lenny Makes A Wish', 'Knock Knock Alien', 'Boogie Bear', 'Father Christmas Needs A Wee', 'The Polar Express', 'Mini Beasties', 'The Smartest Giant in Town', 'Barry the Fish With Fingers and the Hairy Scary Monster', 'Stick Man', 'Sharing A Shell', \"Dogs Don't Do Ballet\", 'Santa to the Rescue']\n"
     ]
    }
   ],
   "source": [
    "print(list(null_speaker_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross Rabbit\n"
     ]
    }
   ],
   "source": [
    "current_book = next(null_speaker_books)\n",
    "print(current_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>speech_section_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recipient</th>\n",
       "      <th>speaker_matched</th>\n",
       "      <th>recipient_matched</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>spoken_words_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>chunk_titles</th>\n",
       "      <th>self_talk_flag</th>\n",
       "      <th>name_speaker</th>\n",
       "      <th>gender_speaker</th>\n",
       "      <th>human_speaker</th>\n",
       "      <th>alias_count_speaker</th>\n",
       "      <th>name_recipient</th>\n",
       "      <th>gender_recipient</th>\n",
       "      <th>human_recipient</th>\n",
       "      <th>alias_count_recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>9</td>\n",
       "      <td>the mice</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Percy</td>\n",
       "      <td>“Hello Percy!” they called. But suddenly they\\...</td>\n",
       "      <td>Hello Percy! You’re not going to tell us to st...</td>\n",
       "      <td>58</td>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>11</td>\n",
       "      <td>the mice</td>\n",
       "      <td>Percy</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Percy</td>\n",
       "      <td>“We’ll try!” they squeaked loudly.</td>\n",
       "      <td>We’ll try!</td>\n",
       "      <td>10</td>\n",
       "      <td>The Cross Rabbit</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Percy</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book  speech_section_id   speaker recipient speaker_matched  \\\n",
       "556  The Cross Rabbit                  9  the mice     Percy         Unknown   \n",
       "558  The Cross Rabbit                 11  the mice     Percy         Unknown   \n",
       "\n",
       "    recipient_matched                                        speech_text  \\\n",
       "556             Percy  “Hello Percy!” they called. But suddenly they\\...   \n",
       "558             Percy                 “We’ll try!” they squeaked loudly.   \n",
       "\n",
       "                                     spoken_words_only  spoken_word_count  \\\n",
       "556  Hello Percy! You’re not going to tell us to st...                 58   \n",
       "558                                         We’ll try!                 10   \n",
       "\n",
       "         chunk_titles  self_talk_flag name_speaker gender_speaker  \\\n",
       "556  The Cross Rabbit           False          NaN            NaN   \n",
       "558  The Cross Rabbit           False          NaN            NaN   \n",
       "\n",
       "    human_speaker  alias_count_speaker name_recipient gender_recipient  \\\n",
       "556           NaN                  NaN          Percy                M   \n",
       "558           NaN                  NaN          Percy                M   \n",
       "\n",
       "    human_recipient  alias_count_recipient  \n",
       "556               H                    0.0  \n",
       "558               H                    0.0  "
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[(speakers.book == current_book) * (speakers.name_speaker.isna())]\n",
    "# speakers[(speakers.book == current_book) * (speakers.name_recipient.isna())]\n",
    "# speakers[(speakers.book == 'Sing A Song Of Bottoms') * (speakers.name_speaker.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Harry</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Mum</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Sam</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Gran</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>T-Rex</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Museum Guard</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Pterodactyl</td>\n",
       "      <td>M</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Triceratops</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Anchisaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Apatosaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Scelidosaurs</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Nan</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Person in charge</td>\n",
       "      <td>NGS</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Harry and the Dinosaurs at the Museum</td>\n",
       "      <td>Stegosaurus</td>\n",
       "      <td>NGS</td>\n",
       "      <td>NH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      book              name gender human  \\\n",
       "40   Harry and the Dinosaurs at the Museum             Harry      M     H   \n",
       "380  Harry and the Dinosaurs at the Museum               Mum      F     H   \n",
       "381  Harry and the Dinosaurs at the Museum               Sam      F     H   \n",
       "382  Harry and the Dinosaurs at the Museum              Gran      F     H   \n",
       "383  Harry and the Dinosaurs at the Museum             T-Rex      M    NH   \n",
       "384  Harry and the Dinosaurs at the Museum      Museum Guard      M     H   \n",
       "385  Harry and the Dinosaurs at the Museum       Pterodactyl      M    NH   \n",
       "386  Harry and the Dinosaurs at the Museum       Triceratops    NGS    NH   \n",
       "387  Harry and the Dinosaurs at the Museum       Anchisaurus    NGS    NH   \n",
       "388  Harry and the Dinosaurs at the Museum       Apatosaurus    NGS    NH   \n",
       "389  Harry and the Dinosaurs at the Museum      Scelidosaurs    NGS    NH   \n",
       "390  Harry and the Dinosaurs at the Museum               Nan      F     H   \n",
       "391  Harry and the Dinosaurs at the Museum  Person in charge    NGS     H   \n",
       "392  Harry and the Dinosaurs at the Museum       Stegosaurus    NGS    NH   \n",
       "\n",
       "     alias_count  \n",
       "40             0  \n",
       "380            0  \n",
       "381            0  \n",
       "382            0  \n",
       "383            1  \n",
       "384            0  \n",
       "385            0  \n",
       "386            0  \n",
       "387            0  \n",
       "388            0  \n",
       "389            0  \n",
       "390            0  \n",
       "391            0  \n",
       "392            0  "
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.book == current_book]\n",
    "# characters[characters.book == 'Sing A Song Of Bottoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>pack</td>\n",
       "      <td>wolves</td>\n",
       "      <td>1084</td>\n",
       "      <td>The Way Home For Wolf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alias character  character_id                   book\n",
       "index                                                     \n",
       "147    pack    wolves          1084  The Way Home For Wolf"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aliases[aliases.character_id==196]\n",
    "aliases[aliases.character=='wolves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>character</th>\n",
       "      <th>character_id</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gruff the Grump</td>\n",
       "      <td>Mr Bear</td>\n",
       "      <td>5</td>\n",
       "      <td>Gruff the Grump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We</td>\n",
       "      <td>I</td>\n",
       "      <td>16</td>\n",
       "      <td>The Polar Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little dove</td>\n",
       "      <td>her baby</td>\n",
       "      <td>24</td>\n",
       "      <td>The Christmas Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McTat</td>\n",
       "      <td>Tabby McTat</td>\n",
       "      <td>51</td>\n",
       "      <td>Tabby McTat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we're</td>\n",
       "      <td>we</td>\n",
       "      <td>67</td>\n",
       "      <td>We're Going On A Lion Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>everyone</td>\n",
       "      <td>other children</td>\n",
       "      <td>1383</td>\n",
       "      <td>Eleanor Won't Share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother duck</td>\n",
       "      <td>1434</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>the swans</td>\n",
       "      <td>white birds</td>\n",
       "      <td>1436</td>\n",
       "      <td>The Ugly Duckling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Granny</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>1449</td>\n",
       "      <td>Little Red Riding Hood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>The Troll</td>\n",
       "      <td>Troll</td>\n",
       "      <td>50</td>\n",
       "      <td>The Troll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  alias       character  character_id  \\\n",
       "index                                                   \n",
       "0       Gruff the Grump         Mr Bear             5   \n",
       "1                    We               I            16   \n",
       "2           little dove        her baby            24   \n",
       "3                McTat      Tabby McTat            51   \n",
       "4                 we're              we            67   \n",
       "...                 ...             ...           ...   \n",
       "164            everyone  other children          1383   \n",
       "165              mother     mother duck          1434   \n",
       "166           the swans     white birds          1436   \n",
       "167              Granny     grandmother          1449   \n",
       "168           The Troll           Troll            50   \n",
       "\n",
       "                             book  \n",
       "index                              \n",
       "0                 Gruff the Grump  \n",
       "1               The Polar Express  \n",
       "2             The Christmas Story  \n",
       "3                     Tabby McTat  \n",
       "4      We're Going On A Lion Hunt  \n",
       "...                           ...  \n",
       "164           Eleanor Won't Share  \n",
       "165             The Ugly Duckling  \n",
       "166             The Ugly Duckling  \n",
       "167        Little Red Riding Hood  \n",
       "168                     The Troll  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_character_count = sum(characters.gender == 'F')\n",
    "male_character_count = sum(characters.gender == 'M')\n",
    "ngs_character_count = sum(characters.gender == 'NGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_word_count = speakers[speakers.gender_speaker == 'M'].spoken_word_count.sum()\n",
    "female_spoken_word_count = speakers[speakers.gender_speaker == 'F'].spoken_word_count.sum()\n",
    "ngs_spoken_word_count = speakers[speakers.gender_speaker == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.65625"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.85217391304347"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.58069620253164"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_spoken_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22682445759368836"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / (male_character_count + female_character_count + ngs_character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3576594345825115"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_character_count / (male_character_count + female_character_count + ngs_character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6341911764705882"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_character_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_received_word_count = speakers[speakers.gender_recipient == 'M'].spoken_word_count.sum()\n",
    "female_received_word_count = speakers[speakers.gender_recipient == 'F'].spoken_word_count.sum()\n",
    "ngs_received_word_count = speakers[speakers.gender_recipient == 'NGS'].spoken_word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.32264150943396"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_received_word_count / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.57910447761193"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_received_word_count / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.68092105263158"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_received_word_count / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_speech_sections = len(speakers[speakers.gender_speaker == 'M'])\n",
    "female_speech_sections = len(speakers[speakers.gender_speaker == 'F'])\n",
    "ngs_speech_sections = len(speakers[speakers.gender_speaker == 'NGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6962264150943396"
      ]
     },
     "execution_count": 1216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / male_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.537313432835821"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / female_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.350328947368421"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / ngs_character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396694214876033"
      ]
     },
     "execution_count": 1219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23415977961432508"
      ]
     },
     "execution_count": 1220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22617079889807162"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngs_speech_sections / (male_speech_sections + female_speech_sections + ngs_speech_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128964935670641"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_spoken_word_count / (male_spoken_word_count + female_spoken_word_count + ngs_spoken_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22806182779235584"
      ]
     },
     "execution_count": 1223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_spoken_word_count / (male_spoken_word_count + female_spoken_word_count + ngs_spoken_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_spoken_words = speakers[speakers.gender_speaker == 'M'].spoken_words_only\n",
    "female_spoken_words = speakers[speakers.gender_speaker == 'F'].spoken_words_only\n",
    "ngs_spoken_words = speakers[speakers.gender_speaker == 'NGS'].spoken_words_only\n",
    "\n",
    "male_received_words = speakers[speakers.gender_recipient == 'M'].spoken_words_only\n",
    "female_received_words = speakers[speakers.gender_recipient == 'F'].spoken_words_only\n",
    "ngs_received_words = speakers[speakers.gender_recipient == 'NGS'].spoken_words_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011435552167243802"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(male_spoken_words)]) / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010142532534600289"
      ]
     },
     "execution_count": 1387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(female_spoken_words)]) / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013821700069108501"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(ngs_spoken_words)]) / ngs_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004491554224724674"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(male_spoken_words)]) / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003966122701921091"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(female_spoken_words)]) / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010142869562697424"
      ]
     },
     "execution_count": 1392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(male_received_words)]) / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012995742773918888"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(female_received_words)]) / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012929959256076942"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '!' for c in ' '.join(ngs_received_words)]) / ngs_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004742999005032796"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(male_received_words)]) / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004929419672865786"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c == '?' for c in ' '.join(female_received_words)]) / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>gender</th>\n",
       "      <th>human</th>\n",
       "      <th>alias_count</th>\n",
       "      <th>is_protagonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mum</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mum</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mummy</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nan</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cinderella</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Granny</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goldilocks</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Bear</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Bird</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Griselda</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow White</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book  gender  human  alias_count  is_protagonist\n",
       "name                                                        \n",
       "Mum           19      19     19           19              19\n",
       "mum            9       9      9            9               9\n",
       "Mummy          8       8      8            8               8\n",
       "Sam            7       7      7            7               7\n",
       "mother         6       6      6            6               6\n",
       "Nan            5       5      5            5               5\n",
       "girl           5       5      5            5               5\n",
       "cow            5       5      5            5               5\n",
       "Mary           5       5      5            5               5\n",
       "Cinderella     5       5      5            5               5\n",
       "Granny         5       5      5            5               5\n",
       "hen            4       4      4            4               4\n",
       "Goldilocks     4       4      4            4               4\n",
       "I              4       4      4            4               4\n",
       "Mrs Bear       4       4      4            4               4\n",
       "Miss Bird      4       4      4            4               4\n",
       "Griselda       3       3      3            3               3\n",
       "Snow White     3       3      3            3               3\n",
       "granny         3       3      3            3               3\n",
       "lady           3       3      3            3               3"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters[characters.gender == 'F'].groupby('name').agg('count').sort_values('book', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much female speech is by Mum compared to male speech by Dad (option include Granny/Grandpa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "mum_map = ['mum', 'mother', 'mummy', 'mom', 'mommy', 'ma', 'mama', 'mumma', 'mamma']\n",
    "dad_map = ['dad', 'father', 'daddy', 'dada', 'dadda', 'da', 'pa', 'papa']\n",
    "gran_map = ['gran', 'granny', 'nan', 'nana', 'nanna', 'grandma', 'gradmother', 'granmother'] \n",
    "grandpa_map = ['grandpa', 'gramps', 'grandfather', 'grandad', 'granddad']\n",
    "\n",
    "def match_map(_map, _name, verbose=False):\n",
    "    exclusions = ['christmas', 'xmas', 'nature', 'earth', 'time', 'clock']\n",
    "    \n",
    "    if not pd.isna(_name):\n",
    "        _name = str(_name)\n",
    "    else:\n",
    "        _name=''\n",
    "   \n",
    "    is_exclusion = sum([\n",
    "        m in _name.lower() for m in exclusions\n",
    "    ]) > 0\n",
    "    if is_exclusion:\n",
    "        return False\n",
    "    \n",
    "    is_match = sum([\n",
    "        m in _name.lower().split() for m in _map\n",
    "    ]) > 0\n",
    "    if is_match and verbose:\n",
    "        print(_name)\n",
    "\n",
    "    return is_match #| is_short_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_map(mum_map, 'ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16716417910447762"
      ]
     },
     "execution_count": 1341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(mum_map, s)\n",
    "#     for s in characters.name]) / len(characters)\n",
    "    for s in characters.name]) / sum(characters.gender=='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062264150943396226"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(dad_map, s)\n",
    "#     for s in characters.name]) / len(characters)\n",
    "     for s in characters.name]) / sum(characters.gender=='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_characters = characters[characters.is_protagonist==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07888040712468193"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(dad_map, s)\n",
    "    for s in secondary_characters.name]) / sum(secondary_characters.gender=='M')\n",
    "#     for s in secondary_characters.name]) / len(secondary_characters.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17905405405405406"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([match_map(mum_map, s)\n",
    "    for s in secondary_characters.name]) / sum(secondary_characters.gender=='F')\n",
    "#     for s in secondary_characters.name]) / len(secondary_characters.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers['speaker_is_mum'] = [\n",
    "    match_map(mum_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_dad'] = [\n",
    "    match_map(dad_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_granny'] = [\n",
    "    match_map(gran_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "speakers['speaker_is_grandpa'] = [\n",
    "    match_map(grandpa_map, s)\n",
    "    for s in speakers.name_speaker\n",
    "]\n",
    "\n",
    "speakers['recipient_is_mum'] = [\n",
    "    match_map(mum_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_dad'] = [\n",
    "    match_map(dad_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_granny'] = [\n",
    "    match_map(gran_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]\n",
    "speakers['recipient_is_grandpa'] = [\n",
    "    match_map(grandpa_map, s)\n",
    "    for s in speakers.name_recipient\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_mum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_dad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_granny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_grandpa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09902912621359224"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_mum].spoken_word_count.sum() / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01990429039872877"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_dad].spoken_word_count.sum() / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02189630241685602"
      ]
     },
     "execution_count": 1354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_granny].spoken_word_count.sum() / female_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03337895307290279"
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.speaker_is_grandpa].spoken_word_count.sum() / male_spoken_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1223529411764706"
      ]
     },
     "execution_count": 1357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_mum]) / female_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022460438999489536"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speakers[speakers.speaker_is_dad]) / male_speech_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15286802599148555"
      ]
     },
     "execution_count": 1368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.recipient_is_mum].spoken_word_count.sum() / female_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023589416640102008"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[speakers.recipient_is_dad].spoken_word_count.sum() / male_received_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
